¿Cómo se Puede Usar la IA Generativa en la Ciberseguridad? 10 Ejemplos del Mundo Real | Secureframe
Autor desconocido
secureframe.com

Actualizaciones del Producto Explorar Novedades
Centro de Ayuda
Table of Contents
En una encuesta reciente a ejecutivos y profesionales de la seguridad por Splunk Inc., el 91% de los encuestados dijo que utilizan IA generativa y el 46% afirmó que será un cambio revolucionario para sus equipos de seguridad.
A pesar de la disponibilidad pública relativamente reciente de la IA generativa, ya está cambiando fundamentalmente los trabajos y flujos de trabajo de los profesionales de la ciberseguridad.
En este artículo, exploraremos las formas en que la IA generativa está impactando la industria de la ciberseguridad, tanto para bien como para mal. También nos centraremos en casos de uso del mundo real de la IA generativa en la ciberseguridad hoy en día.
Cómo la Inteligencia Artificial Afectará la Ciberseguridad en 2024 y Más Allá
La IA generativa se ha convertido en una espada de doble filo en el ámbito de la ciberseguridad. Por un lado, los actores maliciosos están aprovechando cada vez más su poder para crear amenazas sofisticadas a gran escala. Explotan modelos de IA como ChatGPT para generar malware, identificar vulnerabilidades en el código y eludir los controles de acceso de los usuarios. Además, los ingenieros sociales están empleando IA generativa para elaborar estafas de phishing y deepfakes más convincentes, amplificando el panorama de amenazas. Un sustancial 85% de los profesionales de la seguridad que presenciaron un aumento en los ciberataques en los últimos 12 meses atribuyen el aumento a los actores maliciosos que utilizan IA generativa.
Sin embargo, la IA generativa también presenta oportunidades significativas para fortalecer las defensas de ciberseguridad. Puede ayudar en la identificación de vectores de ataque potenciales, responder automáticamente a incidentes de seguridad y potenciar las capacidades de inteligencia de amenazas.
Para comprender plenamente el impacto de la IA generativa en la ciberseguridad, los CISOs y otros líderes de seguridad y TI deben entender los riesgos y beneficios que ofrece. A continuación, echaremos un vistazo más de cerca a estos.
Los atacantes maliciosos están aprovechando el potencial de la IA generativa para lanzar ciberataques que son más difíciles de detectar y defender. Veamos algunos de los riesgos de la IA generativa a continuación.
En la Encuesta de EY 2024 sobre el Riesgo Humano en Ciberseguridad, el 85% de los encuestados dijo que creen que la IA ha hecho que los ataques de ciberseguridad sean más sofisticados.
Los hackers están usando IA generativa en particular para lanzar ataques cada vez más sofisticados como malware autoevolutivo. Estas cepas de malware utilizan IA generativa para ‘auto-evolucionar’ y crear variaciones con técnicas únicas, cargas útiles y código polimórfico para atacar un objetivo específico y pasar desapercibidos por las medidas de seguridad existentes.
Los hackers también están usando IA generativa para lanzar volúmenes más grandes de ataques. En un  informe de Deep Instinct , el 75% de los profesionales de seguridad fueron testigos de un aumento en los ataques en los últimos 12 meses, y el 85% atribuyó este aumento a los actores maliciosos que utilizan IA generativa.
Eso significa que los ciberdelincuentes están utilizando IA generativa para crear ataques cibernéticos más sofisticados a gran escala. Por ejemplo, el IBM X-Force Threat Intelligence Index 2024 encontró que las capacidades de IA generativa facilitan una reducción de más del 99.5% en el tiempo necesario para crear un correo electrónico de phishing efectivo.
Mientras que la adopción de la IA generativa está aumentando, los esfuerzos para gestionar los riesgos introducidos por la IA generativa están rezagados. Un estudio reciente publicado por IBM y Amazon Web Services encontró que las organizaciones están asegurando solo el 24% de sus proyectos actuales de IA generativa, a pesar de que el 82% de los encuestados dice que tener una IA segura y confiable es esencial para el éxito de su negocio. De hecho, el 69% de los ejecutivos encuestados dice que la innovación tiene prioridad sobre la seguridad.
Esto es solo un poco mejor que los resultados de un  informe de 2023 de Riskconnect, en el que el 93% de las empresas reconocieron los riesgos asociados con el uso de IA generativa dentro de la empresa, pero solo el 9% dijo que están preparados para gestionar la amenaza.
Las organizaciones que aumenten su adopción de IA generativa sin actualizar y fortalecer simultáneamente su estrategia de gestión de riesgos aumentarán su exposición al riesgo.
Muchos desarrolladores están recurriendo a la IA generativa para mejorar su productividad. Sin embargo, un  estudio de Stanford encontró que los ingenieros de software que utilizan sistemas de generación de código por IA son más propensos a causar vulnerabilidades de seguridad en las aplicaciones que desarrollan. A medida que más desarrolladores sin la experiencia o el tiempo para detectar y remediar vulnerabilidades en el código usan IA generativa, se introducirán más vulnerabilidades en el código que pueden ser explotadas por hackers.
La IA generativa también está ayudando a que los equipos de seguridad sean más precisos, eficientes y productivos en la defensa de sus organizaciones. Veamos a continuación cómo la IA generativa está transformando las operaciones de seguridad.
La IA se está utilizando para complementar los equipos de seguridad y mejorar los resultados de seguridad. La mayoría de los ejecutivos de TI (93%) ya están utilizando o considerando implementar IA y ML para mejorar sus capacidades de seguridad. Estos adoptadores de IA ya están reportando mejoras en el rendimiento en la clasificación de amenazas de Nivel 1, la detección de ataques y amenazas de día cero, y la reducción de falsos positivos y ruido.
Como resultado de estos primeros indicadores de éxito, más de la mitad de los ejecutivos (52%) dice que la IA generativa les ayudará a asignar mejor los recursos, la capacidad, el talento o las habilidades.
La detección de amenazas es uno de los principales casos de uso de la IA generativa hoy en día. Al utilizarla para identificar patrones y anomalías más rápidamente, filtrar alertas de incidentes más eficientemente y rechazar falsos positivos, las organizaciones pueden acelerar significativamente su capacidad para detectar nuevos vectores de amenazas.
La IA generativa también se está utilizando para mejorar la inteligencia de amenazas. Anteriormente, los analistas tendrían que utilizar lenguajes de consulta complejos, operaciones y la ingeniería inversa para analizar grandes cantidades de datos para entender las amenazas. Ahora, pueden utilizar algoritmos de IA generativa que escanean automáticamente el código y el tráfico de la red en busca de amenazas y proporcionan información detallada que ayuda a los analistas a entender el comportamiento de los scripts maliciosos y otras amenazas.
La IA generativa puede automatizar el análisis y la aplicación de parches. Utilizando redes neuronales, puede escanear bases de código en busca de vulnerabilidades y aplicar o sugerir parches apropiados utilizando el procesamiento de lenguaje natural (PLN) para el análisis de patrones o un algoritmo de aprendizaje automático conocido como el algoritmo de K vecinos más cercanos (KNN).
Otra aplicación exitosa de la IA generativa en ciberseguridad es en la respuesta a incidentes. La IA generativa puede proporcionar a los analistas de seguridad estrategias de respuesta basadas en tácticas exitosas usadas en incidentes pasados, lo que puede ayudar a acelerar los flujos de trabajo de respuesta a incidentes. La IA generativa también puede seguir aprendiendo de los incidentes para adaptar estas estrategias de respuesta con el tiempo. Las organizaciones también pueden utilizar la IA generativa para automatizar la creación de informes de respuesta a incidentes.
Durante la Conferencia RSA 2024, Elie Bursztein, líder técnico y de investigación en ciberseguridad de Google y DeepMind AI, dijo que una de las aplicaciones más prometedoras de la IA generativa es acelerar la respuesta a incidentes. Aunque es necesario realizar más investigación e innovación, afirmó que algún día la IA generativa podría modelar un incidente o generar un informe de incidentes casi en tiempo real para ayudar a acelerar drásticamente las tasas de respuesta a incidentes.
Inteligencia Artificial: El Próximo Gran Salto para el Cumplimiento de Seguridad
Ahora que entendemos algunas de las aplicaciones generales de la IA generativa en ciberseguridad, echemos un vistazo a algunas herramientas específicas de ciberseguridad que utilizan IA generativa.
Secureframe lanzó Comply AI para Remediación para proporcionar una experiencia de usuario más contextual, precisa y personalizada para remediar pruebas fallidas, de modo que las organizaciones puedan solucionar rápidamente problemas de ciberseguridad y agilizar el cumplimiento.
Comply AI para Remediación proporciona orientación de remediación adaptada al entorno del usuario, de modo que puedan actualizar fácilmente el problema subyacente que causa la configuración fallida en su entorno. Esto les permite corregir controles fallidos para pasar las pruebas, estar listos para la auditoría más rápido y mejorar su postura de seguridad y cumplimiento en general.
Los usuarios también pueden hacer preguntas de seguimiento utilizando el chatbot para obtener detalles adicionales sobre el código de remediación o para proporcionar una orientación más personalizada para sus necesidades específicas de seguridad y cumplimiento.
Google anunció recientemente Google Threat Intelligence, que combina el poder de la experiencia de Mandiant en primera línea, la inteligencia de amenazas de VirusTotal que es recolectada por más de 1 millón de usuarios, y el modelo de IA Gemini en una sola oferta.
Gemini es un agente impulsado por IA que proporciona búsqueda conversacional a través del vasto repositorio de Google de inteligencia de amenazas, permitiendo a los usuarios obtener información sobre amenazas y protegerse más rápido. Tradicionalmente, operacionalizar la inteligencia de amenazas ha sido laborioso y lento. Google Threat Intelligence utiliza Gemini para analizar potencialmente código malicioso y proporciona un resumen de sus hallazgos para ayudar a los profesionales de seguridad a combatir el malware y otros tipos de amenazas de manera más rápida y efectiva.
Secureframe Comply AI para Riesgo fue diseñado para automatizar el proceso de evaluación de riesgos y ahorrar tiempo y recursos a las organizaciones.
Usando solo una descripción de riesgo e información de la empresa, Comply AI for Risk produce información detallada sobre un riesgo, incluyendo la probabilidad e impacto de un riesgo antes de una respuesta, un plan de tratamiento para responder al riesgo, y la probabilidad e impacto residual del riesgo después del tratamiento. Estos resultados detallados de Comply AI for Risk ayudan a las organizaciones a comprender mejor el impacto potencial de un riesgo y los métodos adecuados de mitigación, mejorando su conciencia y respuesta ante riesgos.
Tenable lanzó  ExposureAI para proporcionar nuevos y ricos conocimientos a los analistas para hacer que la gestión de exposición sea más accesible. Estas nuevas capacidades de IA generativa ayudan a los analistas a buscar, analizar y tomar decisiones sobre exposiciones más rápido al:
Ironscales lanzó Pruebas de Simulación de Phishing impulsadas por GPT (PST) como una característica beta. Esta herramienta utiliza el modelo de lenguaje propio de Ironscales para generar campañas de pruebas de simulación de phishing que están personalizadas para los empleados y los ataques de phishing avanzados que pueden encontrar.
El objetivo es ayudar a las organizaciones a personalizar rápidamente su capacitación en concienciación sobre seguridad para combatir el aumento y la sofisticación de los ataques de ingeniería social.
ZeroFox ha desarrollado FoxGPT, una herramienta de IA generativa diseñada para acelerar el análisis y la resumición de inteligencia a través de grandes conjuntos de datos. Puede ayudar a los equipos de seguridad a analizar y contextualizar contenido malicioso, ataques de phishing y posibles tomas de cuentas.
SentinelOne presentó una plataforma de caza de amenazas impulsada por IA generativa que combina redes neuronales integradas en tiempo real y una interfaz de lenguaje natural (LLM) basada en modelo de lenguaje grande para ayudar a los analistas a identificar, analizar y mitigar amenazas más rápido.
Usando lenguaje natural, los analistas pueden hacer preguntas complejas de caza de amenazas y adversarios y ejecutar comandos operativos para gestionar su entorno empresarial y obtener respuestas rápidas, precisas y detalladas en segundos. Purple AI también puede analizar amenazas y proporcionar información sobre el comportamiento identificado junto con los próximos pasos recomendados.
VirusTotal Code Insight utiliza Sec-PaLM, uno de los modelos de IA generativa alojados en Google Cloud AI, para producir resúmenes en lenguaje natural de fragmentos de código. Esto puede ayudar a los equipos de seguridad a analizar y comprender el comportamiento de scripts potencialmente maliciosos. VirusTotal Code Insight está destinado a servir como un asistente poderoso para los analistas de ciberseguridad, trabajando 24/7 para mejorar su rendimiento y efectividad general.
El suite QRadar combina IA avanzada y automatización para acelerar la detección y respuesta a amenazas. IBM ha anunciado que lanzará capacidades de seguridad de IA generativa a principios de 2024 para automatizar aún más tareas manuales y optimizar el tiempo y talento de los equipos de seguridad. Estas tareas incluyen:
Responder a cuestionarios de seguridad puede ser un proceso tedioso y que consume mucho tiempo para los analistas de seguridad y otros stakeholders, con preguntas que varían de cliente a cliente y sin un formato, conjunto o orden estándar de preguntas.
La Automatización de Cuestionarios de Secureframe utiliza IA generativa para agilizar y automatizar el proceso. Esta herramienta sugiere respuestas a cuestionarios utilizando políticas, controles, pruebas y otro contexto de la plataforma Secureframe junto con respuestas previas aprobadas en la Base de Conocimiento para ofrecer una mayor precisión. Después de revisar rápidamente las respuestas y realizar los ajustes necesarios, los usuarios pueden compartir los cuestionarios completados con prospectos y clientes en su formato original.
IA en ciberseguridad: cómo se usa + 8 desarrollos más recientes
A continuación, algunos pasos que su organización puede tomar ahora mismo para comenzar a defenderse contra los riesgos de la IA generativa.
Tómese el tiempo para evaluar y actualizar la capacitación de los empleados en torno a la IA generativa. Esta capacitación debe reflejar la sofisticación de los ciberataques que utilizan IA generativa, incluidos los correos electrónicos de phishing cada vez más convincentes y las llamadas y videos de deep fake.
Considere también incluir medidas de control para el uso de herramientas de IA generativa en la capacitación de los empleados.
Mientras que un informe reciente de ExtraHop reveló que el 32% de las organizaciones han prohibido el uso de herramientas de IA generativa, organizaciones líderes como el AICPA recomiendan que las organizaciones actualicen sus políticas de seguridad para promover el uso seguro de herramientas de IA, ya que es inevitable. Las consideraciones clave incluyen:
Similar a cómo el TI en la sombra aumentó a medida que los productos SaaS se volvieron más populares y accesibles, la IA en la sombra está creciendo a medida que los empleados adoptan cada vez más la IA para mejorar su productividad.
La IA en la sombra presenta grandes desafíos en términos de seguridad y gobernanza por dos razones principales. Primero, los empleados pueden exponer información sensible, privilegiada o propietaria al usar productos de IA. Segundo, el equipo de seguridad de una organización no puede evaluar y mitigar los riesgos de las herramientas de IA que no conocen.
Para abordar estos desafíos, las organizaciones pueden adoptar un enfoque múltiple para reducir el TI en la sombra. Esto puede incluir educar a los empleados sobre los riesgos del TI en la sombra, identificar servicios de IA no autorizados y otras medidas de control en las políticas, e implementar estrategias de seguridad ofensivas y defensivas, como cercas de seguridad para detectar y controlar qué tipo y cuánta información fluye dentro de su organización.
Dado que la IA generativa es una espada de doble filo, asegúrese de utilizarla a su favor. Por ejemplo, puede desplegar soluciones de IA generativa para detectar amenazas con la velocidad, escala y sofisticación con la que los actores nefastos las lanzan. También puede usarla para automatizar tareas rutinarias que no requieren tanta experiencia o juicio humano, como la caza de amenazas.
Cuando se usa estratégicamente de estas maneras, la IA generativa y la automatización pueden ayudar a su organización a identificar y responder a los riesgos e incidentes de seguridad de manera más rápida y a gran escala.
La regulación de la IA ya ha sido aprobada por la UE, China y partes de los EE.UU., y se espera que aumente. También hay un número creciente de marcos voluntarios que abordan las complejidades y preocupaciones éticas de la IA y están diseñados para ayudar a las organizaciones a mitigar riesgos y mejorar la gobernanza, como el Marco de Gestión de Riesgos de IA de NIST (AI RMF) y la norma ISO 42001.
Cumplir con estas regulaciones y marcos puede proporcionar a las organizaciones un enfoque estructurado para gestionar los sistemas de IA de manera responsable y efectiva, mejorando así la confianza y la fiabilidad entre los desarrolladores y usuarios de IA.
Siga estas mejores prácticas para implementar la IA de manera efectiva al tiempo que aborda las preocupaciones relacionadas con la transparencia, la privacidad y la seguridad.
Secureframe continúa expandiendo sus capacidades de IA para ayudar a los clientes a:
¿Quiere explorar más a fondo la IA de Secureframe? Agendar una demo para ver cómo la IA de Secureframe puede automatizar tareas manuales relacionadas con la seguridad, privacidad y cumplimiento.
¿Cómo se utiliza la IA generativa en la ciberseguridad?
La IA generativa se está utilizando para fortalecer la postura de seguridad de las organizaciones al aumentar las capacidades de los equipos de seguridad para detectar, analizar y responder a las amenazas de manera más rápida y eficiente y al automatizar tareas rutinarias como la elaboración de informes de respuesta a incidentes. La IA generativa también está siendo utilizada por ciberdelincuentes para aprovecharse de ataques cibernéticos más sofisticados y frecuentes, como llamadas de video falsas (deepfake).
¿Qué es la IA generativa y un ejemplo?
La IA generativa es un tipo de IA que utiliza modelos o algoritmos de aprendizaje profundo para crear automáticamente textos, fotos, videos, código y otros resultados basados en los conjuntos de datos en los que se entrenan. El ejemplo más conocido es ChatGPT, un modelo de lenguaje impulsado por IA desarrollado por OpenAI.
¿Puede la ciberseguridad ser automatizada por IA generativa?
Partes de la ciberseguridad pueden ser automatizadas por la IA generativa, incluyendo la detección de amenazas, el análisis y la respuesta; sin embargo, no puede reemplazar completamente a los expertos humanos. Por ejemplo, aunque las herramientas de IA generativa pueden identificar patrones de ataque conocidos y predecir nuevos, los analistas humanos pueden confirmar amenazas reales de falsos positivos basándose en su comprensión más profunda y contextual de los sistemas, redes y el entorno operativo único de su organización.
  Spain / Español 