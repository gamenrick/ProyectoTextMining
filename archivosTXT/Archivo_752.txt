Yoshua Bengio, padre del "deep learning", advierte que la IA puede hacernos "perder el control humano"
Autor desconocido
biobiochile.cl


                                        Ingresa tu rut o nombre completo y conoce si tus documentos extraviados están en
                                        nuestros estudios.
                                    

                                        Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem
                                        Ipsum.
                                    

                                        Escucha las 8 estaciones de Radio Bío Bío con su aplicación oficial.
                                    

                                            Ingresa tu rut o nombre completo y conoce si tus documentos extraviados
                                            están en nuestros estudios.
                                        

                                            Lorem Ipsum is simply dummy text of the printing and typesetting industry.
                                            Lorem Ipsum.
                                        

                                            Escucha las 8 estaciones de Radio Bío Bío con su aplicación oficial.
                                        
Certifico que es información real y autorizo a Bio Bio para publicarla de la forma Que estime conveniente, manteniendo la confidencialidad de mis datos si asi lo deseo

        
            por
        
        
            Sara Jerez
        

El informático canadiense Yoshua Bengio, uno de los padres del \'deep learning\', ha reconocido la existencia de riesgos reales en la inteligencia artificial (IA) y asume su responsabilidad en mitigar los impactos negativos que pueda generar esta tecnología. Bengio aboga por detener temporalmente el avance de la IA para implementar políticas que controlen su uso, advirtiendo sobre posibles consecuencias catastróficas a medida que avance la superinteligencia.  
Yoshua Bengio, el informático canadiense considerado uno de los padres del ‘deep learning’ o el aprendizaje profundo, dice que los riesgos de la inteligencia artificial (IA) no son ficticios y admitió que se siente responsable de mitigar los impactos negativos de esta tecnología.
Recordemos que el deep learning es una técnica esencial en la IA, que se utiliza para “entrenar” a las computadoras para que puedan procesar datos de una manera similar a como lo hace el cerebro humano.
Bengio, tuvo un importante papel en el desarrollo de estas redes neuronales artificiales, pero ahora está haciendo pidiendo que se detenga temporalmente su avance para implementar políticas que limiten y fiscalicen el uso de la IA. 
En entrevista con Live Science abordó algunas de sus preocupaciones. “Es difícil ir en contra de tu propia iglesia, pero si piensas racionalmente sobre las cosas, no hay forma de negar la posibilidad de resultados catastróficos cuando alcancemos cierto nivel de IA. La razón por la que cambié de postura es porque antes de ese momento, entendí que hay escenarios que son malos, pero pensé que lo resolveríamos”, planteó.
En la instancia, fue consultado sobre su responsabilidad con el rápido avance de la IA y los riesgos que esto significa. Bengio dijo que sí se siente responsable: “lo hago, siento que tengo el deber de hablar porque mi voz tiene algún impacto debido al reconocimiento que obtuve por mi trabajo científico, y por eso siento que debo alzar la voz”.
A raíz del deep learning surgió también el llamado ‘automatic learning’, o aprendizaje automático, este implica que un sistema aprenda y mejore de manera autónoma, es decir, por sí mismo.
Sobre este concepto, el experto advirtió que “la gente siempre dice que estos riesgos son ciencia ficción, pero no lo son. A corto plazo, ya vemos que se está utilizando la IA en la campaña electoral de Estados Unidos, y la cosa va a empeorar mucho. Un estudio reciente demostró que ChatGPT-4 es mucho mejor que los humanos en la persuasión, y eso es solo ChatGPT-4: la nueva versión va a ser peor”.
“Si miramos más adelante, cuando alcancemos el nivel de superinteligencia, habrá dos riesgos importantes. El primero es la pérdida del control humano: si las máquinas superinteligentes tienen un objetivo de autoconservación, su objetivo podría ser destruir a la humanidad para que no podamos apagarlas“, planteó.
Pero no solo la IA por sí sola puede ser un problema, dijo el informático, los humanos, como ya se ha visto, también pueden darle un mal uso. “El otro peligro, si el primer escenario no se concreta, es que los humanos utilicen el poder de la IA para tomar el control de la humanidad en una dictadura mundial. Puede haber versiones más suaves de eso y puede existir en un espectro, pero la tecnología le dará un enorme poder a quien la controle”, sugirió.
Bengio puntualiza que, eso puede evitarse de la mano de leyes que implementen los gobiernos para regular las IA. Y esto no solo es tarea de los países, “las empresas tienen que tener planes de seguridad, divulgar los resultados de sus pruebas y, si no siguen las normas más modernas de protección del público, podrían ser demandadas. Creo que esa es la mejor propuesta legislativa que existe”.
Síguenos en Google News:
Suscríbete en nuestro canal de whatsapp:
Ética y transparencia de BioBioChile







                Contenidos bajo licencia Creative Commons (CC-BY-NC) salvo donde indique lo contrario. | Basado en
                Sistema WordPress.
            

                Desarrollado por Bio Bio Comunicaciones 2024
                Concepción - Chile
            