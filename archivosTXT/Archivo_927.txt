Este bebé con un casco tiene la clave para entrenar la IA | MIT Technology Review en español
Autor desconocido
technologyreview.es

Una red neuronal entrenada a partir de las experiencias de un solo niño logró aprender uno de los componentes centrales del lenguaje: cómo relacionar las palabras con los objetos que representa
Los bebés humanos aprenden mucho mejor que los mejores y mayores modelos de lenguaje de inteligencia artificial (IA). Para poder escribir en un inglés aceptable, ChatGPT tuvo que entrenarse con conjuntos de datos masivos que contienen millones o incluso un billón de palabras. Los niños, por otro lado, tienen acceso sólo a una pequeña fracción de esos datos, pero a los tres años se comunican de manera bastante sofisticada.
Un equipo de investigadores de la Universidad de Nueva York se preguntó si la IA podría aprender como un bebé. ¿Qué podría hacer un modelo de IA si se le diera un conjunto de datos mucho más pequeño: las imágenes y los sonidos experimentados por un solo niño que aprende a hablar?
Resulta que mucho. El modelo de IA logró relacionar palabras con los objetos que representan. "Hay suficientes datos incluso en este fase de la experiencia del niño como para que pueda aprender palabras genuinamente", dice Brenden Lake, científico cognitivo computacional de la Universidad de Nueva York y autor del estudio. Este trabajo, publicado en Science , no solo proporciona información sobre cómo aprenden los bebés, sino que también podría conducir a mejores modelos de IA.
Para este experimento, los investigadores se basaron en 61 horas de vídeo de un casco con cámara usado por un niño de Adelaida, Australia. Ese niño, Sam, usó la cámara de vez en cuando durante un año y medio, desde que tenía seis meses hasta poco después de su segundo cumpleaños. La cámara capturó las cosas que Sam miraba y a las que prestaba atención durante aproximadamente el 1% de sus horas de vigilia. Grabó a los dos gatos de Sam, sus padres, su cuna y sus juguetes, su casa, sus comidas y mucho más. "Este conjunto de datos era totalmente único", dice Lake. "Es la mejor ventana que hemos tenido sobre a qué tiene acceso un solo niño".
Para entrenar el modelo, Lake y sus colegas utilizaron 600.000 fotogramas de vídeo combinados con las frases pronunciadas por los padres de Sam u otras personas en la habitación cuando se capturó la imagen: 37.500 "expresiones" en total. A veces las palabras y los objetos coincidían. A veces no lo hacían. Por ejemplo, en una fotografía, Sam mira un rompecabezas de formas y uno de sus padres dice: “¿te gusta la cuerda?”. En otro, la mano de un adulto agarra algunos bloques y uno de los progenitores dice “¡tú también quieres los bloques!”.
 
El equipo le dio al modelo dos pistas. Cuando los objetos y las palabras aparecen juntos, es una señal de que podrían estar vinculados. Pero cuando un objeto y una palabra no aparecen juntos, es una señal de que probablemente no coincidan. “Es el tipo de unión y separación que ocurre dentro del modelo. La esperanza es que haya suficientes casos en los datos en los que cuando el padre dice la palabra 'pelota', el niño esté viendo una pelota”, explica Wai Keen Vong, científico cognitivo computacional de la Universidad de Nueva York y autor del estudio.
Relacionar palabras con los objetos que representan puede parecer una tarea sencilla, pero no lo es. Para tener una idea del alcance del problema, imaginemos el salón de una familia con niños pequeños. Tiene todos los muebles normales de una sala de estar, pero también el desorden de los niños. El suelo está lleno de juguetes. Hay crayones esparcidos sobre la mesa de café, una taza de refresco en el alféizar de la ventana, ropa sucia en una silla. Si un niño pequeño escucha la palabra "pelota", podría referirse a una pelota. Pero también podría referirse a cualquier otro juguete, o al sofá, o a un pantalón, o a la forma de un objeto, o a su color, o a la hora del día. “Hay un número infinito de significados posibles para cualquier palabra”, dice Lake.
El problema es tan difícil de resolver que algunos psicólogos del desarrollo plantean que los niños deben nacer con una comprensión innata de cómo funciona el lenguaje para poder aprenderlo tan rápidamente. Pero el estudio sugiere que algunas partes del lenguaje se pueden aprender a partir de un conjunto realmente pequeño de experiencias, incluso sin esa habilidad innata, dice Jess Sullivan, psicóloga del desarrollo de la Universidad Skidmore, que formó parte del equipo que recopiló los datos de la cámara del casco de Sam, pero no involucrada en el nuevo estudio. “Eso, realmente, cambia mi visión del mundo”, añade.
Pero Sullivan señala que ser capaz de relacionar palabras con los objetos que representan, aunque sea un problema de aprendizaje difícil, es sólo una parte de lo que constituye el lenguaje. También existen reglas que rigen cómo se unen las palabras. Es posible que su perro conozca las palabras “pelota” o “caminar”, pero eso no significa que pueda entender inglés. Y podría ser que cualquier capacidad innata para el lenguaje que posean los bebés vaya más allá del vocabulario. Podría influir en cómo se mueven por el mundo, a qué prestan atención o cómo responden al lenguaje. “No creo que el estudio hubiera funcionado si los bebés no hubieran creado el conjunto de datos del que aprendía la red neuronal”, afirma.

El siguiente paso para Lake y sus colegas es tratar de descubrir qué necesitan para que el aprendizaje del modelo reproduzca más fielmente el aprendizaje temprano del lenguaje en los niños. “Queda trabajo por hacer para conseguir un modelo con capacidades más parecidas a las de un niño de dos años”, afirma, lo que puede significar que hagan falta más datos. El hijo de Lake, que ahora tiene 18 meses, es parte del próximo grupo de niños que proporcionará esos datos. Lleva una cámara en el casco durante unas horas a la semana. Tal vez el modelo necesita prestar atención a la mirada de los padres, o tener alguna sensación de la solidez de los objetos, algo que los niños captan intuitivamente. La creación de modelos que puedan aprender más como los niños ayudará a los investigadores a comprender mejor el aprendizaje y el desarrollo humanos.
Los modelos de IA que pueden captar algunas de las formas en que los humanos aprenden el lenguaje podrían ser mucho más eficientes en el aprendizaje; podrían actuar más como humanos y menos como “un pesado motor estadístico para la comparación de patrones”, como una vez describieron el lingüista Noam Chomsky y algunos de sus colegas los grandes modelos de lenguaje como ChatGPT. “Los sistemas de IA todavía son frágiles y carecen de sentido común”, dice Howard Shrobe, que dirige el programa de la Agencia de Proyectos de Investigación Avanzada de Defensa del gobierno de Estados Unidos que ayudó a financiar el equipo de Lake. Pero una IA que pudiera aprender como un niño podría ser capaz de comprender el significado, responder a situaciones nuevas y aprender de nuevas experiencias. El objetivo es acercar la IA un paso más a la inteligencia humana.
 
 
La inteligencia artificial y los robots están transformando nuestra forma de trabajar y nuestro estilo de vida.

 
La inteligencia artificial y los robots están transformando nuestra forma de trabajar y nuestro estilo de vida.
Un experimento en Minecraft con personajes impulsados por IA demostró que, de manera autónoma, pueden desarrollar comportamientos similares a los humanos, como hacer amigos, inventar roles laborales o incluso difundir una religión como el pastafarismo entre sus compañeros para ganar adeptos
Por Niall Firth
En un futuro cercano, la IA no solo será capaz de imitar nuestra personalidad, sino también de actuar en nuestro nombre para llevar a cabo tareas humanas. Sin embargo, esto da lugar a nuevos dilemas éticos que aún deben ser resueltos
Por James O'Donnell
Los benchmarks, diseñados para evaluar el rendimiento de una IA, a menudo están basados en criterios opacos o en parámetros que no reflejan su impacto real. No obstante, hay enfoques que buscan ofrecer evaluaciones más precisas y alineadas con desafíos prácticos
Por Scott J Mulligan

Más información sobre Inteligencia Artificial

Síguenos
Copyright © MIT Technology Review, 2017-2024.