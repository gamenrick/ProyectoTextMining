¿Qué es el machine learning (ML)? | IBM
Autor desconocido
ibm.com

Dado que el deep learning y el machine learning tienden a utilizarse indistintamente, conviene señalar los matices entre ambos. El machine learning, el deep learning y las redes neuronales son subcampos de la inteligencia artificial. Sin embargo, las redes neuronales son en realidad un subcampo del machine learning, y el deep learning es un subcampo de las redes neuronales.
La forma en que el deep learning y el machine learning difieren es en cómo aprende cada algoritmo. El "deep" machine learning puede utilizar conjuntos de datos etiquetados, también conocido como aprendizaje supervisado, para informar a su algoritmo, pero no requiere necesariamente un conjunto de datos etiquetados. El proceso de deep learning puede ingerir datos no estructurados en su forma bruta (por ejemplo, texto o imágenes) y determinar automáticamente el conjunto de características que distinguen unas categorías de datos de otras. Esto elimina parte de la intervención humana necesaria y permite utilizar grandes cantidades de datos. Se puede pensar en el deep learning como un "machine learning escalable", como señala Lex Fridman en esta conferencia del MIT (enlace externo a ibm.com).
El machine learning clásico, o "no profundo", depende más de la intervención humana para aprender. Los expertos humanos determinan el conjunto de características para comprender las diferencias entre las entradas de datos, lo que suele requerir datos más estructurados para aprender.
Las redes neuronales, o redes neuronales artificiales (RNA), se componen de capas de nodos, que contienen una capa de entrada, una o más capas ocultas y una capa de salida. Cada nodo, o neurona artificial, se conecta a otro y tiene un peso y un umbral asociados. Si la salida de cualquier nodo individual está por encima del valor umbral especificado, ese nodo se activa y envía datos a la siguiente capa de la red. En caso contrario, ese nodo no transmite ningún dato a la siguiente capa de la red. El término "deep" (profundo) en deep learning se refiere al número de capas de una red neuronal. Una red neuronal que consta de más de tres capas (que incluirían la entrada y la salida) puede considerarse un algoritmo de deep learning o una red neuronal profunda. Una red neuronal que sólo tiene tres capas no es más que una red neuronal básica.
Al deep learning y las redes neuronales se les atribuye el mérito de acelerar el progreso en áreas como la computer vision, el procesamiento del lenguaje natural y el reconocimiento de voz.
Consulte la entrada del blog "IA vs. machine learning vs. deep learning vs. redes neuronales: ¿cuál es la diferencia?" para ver más de cerca cómo se relacionan los distintos conceptos.
Explore la demostración interactiva de watsonx.ai 
Descargue "Machine learning para principiantes" 
Explore Gen AI para desarrolladores
Los modelos de machine learning se dividen en tres categorías principales.
El aprendizaje supervisado, también conocido como machine learning supervisado, se define por su uso de conjuntos de datos etiquetados para entrenar algoritmos que clasifiquen datos o predigan resultados con precisión. A medida que se introducen datos de entrada en el modelo, éste ajusta sus ponderaciones hasta que se ha ajustado adecuadamente. Esto ocurre como parte del proceso de validación cruzada para garantizar que el modelo evite el sobreajuste o el infraajuste. El aprendizaje supervisado ayuda a las organizaciones a resolver una variedad de problemas del mundo real a escala, como clasificar el spam en una carpeta separada de su bandeja de entrada. Algunos métodos utilizados en el aprendizaje supervisado son las redes neuronales, el clasificador bayesiano ingenuo, la regresión lineal y logística, el bosque aleatorio y la máquina de vectores de soporte (SVM).
El aprendizaje no supervisado, también conocido como machine learning no supervisado, utiliza algoritmos de machine learning para analizar y agrupar conjuntos de datos no etiquetados (subconjuntos denominados clústeres). Estos algoritmos descubren patrones ocultos o agrupaciones de datos sin necesidad de intervención humana. La capacidad de este método para descubrir similitudes y diferencias en la información lo hace ideal para el análisis exploratorio de datos, las estrategias de venta cruzada, la segmentación de clientes y el reconocimiento de imágenes y patrones. También se utiliza para reducir el número de características de un modelo mediante el proceso de reducción de la dimensionalidad. El análisis de componentes principales (PCA) y la descomposición en valores singulares (DVE) son dos métodos habituales para ello. Otros algoritmos utilizados en el aprendizaje no supervisado son las redes neuronales, el k-medias y los métodos de agrupación probabilística.
El aprendizaje semisupervisado ofrece un término medio entre el aprendizaje supervisado y el no supervisado. Durante el entrenamiento, utiliza un conjunto de datos etiquetados más pequeño para guiar la clasificación y la extracción de características a partir de un conjunto de datos más grande sin etiquetar. El aprendizaje semisupervisado puede resolver el problema de no disponer de suficientes datos etiquetados para un algoritmo de aprendizaje supervisado. También ayuda si etiquetar los datos suficientes resulta demasiado costoso. 
Para profundizar en las diferencias entre estos enfoques, consulte "Aprendizaje supervisado vs. aprendizaje no supervisado: ¿Cuál es la diferencia?"
El aprendizaje por refuerzo es un modelo de machine learning similar al aprendizaje supervisado, pero el algoritmo no se entrena con datos de ejemplo. Este modelo aprende sobre la marcha mediante el método de ensayo y error. A sequence of successful outcomes will be reinforced to develop the best recommendation or policy for a given problem.
El sistema IBM Watson que ganó el desafío  Jeopardy! en 2011 es un buen ejemplo. El sistema utilizaba el aprendizaje por refuerzo para aprender cuándo intentar responder (o preguntar, por así decirlo), qué casilla seleccionar en el tablero y cuánto apostar, especialmente en los dobles diarios.
Más información sobre el aprendizaje por refuerzo      
Se suelen utilizar varios algoritmos de machine learning. Entre ellos se incluyen:
Dependiendo de su presupuesto, necesidad de velocidad y precisión requerida, cada tipo de algoritmo (supervisado, no supervisado, semisupervisado o por refuerzo) tiene sus propias ventajas e inconvenientes. Por ejemplo, los algoritmos de árboles de decisión se utilizan tanto para predecir valores numéricos (problemas de regresión) como para clasificar datos en categorías. Los árboles de decisión utilizan una secuencia ramificada de decisiones vinculadas que pueden representarse con un diagrama de árbol. Una ventaja primordial de los árboles de decisión es que son más fáciles de validar y auditar que una red neuronal. La mala noticia es que pueden ser más inestables que otros predictores de decisiones. 

En general, el machine learning ofrece muchas ventajas que las empresas pueden aprovechar para obtener nuevas eficiencias. Entre ellas se incluye el machine learning para identificar patrones y tendencias en volúmenes masivos de datos que los humanos podrían no detectar en absoluto. Y este análisis requiere poca intervención humana: basta con introducir el conjunto de datos de interés y dejar que el sistema de machine learning elabore y perfeccione sus propios algoritmos, que mejorarán continuamente con la introducción de más datos a lo largo del tiempo. Los clientes y usuarios pueden disfrutar de una experiencia más personalizada, ya que el modelo aprende más con cada experiencia con esa persona.

La desventaja es que el machine learning requiere grandes conjuntos de datos de entrenamiento que sean precisos e imparciales. GIGO es el factor operativo: basura entra, basura sale (garbage in, garbage out). Recopilar datos suficientes y disponer de un sistema lo bastante sólido para ejecutarlos también puede suponer una merma de recursos. El machine learning también puede ser propenso a errores, dependiendo de los datos de entrada. Con una muestra demasiado pequeña, el sistema podría producir un algoritmo perfectamente lógico pero completamente erróneo o engañoso. Para evitar malgastar el presupuesto o disgustar a los clientes, las organizaciones deben actuar en función de las respuestas sólo cuando exista una gran confianza en el resultado.
He aquí algunos ejemplos de machine learning que puede encontrar en su día a día:
Reconocimiento de voz: También se conoce como reconocimiento automático de voz (ASR), reconocimiento informático de voz o conversión de voz a texto (speech to text), y es una capacidad que utiliza el procesamiento del lenguaje natural (PLN) para traducir el habla humana a un formato escrito. Muchos dispositivos móviles incorporan el reconocimiento de voz en sus sistemas para realizar búsquedas por voz, por ejemplo, Siri, o cómo mejorar la accesibilidad de los mensajes de texto.
Servicios de atención al cliente:  Los chatbots en línea eestán reemplazando a los agentes humanos a lo largo del recorrido del cliente, cambiando la forma en que pensamos acerca del compromiso con el cliente a través de sitios web y plataformas de medios sociales. Los chatbots responden a las preguntas más frecuentes (FAQ) sobre temas como los envíos, o proporcionan asesoramiento personalizado, realizando ventas cruzadas de productos o sugiriendo tallas para los usuarios. Algunos ejemplos son los agentes virtuales de los sitios de comercio electrónico; los bots de mensajería, que utilizan Slack y Facebook Messenger; y las tareas que suelen realizar los asistentes virtuales y de voz.
Computer vision : esta tecnología de IA permite a los ordenadores obtener información significativa a partir de imágenes digitales, vídeos y otras entradas visuales y, a continuación, tomar las medidas adecuadas. Gracias a las redes neuronales convolucionales, la computer vision tiene aplicaciones en el etiquetado de fotos en las redes sociales, la obtención de imágenes radiológicas en la sanidad y los coches autónomos en la industria de la automoción. 
Motores de recomendación: utilizando datos de comportamientos de consumo anteriores, los algoritmos de IA pueden ayudar a descubrir tendencias de datos que pueden utilizarse para desarrollar estrategias de venta cruzada más eficaces. Los motores de recomendación los utilizan los minoristas en línea para hacer recomendaciones de productos relevantes a los clientes durante el proceso de pago.

Automatización de procesos robóticos (RPA): también conocida como robótica de software, la RPA utiliza tecnologías de automatización inteligente para realizar tareas manuales repetitivas.
Negociación bursátil automatizada: Diseñada para optimizar las carteras de valores, las plataformas de negociación de alta frecuencia impulsadas por IA realizan miles o incluso millones de operaciones al día sin intervención humana.
Detección del fraude: los bancos y otras instituciones financieras pueden utilizar el machine learning para detectar transacciones sospechosas. El aprendizaje supervisado puede entrenar un modelo utilizando información sobre transacciones fraudulentas conocidas. La detección de anomalías puede identificar transacciones que parecen atípicas y merecen una investigación más profunda.
El desarrollo de la tecnología de machine learning nos ha facilitado la vida. Sin embargo, la implementación del machine learning en las empresas también ha suscitado una serie de preocupaciones éticas sobre las tecnologías de IA, entre las que se incluyen:
Aunque este tema suscita mucha atención pública, a muchos investigadores no les preocupa la idea de que la IA supere a la inteligencia humana en un futuro próximo. La singularidad tecnológica también se conoce como IA sólida o superinteligencia. El filósofo Nick Bostrum define la superinteligencia como "cualquier intelecto que supere ampliamente a los mejores cerebros humanos en prácticamente todos los campos, incluida la creatividad científica, la sabiduría general y las habilidades sociales". A pesar de que la superinteligencia no es inminente en la sociedad, su idea plantea algunas cuestiones interesantes al considerar el uso de sistemas autónomos, como los coches autoconducidos. Es poco realista pensar que un coche sin conductor nunca tendrá un accidente, pero ¿quién es el responsable en esas circunstancias? ¿Debemos seguir desarrollando vehículos autónomos o limitar esta tecnología a vehículos semiautónomos que ayuden a las personas a conducir con seguridad? El jurado aún no se ha pronunciado al respecto, pero estos son los tipos de debates éticos que se producen a medida que se desarrolla la nueva e innovadora tecnología de IA.
Aunque gran parte de la percepción pública de la inteligencia artificial se centra en la pérdida de puestos de trabajo, esta preocupación debería replantearse. Con cada nueva tecnología disruptiva, vemos que cambia la demanda del mercado de funciones laborales específicas. Por ejemplo, si nos fijamos en la industria de la automoción, muchos fabricantes, como GM, están pasando a centrarse en la producción de vehículos eléctricos para alinearse con las iniciativas ecológicas. El sector energético no va a desaparecer, pero la fuente de energía está desplazándose de la economía de combustible a la eléctrica.
De forma similar, la inteligencia artificial desplazará la demanda de puestos de trabajo a otras áreas. Harán falta personas que ayuden a gestionar los sistemas de IA. Seguirá siendo necesario contar con personas que se ocupen de problemas más complejos en los sectores con más probabilidades de verse afectados por los cambios en la demanda de empleo, como el servicio de atención al cliente. El mayor reto de la inteligencia artificial y su efecto en el mercado laboral será ayudar a las personas a hacer la transición a las nuevas funciones que se demandan.
La privacidad tiende a debatirse en el contexto de la privacidad, la protección y la seguridad de los datos. Estas preocupaciones han permitido a los responsables políticos avanzar más en los últimos años. Por ejemplo, en 2016 se creó la legislación RGPD para proteger los datos personales de las personas en la Unión Europea y el Espacio Económico Europeo, dando a los individuos más control sobre sus datos. En Estados Unidos, los estados individuales están desarrollando políticas, como la Ley de Privacidad del Consumidor de California (CCPA), que se introdujo en 2018 y exige a las empresas que informen a los consumidores sobre la recopilación de sus datos. Este tipo de legislación ha obligado a las empresas a replantearse cómo almacenan y utilizan la información de identificación personal (PII, por sus siglas en inglés). Como resultado, las inversiones en seguridad se han convertido en una prioridad cada vez mayor para las empresas, que tratan de eliminar cualquier vulnerabilidad y oportunidad de vigilancia, piratería informática y ciberataques.
Los casos de sesgo y discriminación en una serie de sistemas de machine learning han planteado muchas cuestiones éticas sobre el uso de la inteligencia artificial. ¿Cómo podemos protegernos contra el sesgo y la discriminación cuando los propios datos de formación pueden ser generados por procesos humanos sesgados? Aunque las empresas suelen tener buenas intenciones en sus esfuerzos de automatización, Reuters (enlace externo a ibm.com) destaca algunas de las consecuencias imprevistas de incorporar la IA a las prácticas de contratación. En su esfuerzo por automatizar y simplificar un proceso, Amazon discriminó involuntariamente a los candidatos por género para puestos técnicos, y la empresa tuvo que desechar finalmente el proyecto. Harvard Business Review (enlace externo a ibm.com) ha planteado otras cuestiones puntuales sobre el uso de la IA en las prácticas de contratación, como qué datos debería poder utilizar a la hora de evaluar a un candidato para un puesto.
El sesgo y la discriminación tampoco se limitan a la función de recursos humanos; pueden encontrarse en diversas aplicaciones, desde el software de reconocimiento facial hasta los algoritmos de las redes sociales.
A medida que las empresas son más conscientes de los riesgos de la IA, también se han vuelto más activas en este debate sobre la ética y los valores de la IA. Por ejemplo, IBM ha puesto al descubierto sus productos de reconocimiento y análisis facial de uso general. El CEO de IBM, Arvind Krishna, escribió: "IBM se opone firmemente y no aprobará el uso de ninguna tecnología, incluida la tecnología de reconocimiento facial ofrecida por otros proveedores, para la vigilancia masiva, la elaboración de perfiles raciales, la violación de los derechos humanos y las libertades fundamentales, o cualquier otro fin que no sea coherente con nuestros valores y Principios de Confianza y Transparencia."
Dado que no existe una legislación significativa que regule las prácticas de la IA, no hay ningún mecanismo de aplicación real que garantice que se practica una IA ética. Los incentivos actuales para que las empresas sean éticas son las repercusiones negativas de un sistema de IA poco ético en el balance final. Para colmar esta laguna, han surgido marcos éticos como parte de una colaboración entre especialistas en ética e investigadores para regir la construcción y distribución de modelos de IA en la sociedad. Sin embargo, de momento sOlo sirven para orientar. Algunas investigaciones (enlaces externos a ibm.com) demuestran que la combinación de responsabilidad distribuida y falta de previsión de las posibles consecuencias no favorece la prevención de daños a la sociedad.
Más información sobre la postura de IBM ante la ética de la IA
Seleccionar una plataforma puede ser un proceso difícil, ya que un sistema equivocado puede disparar los costes o limitar el uso de otras herramientas o tecnologías valiosas. Cuando se examinan varios proveedores para seleccionar una plataforma de IA, a menudo se tiende a pensar que más funciones = mejor sistema. Puede que sí, pero los revisores deberían empezar por pensar qué hará la plataforma de IA por su organización. ¿Qué capacidades de machine learning hay que ofrecer y qué características son importantes para conseguirlas? Una característica que falte puede condenar la utilidad de todo un sistema. Estas son algunas características a tener en cuenta.
Reimagine su forma de trabajar con la IA: nuestro variado equipo global de más de 20 000 expertos en IA puede ayudarle a diseñar y escalar la IA y la automatización en su empresa con rapidez y confianza, trabajando con nuestra propia tecnología IBM watsonx y un ecosistema abierto de socios para ofrecer cualquier modelo de IA, en cualquier nube, guiado por la ética y la confianza.

Haga operativa la IA en toda su empresa para obtener beneficios de forma rápida y ética. Nuestra amplia cartera de productos de IA y soluciones analíticas de nivel empresarial está diseñada para reducir los obstáculos de la adopción de la IA y establecer la base de datos adecuada, al tiempo que se optimizan los resultados y el uso responsable.
Multiplique el poder de la IA con nuestra plataforma de IA y datos de última generación. IBM watsonx es una cartera de herramientas, aplicaciones y soluciones listas para el negocio, diseñadas para reducir los costos y los obstáculos de la adopción de la IA, al tiempo que optimiza los resultados y el uso responsable de la IA.
Aprenda los conceptos fundamentales de la IA y la IA generativa, incluida la ingeniería de avisos, los grandes modelos lingüísticos y los mejores proyectos de código abierto.
La tecnología de IA ha evolucionado rápidamente en las últimas dos décadas. Conozca cómo las empresas están implementando la IA en la actualidad.
Conozca las herramientas que utilizan las empresas para ejecutar y gestionar de forma eficiente los modelos de IA y capacitar a sus científicos de datos con tecnología que puede ayudar a optimizar su toma de decisiones basada en datos. 
Explore cómo los proyectos de aprendizaje automático le ayudan a aprender continuamente de los datos y predecir el futuro.
IBM reconocida de nuevo como líder en el Magic Quadrant™ de Gartner 2023™ para IA conversacional empresarial.
Explore las ideas en las que se basan los modelos de ML y algunos algoritmos clave utilizados para cada uno de ellos.
Entrene, valide, ajuste e implemente IA generativa, modelos fundacionales y capacidades de machine learning con IBM watsonx.ai, un estudio empresarial de próxima generación para constructores de IA. Cree aplicaciones de IA en menos tiempo y con menos datos.