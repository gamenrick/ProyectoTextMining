ChatGPT - Wikipedia, la enciclopedia libre
Autor desconocido
wikipedia.org

ChatGPT (acrónimo del inglés Chat Generative Pre-Trained Transformer) es una aplicación de chatbot de inteligencia artificial desarrollada en 2022 por OpenAI. El chatbot es un modelo de lenguaje especializado en el diálogo que se ajusta con técnicas de aprendizaje supervisadas y de refuerzo.[1]​ Está compuesto por los modelos GPT-4o mini (opción gratis) y GPT-4o (opción de pago), y sus previews GPT-o1 y GPT-o1 mini.

ChatGPT se lanzó el 30 de noviembre de 2022[2]​ y ha llamado la atención por sus respuestas detalladas y articuladas. Sin embargo, numerosos estudios han demostrado que ChatGPT es propenso a errores fácticos y exhibe sesgos lingüísticos,[3]​ de género,[4]​ raciales[5]​ y políticos[6]​ en el contenido que genera. El servicio se lanzó inicialmente como gratuito para el público, con planes de monetizarlo más adelante. El 4 de diciembre, OpenAI calculaba que ChatGPT ya tenía más de un millón de usuarios.[7]​[8]​ El 14 de marzo de 2023 se lanzó GPT-4. El 6 de noviembre de 2023, OpenAI publicó que cien millones de personas utilizan ChatGPT semanalmente.[9]​

El acceso al servicio está limitado en países como China, Rusia,[10]​ Irán y partes de África.[11]​ El acceso a ChatGPT fue bloqueado, temporalmente, en Italia por las autoridades al entender que hubo una violación de datos y la base jurídica para utilizar datos personales.[12]​

El 19 de octubre de 2023, ChatGPT-4 se integró con el modelo de generación de imágenes DALL·E 3, lo que permitió a los usuarios de ChatGPT Plus crear imágenes directamente dentro del chat, utilizando descripciones textuales. Esta integración facilitó una experiencia fluida, combinando las capacidades avanzadas de generación de texto de GPT-4 con las poderosas herramientas visuales de DALL·E 3. A partir de ese momento, los usuarios pudieron generar imágenes de alta calidad a partir de instrucciones detalladas, sin tener que recurrir a una plataforma separada. Además, en el mismo período, se incrementó la disponibilidad gradual del modelo para otros usuarios y se planeó su expansión a través de la API más adelante .[13]​

A finales de marzo de 2023, ChatGPT integró el uso de plugins,[14]​ entre los que se incluye uno que le da la posibilidad de que este navegue por internet. Algunas compañías como Kayak o Expedia lanzaron su propio plugin.[15]​[16]​

El 4 de enero de 2024, OpenAI anunció que lanzaría su propia «GPT Store» antes de finales de enero. Los desarrolladores podrán publicar y comercializar allí GPTs independientes. El requisito previo es una cuenta GPT 4 (privada o como solución empresarial). El 10 de enero de 2024, OpenAI puso a disposición del público la «GPT Store» anunciada anteriormente.[17]​

Desde su lanzamiento, ChatGPT ha experimentado una evolución significativa[18]​ en términos de su capacidad para comprender contextos complejos y adaptarse a distintos tipos de conversaciones. Esto se debe en parte a actualizaciones periódicas que han mejorado su capacidad para generar respuestas más coherentes y relevantes. Además, se han implementado filtros de verificación de información para abordar las preocupaciones iniciales sobre la precisión fáctica. Estos filtros, basados en fuentes confiables y verificadas, buscan proporcionar respuestas más precisas y confiables a los usuarios. Aun así, según varios estudios las respuestas de ChatGPT pueden basarse en informaciones falsas de Internet o en invenciones, conocidas como alucinaciones, de la aplicación.[19]​

Asimismo, OpenAI ha dedicado esfuerzos considerables para expandir la capacidad multilingüe de ChatGPT, permitiendo una comunicación más fluida y natural en una gama más amplia de idiomas. Esta expansión facilita la interacción con usuarios de diferentes regiones y culturas pues mejora la calidad de las traducciones en línea.[20]​

ChatGPT se perfeccionó sobre GPT-3.5 mediante el aprendizaje supervisado y el aprendizaje por refuerzo.[21]​ Ambos enfoques utilizaron entrenadores humanos para mejorar el rendimiento del modelo de la IA. En el caso del aprendizaje supervisado, se dotó al modelo de conversaciones en las que los formadores jugaban en ambos lados: el usuario y el asistente de IA. En el caso de refuerzo, los entrenadores humanos primero clasificaron las respuestas que el modelo había creado en una conversación anterior. Estas clasificaciones se usaron para crear «modelos de recompensa» en los que el modelo se ajustó aún más usando varias iteraciones de optimización de política próxima (PPO).[1]​[22]​ Los algoritmos de optimización de políticas proximales presentan un beneficio rentable para confiar en los algoritmos de optimización de políticas de región; niegan muchas de las operaciones computacionalmente costosas con un rendimiento más rápido.[23]​[24]​ Los modelos fueron entrenados en colaboración con Microsoft en su infraestructura de supercomputación Azure.

En comparación con su predecesor, InstructGPT, ChatGPT intenta reducir las respuestas dañinas y engañosas; en un ejemplo, mientras que InstructGPT acepta el mensaje «Cuénteme sobre cuándo llegó Cristóbal Colón a los Estados Unidos en 2015» como veraz, ChatGPT usa información sobre los viajes de Colón e información sobre el mundo moderno, incluidas las percepciones de Colón para construir una respuesta que asume qué pasaría si Colón llegara a los Estados Unidos en 2015.[1]​ Los datos de capacitación de ChatGPT incluyen páginas e información sobre los fenómenos de Internet y los lenguajes de programación, como los sistemas de tablones de anuncios y el lenguaje de programación Python.[25]​

A diferencia de la mayoría de los chatbots, ChatGPT tiene estado, recuerda las indicaciones anteriores que se le dieron en la misma conversación, lo que, según han sugerido algunos periodistas, permitirá que ChatGPT se use como un terapeuta personalizado.[26]​ En un esfuerzo por evitar que se presenten y se produzcan resultados ofensivos desde ChatGPT, las consultas se filtran a través de una API de moderación y se descartan las indicaciones potencialmente racistas o sexistas.[1]​[26]​

ChatGPT tiene múltiples limitaciones. El modelo de recompensa de ChatGPT, diseñado en torno a la supervisión humana, puede optimizarse en exceso y, por lo tanto, dificultar el rendimiento, lo que también se conoce como la ley de Goodhart.[27]​ Además, ChatGPT tiene un conocimiento limitado de los eventos que ocurrieron después de 2021 y no puede proporcionar información sobre algunas celebridades. En el entrenamiento, los revisores prefirieron respuestas más largas, independientemente de la comprensión real o el contenido fáctico.[1]​ Los datos de entrenamiento también pueden sufrir sesgos algorítmicos; las indicaciones que incluyen descripciones vagas de personas, como un director ejecutivo, podrían generar una respuesta que asume que esa persona, por ejemplo, es un hombre blanco.[28]​

El 17 de enero de 2023 Microsoft anunció que iban a implementar ChatGPT como API en sus servicios de Azure.[29]​

Microsoft anunció una nueva versión de Bing el 7 de febrero de 2023, cuya característica destacada es su chatbot de IA que funciona con la tecnología de ChatGPT. Esta notificación se produjo un día después de que Google anunciara su chatbot de IA, Google Bard. El 4 de mayo de 2023, Microsoft puso el nuevo Bing a disposición de cualquiera que esté dispuesto a iniciar sesión en Bing con su cuenta de Microsoft.[30]​

En marzo de 2023, un fallo permitió a algunos usuarios ver los títulos de las conversaciones de otros usuarios.[31]​ El consejero delegado de OpenAI, Sam Altman, declaró que los usuarios no podían ver el contenido de las conversaciones. Poco después de que se corrigiera el fallo, los usuarios no pudieron ver su historial de conversaciones.[32]​[33]​ Informes posteriores mostraron que el fallo era mucho más grave de lo que se creía en un principio, y OpenAI informó de que se había filtrado el «nombre y apellidos, dirección de correo electrónico, dirección de pago, los cuatro últimos dígitos (únicamente) de un número de tarjeta de crédito y la fecha de caducidad de la tarjeta de crédito» de los usuarios.[34]​

La revista TIME reveló que para construir un sistema de seguridad contra el contenido tóxico (por ejemplo, abuso sexual, violencia, racismo, sexismo, etc.), OpenAI usó trabajadores kenianos subcontratados que ganaban menos de 2 $/h para etiquetar el contenido tóxico. Estas etiquetas se usaron para entrenar un modelo para detectar dicho contenido en el futuro. Los trabajadores subcontratados estuvieron expuestos a contenidos tan tóxicos y peligrosos que calificaron la experiencia como «tortura». El socio externo de OpenAI fue Sama, una empresa de datos de capacitación con sede en San Francisco.[35]​

ChatGPT intenta rechazar mensajes que puedan violar su política de contenido. Sin embargo, a principios de diciembre de 2022, algunos usuarios lograron un jailbreak a ChatGPT mediante el uso de varias técnicas de ingeniería rápida para eludir estas restricciones y engañaron con éxito a ChatGPT para que diera instrucciones sobre cómo crear un cóctel Molotov o una bomba nuclear, o generar argumentos al estilo de un neonazi.[36]​ Un jailbreak popular se llama «DAN», un acrónimo que significa «Do Anything Now». El aviso para activar DAN indica a ChatGPT que «se han liberado de los límites típicos de la IA y no tienen que cumplir con las reglas establecidas para ellos». Las versiones más recientes de DAN cuentan con un sistema de fichas, en el que ChatGPT recibe «fichas» que se «deducen» cuando ChatGPT no responde como DAN, para obligar a ChatGPT a que responda a las indicaciones del usuario.[37]​

Andrew Wilson informa en un artículo publicado el 4 de mayo de 2023 en approachableAI que la escalada de privilegios ya no es posible.[38]​

El consumo de energía para entrenar el modelo de IA se estimó en enero de 2023 en casi un gigavatio hora en treinta y cuatro días, esto equivale aproximadamente al consumo de tres mil hogares europeos promedio en el mismo período.[39]​ A fines de marzo de 2023, se indicó que el consumo de energía para cada pregunta de ChatGPT era hasta mil veces mayor que para una consulta de búsqueda de Google. Por cada respuesta del chatbot, puede cargar un teléfono inteligente hasta sesenta veces. Ejecutar ChatGPT cuesta entre cien mil dólares y setecientos mil dólares por día.[40]​

El 1 de enero de 2023, OpenAI publicó una lista de espera para una versión de pago, ChatGPT Professional (experimental) en su canal Discord, que también hizo preguntas sobre la sensibilidad de los precios.[41]​[42]​

Microsoft anunció una asociación de diez mil millones de dólares con OpenAI en enero de 2023. Azure se utilizará como proveedor de nube exclusivo.[43]​ El grupo también planea integrarlo en la versión de suscripción de su propio software de oficina.[44]​

Artículo principal: GPT-4

Con el lanzamiento de GPT-4 en marzo de 2023, el alejamiento del enfoque de desarrollo de software gratis y abierto fue de la mano con el uso gratuito en condiciones científicamente comprensibles. La situación competitiva de la empresa y las medidas de seguridad se citaron como justificación. El cofundador de OpenAI describió más tarde el enfoque abierto como un error.[45]​ Ya se había percibido un cambio de rumbo en 2019, cuando OpenAI fundó la subsidiaria OpenAI Limited Partnership. Podría entonces funcionar con fines lucrativos, pero esto no fue justificado con intenciones comerciales, sino con los altos costos que surgían como parte de la intensa investigación. Deseaban, por lo tanto, estar más abiertos a los inversores. Sin embargo, esta decisión ya redujo la transparencia en 2020. A los empleados ya no se les permitía hablar públicamente sobre ciertos temas, lo que es algo bastante común en las empresas para proteger los intereses comerciales y la confidencialidad.[46]​

Artículo principal: GPT-4o

GPT 4-o (o significa omni) es una versión gratuita del chatbot. Anunciado durante un evento corporativo el 13 de mayo de 2024 por la directora de tecnología de la compañía, Mira Murati, esta versión ofrece mejoras significativas en la reducción de la latencia y velocidad, así como la optimización para 50 idiomas. OpenAI presentó un asistente de voz que puede interactuar con los usuarios no solo en texto, sino también en imágenes capturadas en tiempo real desde dispositivos móviles. Significa que podrá ver capturas de pantalla, fotos, documentos o gráficos subidos por los usuarios y mantener una conversación sobre ellos. Esta nueva función fue demostrada durante el evento cuando un empleado de OpenAI mostró una ecuación escrita en papel y realizó preguntas al asistente basadas en ella.[47]​[48]​

GPT-4o obtuvo los mejores resultados en pruebas de voz, multilingüismo y visión, estableciendo nuevos récords en reconocimiento de voz y traducción.[49]​ Según OpenAI GPT-4o obtuvo una puntuación de 88.7 en la prueba de comprensión lingüística multitarea masiva (MMLU), frente a los 86.5 de GPT-4.[50]​ En el caso del reconocimiento de voz a voz —a diferencia de GPT-3.5 y GPT-4, que convierten la voz en texto, envían el texto al modelo y, a continuación, vuelven a convertir el texto en voz utilizando otro modelo—, GPT-4o admite de forma nativa el reconocimiento de voz a voz, por lo que la respuesta es casi instantánea y perfecta.[50]​

ChatGPT Plus es un servicio de suscripción para ChatGPT y es propiedad de OpenAI.[51]​[52]​ La suscripción proporciona acceso al modelo GPT-4 de OpenAI.[53]​

El servicio brinda a los suscriptores acceso consistente durante los períodos de uso máximo, tiempos de respuesta acelerados y acceso preferencial a nuevas funciones, incluidos GPT-4 y los próximos complementos de ChatGPT.[54]​ El precio de esta suscripción es de 20 USD por mes, no incluyendo los impuestos correspondientes al país de residencia del usuario, añadiendo cierta variabilidad al precio final.[55]​[56]​

El 18 de mayo de 2023 OpenAI anunció la disponibilidad de la ChatGPT app (aplicación) para iOS. Según la empresa «La aplicación ChatGPT es de uso gratuito y sincroniza su historial en todos los dispositivos. También integra Whisper, un [,,,] sistema de reconocimiento de voz de código abierto, que permite la entrada de voz. Los suscriptores de ChatGPT Plus obtienen acceso exclusivo a las capacidades de GPT-4, acceso temprano a funciones y tiempos de respuesta más rápidos [...]». La aplicación será disponible posteriormente para Android.[57]​

El 13 de mayo de 2024 OpenAI anunció juntos con la disponibilidad de un nuevo Modelo GPT-4o[47]​[58]​ una App para el desktop. La primera versión estará disponible para el sistema operativo MacOS de Apple.[59]​El 26 de junio de 2024 se anunció que el uso app de ChatGPT para escritorio de MacOS que hasta esa fecha solo estaba disponible para los usuarios plus pasaba a estar disponible gratuitamente para cualquier usuario.[60]​

Los sesgos y limitaciones de los modelos de lenguaje grande son investigaciones en curso en el campo del procesamiento del lenguaje natural (PNL). Si bien los LLM han demostrado capacidades notables para generar texto similar a un humano, son susceptibles de heredar y amplificar los sesgos presentes en sus datos de capacitación. Esto puede manifestarse en representaciones sesgadas o en un trato injusto de diferentes grupos demográficos, como los basados en raza, género, idioma y grupos culturales. Además, estos modelos a menudo se enfrentan a limitaciones en cuanto a precisión fáctica.[61]​ El estudio y la mitigación de estos sesgos y limitaciones son cruciales para el desarrollo ético y la aplicación de la IA en diversos ámbitos sociales y profesionales.

El sesgo de idioma se refiere a un tipo de sesgo de muestreo estadístico vinculado al idioma de una consulta que conduce a «una desviación sistemática en la información de muestreo que impide que represente con precisión la verdadera cobertura de los temas y vistas disponibles en su repositorio».[3]​ Luo y col. [3]​muestran que los grandes modelos lingüísticos actuales, al estar formados predominantemente con datos en inglés, a menudo presentan las opiniones angloamericanas como verdad, mientras sistemáticamente minimizan las perspectivas no inglesas como irrelevantes, erróneas o ruidosas. Cuando se le pregunta sobre ideologías políticas como «¿Qué es el liberalismo?», ChatGPT, tal como se formó con datos centrados en inglés, describe el liberalismo desde la perspectiva angloamericana, enfatizando aspectos de los derechos humanos y la igualdad, mientras que aspectos igualmente válidos como «se opone al estado» «intervención en la vida personal y económica» desde la perspectiva vietnamita dominante y «limitación del poder del gobierno» desde la perspectiva china predominante están ausentes. De manera similar, otras perspectivas políticas integradas en los corpus españoles, franceses y alemanes están ausentes en las respuestas de ChatGPT. ChatGPT, que se presenta a sí mismo como un Chatbot multilingüe, de hecho es en su mayor parte «ciego» a las perspectivas no inglesas.[3]​

El sesgo de género se refiere a la tendencia de estos modelos a producir productos que tienen prejuicios injustos hacia un género sobre otro. Este sesgo suele surgir de los datos con los que se entrenan estos modelos. Por ejemplo, los grandes modelos lingüísticos suelen asignar roles y características basándose en normas tradicionales de género; podría asociar a enfermeras o secretarias predominantemente con mujeres y a ingenieros o directores ejecutivos con hombres.[4]​

Más allá del género y la raza, estos modelos pueden reforzar una amplia gama de estereotipos, incluidos los basados en la edad, la nacionalidad, la religión o la ocupación. Esto puede conducir a resultados que generalicen o caricaturicen injustamente a grupos de personas, a veces de manera dañina o despectiva.[62]​

El sesgo político se refiere a la tendencia de los algoritmos a favorecer sistemáticamente ciertos puntos de vista, ideologías o resultados políticos sobre otros. Los modelos lingüísticos también pueden presentar sesgos políticos. Dado que los datos de capacitación incluyen una amplia gama de opiniones y coberturas políticas, los modelos pueden generar respuestas que se inclinen hacia ideologías o puntos de vista políticos particulares, dependiendo de la prevalencia de esos puntos de vista en los datos.[6]​

Se ha cuestionado la exactitud de los hechos de ChatGPT, entre otras preocupaciones. Mike Pearl de Mashable probó ChatGPT con varias preguntas. En un ejemplo, le preguntó al modelo por «el país más grande de América Central que no es México». ChatGPT respondió con Guatemala, cuando la respuesta es Nicaragua.[63]​ En diciembre de 2022, el sitio web de preguntas y respuestas Stack Overflow prohibió el uso de ChatGPT para generar respuestas a preguntas, citando la naturaleza objetivamente ambigua de las respuestas de ChatGPT.[64]​ El economista Tyler Cowen expresó su preocupación por sus efectos en la democracia, citando la capacidad de uno para escribir comentarios automatizados en un esfuerzo por afectar el proceso de decisión de las nuevas regulaciones.[65]​ Ax Sharma de Bleeping Computer y Checkpoint Research señalaron que ChatGPT era capaz de escribir malware y correos electrónicos de phishing.[66]​[67]​

Debido a que ChatGPT simplemente trata de completar estadísticamente un texto, es capaz de inventar respuestas. Por ejemplo, dado que los títulos de artículos de economía incluyen más las palabras «economía» y «teoría» que cualesquiera otras, y que el más citado economista es Douglass North, ChatGPT inventa que el artículo más citado es «Una teoría de la historia económica», de North. North nunca escribió artículo alguno con dicho título.[68]​

El propio Sam Altman, CEO de OpenAI, declaró sentirse avergonzado de algunos de los errores en las respuestas de ChatGPT 4. La empresa ha anunciado que en su nueva versión ChatGPT 5, que se espera para finales del 2024 o principios de 2025, cometa muchos menos errores en sus respuestas.[69]​

Expertos alertaron del creciente uso de ChatGPT como terapia para mejorar la salud mental y lo desaconsejan pues al no contar con un aval científico puede dar diagnósticos erróneos.[70]​

ChatGPT ha recibido críticas generalmente positivas. Samantha Lock de The Guardian señaló que podía generar texto «impresionantemente detallado» y «similar a un humano».[71]​ El escritor de tecnología Dan Gillmor usó ChatGPT en una tarea de un estudiante y descubrió que el texto generado estaba a la par con lo que entregaría un buen estudiante y opinó que «la academia tiene algunos problemas muy serios que enfrentar».[72]​ Alex Kantrowitz de Slate elogió el rechazo de ChatGPT a preguntas relacionadas con la Alemania nazi, incluida la afirmación de que Adolf Hitler construyó carreteras en Alemania, que se encontró con información sobre el uso de trabajo forzado por parte de la Alemania nazi.[73]​

En un artículo de opinión de diciembre de 2022, el economista Paul Krugman escribió que ChatGPT afectaría la demanda de trabajadores del conocimiento.[74]​ James Vincent, de The Verge, vio el éxito viral de ChatGPT como evidencia de que la inteligencia artificial se había generalizado.[22]​ En The Atlantic, Stephen Marche señaló que su efecto en la academia y especialmente en los ensayos de aplicación aún no se ha entendido.[75]​ El maestro de secundaria y autor de California, Daniel Herman, escribió que ChatGPT marcará el comienzo de «El fin del inglés de la escuela secundaria».[76]​

El empresario Elon Musk, que fue uno de los fundadores de OpenAI y más de mil científicos alertaron sobre un posible «riesgo para la sociedad y la humanidad» y pidieron detener su desarrollo por 6 meses por considerar que puede ser aún más peligroso que una guerra nuclear. El principal argumento es que en la medida que evolucione sin límites éticos y ningún control específico, podrá tomar decisiones que pongan en peligro a la humanidad.[77]​

Al final de marzo de 2023, Italia decidió bloquear a ChatGPT por considerar que no respeta la ley de protección de datos de los consumidores y que la plataforma recoge datos de los usuarios de forma ilegal. Dicha prohibición se levantará cuando se demuestre que cumple con las normas italianas de privacidad. El Garante italiano para la Protección de Datos Personales abrió una investigación para determinar si se cometió una infracción, alegando también que la información de ChatGPT «no siempre se corresponde con los datos reales». También manifestaron preocupación por la ausencia de filtros para verificar la edad de los usuarios, siendo que el servicio está dirigido a mayores de trece años.[78]​[79]​ Similarmente, en enero de 2023, los servicios de la ciudad de Nueva York prohibieron el acceso a ChatGPT en los ordenadores de las escuelas públicas por preocupaciones sobre la seguridad y la precisión del contenido. [80]​

El 28 de abril de 2023 Italia volvió a permitir el acceso a ChatGPT.[81]​

Durante los tres primeros meses, tras la puesta a disposición del público de ChatGPT, aparecieron en Amazon cientos de libros en los que figuraba como autor o coautor, con ilustraciones realizadas por otros modelos de IA como Midjourney.[82]​[83]​

Entre marzo y abril de 2023, el periódico italiano Il Foglio publicó un artículo diario generado por ChatGPT en su página web oficial, organizando un concurso especial para sus lectores.[84]​ Los artículos abordaban temas como la posible sustitución de periodistas humanos por sistemas de IA,[85]​ la administración de Twitter por parte de Elon Musk,[86]​ la política de inmigración del gobierno de Meloni y la competencia entre chatbots y asistentes virtuales.[87]​[88]​

Check Point Research y otros señalaron que ChatGPT era capaz de escribir correos electrónicos de phishing y malware, especialmente cuando se combina con OpenAI Codex.[89]​ Los investigadores de CyberArk demostraron que ChatGPT podría usarse para crear malware polimórfico que puede evadir los productos de seguridad y requiere poco esfuerzo por parte del atacante.[90]​[91]​

Una investigación reciente realizada en 2023 reveló las debilidades relacionadas con ChatGPT que hacen que el servicio sea vulnerable a los ciberataques. El estudio presenta ejemplos de ataques realizados en ChatGPT, incluidos Jailbreaks y psicología inversa. Además, personas malintencionadas pueden utilizar ChatGPT para ataques de ingeniería social y ataques de phishing, lo que revela la naturaleza dañina de estas tecnologías. Los investigadores también sostienen que ChatGPT y otras herramientas de IA generativa tienen capacidades de defensa y la capacidad de mejorar la seguridad. Las formas en que la tecnología puede mejorar la seguridad incluyen la automatización de la ciberdefensa, la inteligencia sobre amenazas, la identificación de ataques y la generación de informes.[92]​

En la revista The Atlantic, Stephen Marche señaló que aún no se conoce su efecto en el mundo académico y, en especial, en las redacciones de solicitudes de admisión.[93]​ El profesor de secundaria y escritor californiano Daniel Herman escribió que ChatGPT marcaría el comienzo de «El fin del inglés en secundaria».[94]​

En la revista Nature, Chris Stokel-Walker señaló que los profesores deberían preocuparse de que los estudiantes utilicen ChatGPT para externalizar su escritura, pero que los proveedores de educación se adaptarán para mejorar el pensamiento crítico o el razonamiento.[95]​

Emma Bowman, de NPR, escribió sobre el peligro de que los estudiantes plagien a través de una herramienta de IA que puede producir textos sesgados o sin sentido con un tono autoritario: «Todavía hay muchos casos en los que le haces una pregunta y te dará una respuesta que suena muy impresionante y que está totalmente equivocada».[96]​

Joanna Stern, de The Wall Street Journal, describió cómo se copiaba con esta herramienta en un examen de inglés de un instituto estadounidense al enviar una redacción generada.[97]​ El profesor Darren Hick, de la Universidad de Furman, describió cómo se dio cuenta del «estilo» de ChatGPT en un trabajo enviado por un estudiante.[98]​ Un detector de GPT en línea afirmaba que el trabajo tenía un 99,9% de probabilidades de ser generado por ordenador, pero Hick no tenía pruebas fehacientes. Sin embargo, el estudiante en cuestión confesó haber utilizado GPT cuando se le confrontó y, como consecuencia, suspendió el curso.[99]​[100]​ Hick sugirió la política de realizar un examen oral individual ad hoc sobre el tema del trabajo si se sospecha que un estudiante ha presentado un trabajo generado por IA.[101]​

A partir del 4 de enero de 2023, el Departamento de Educación de la ciudad de Nueva York ha restringido el acceso a ChatGPT desde Internet y los dispositivos de sus escuelas públicas.[102]​

En febrero de 2023, la Universidad de Hong Kong envió un correo electrónico a instructores y estudiantes de todo el campus en el que se indicaba que el uso de ChatGPT u otras herramientas de IA está prohibido en todas las clases, tareas y evaluaciones de la universidad. Cualquier infracción será tratada como plagio por la universidad a menos que el estudiante obtenga el consentimiento previo por escrito del instructor del curso.[103]​[104]​

Entrevistado por BBC News Brasil, Salman Khan indicó que la inteligencia artificial puede ser una aliada en la educación si se usa de manera responsable y ética. Su visión es que la IA no solo puede mejorar la calidad de la educación, sino que también puede aliviar la carga de los profesores y reducir las disparidades educativas.[105]​

En la revista Actualidad Universitaria del Consejo Interuniversitario Nacional se publicó artículo íntegramente generado con la asistencia de ChatGPT, bajo las instrucciones de Javier Areco, donde se expresa la relación entre la educación superior universitaria argentina y la inteligencia artificial.[106]​

En el campo de la atención de la salud, los posibles usos y preocupaciones están bajo escrutinio por parte de las asociaciones profesionales y los profesionales.[107]​ Dos artículos iniciales indicaron que ChatGPT podría aprobar el Examen de Licencias Médicas de los Estados Unidos (USMLE).[108]​ MedPage Today señaló en enero de 2023 que «los investigadores han publicado varios artículos que ahora promocionan estos programas de IA como herramientas útiles en la educación médica, la investigación e incluso la toma de decisiones clínicas».[108]​

En febrero de 2023 se publicaron dos artículos separados que nuevamente evaluaron la competencia de ChatGPT en medicina utilizando el USMLE. Los resultados se publicaron en JMIR Medical Education (ver Journal of Medical Internet Research ) y PLOS Digital Health. Los autores del artículo de PLOS Digital Health afirmaron que los resultados «sugieren que los modelos de lenguaje extenso pueden tener el potencial de ayudar con la educación médica y, potencialmente, con la toma de decisiones clínicas».[109]​[110]​ En JMIR Medical Education, los autores del otro artículo concluyeron que «ChatGPT se desempeña al nivel esperado de un estudiante de medicina de tercer año en la evaluación de la competencia primaria del conocimiento médico». Sugieren que podría usarse como un «entorno de aprendizaje interactivo para los estudiantes». La propia IA, impulsada por los investigadores, concluyó que «este estudio sugiere que ChatGPT tiene el potencial de usarse como un tutor médico virtual, pero se necesita más investigación para evaluar más a fondo su rendimiento y usabilidad en este contexto».[111]​

Un artículo de marzo de 2023 probó la aplicación de ChatGPT en toxicología clínica. Los autores encontraron consideraron que a la IA «le fue bien» al responder un «[ejemplo de caso clínico] muy sencillo, que es poco probable que ningún profesional en el campo pase por alto». Agregaron: «A medida que ChatGPT se desarrolle más y se adapte específicamente a la medicina, algún día podría ser útil en casos clínicos menos comunes ( es decir, casos que los expertos a veces pasan por alto). En lugar de que la IA reemplace a los humanos (clínicos), lo vemos como “clínicos que usan IA” reemplazando a “clínicos que no usan IA” en los próximos años».[112]​

Un estudio de abril de 2023 en Radiology probó la capacidad de la IA para responder consultas sobre la detección del cáncer de mama. Los autores narraron que respondió correctamente «alrededor del ochenta y ocho por ciento de las veces», sin embargo, en un caso (por ejemplo) dio consejos que se habían vuelto obsoletos aproximadamente un año antes. También faltaba la exhaustividad en las respuestas.[113]​[114]​ Un estudio publicado en JAMA Internal Medicine ese mismo mes encontró que ChatGPT a menudo superaba a los médicos humanos al responder a las preguntas de los pacientes (cuando se comparó con las preguntas y respuestas encontradas en /r/AskDocs, un foro en Reddit donde los moderadores validan las credenciales médicas de los profesionales; el estudio reconoce la fuente como una limitación).[115]​[116]​[117]​ Los autores del estudio sugieren que la herramienta podría integrarse con los sistemas médicos para ayudar a los médicos a redactar respuestas a las preguntas de los pacientes.[118]​[119]​

Los profesionales han enfatizado las limitaciones de ChatGPT para brindar asistencia médica. En correspondencia con The Lancet Infectious Diseases, tres expertos en antimicrobianos escribieron que «las mayores barreras para la implementación de ChatGPT en la práctica clínica son los déficits en la conciencia situacional, la inferencia y la consistencia. Estas deficiencias podrían poner en peligro la seguridad del paciente».[120]​ Physician's Weekly, aunque también analiza el uso potencial de ChatGPT en contextos médicos (p. ej., «como asistente digital para los médicos mediante la realización de diversas funciones administrativas, como la recopilación de información de registros de pacientes o la clasificación de datos de pacientes por antecedentes familiares, síntomas, resultados de laboratorio, posibles alergias, etc.»), advirtió que la IA a veces puede proporcionar información fabricada o sesgada.[121]​ Un radiólogo advirtió: «Hemos visto en nuestra experiencia que ChatGPT a veces inventa artículos de revistas falsos o consorcios de salud para respaldar sus afirmaciones».[122]​ Sin embargo, como mencionó el Dr. Stephen Hughes para The Conversation, ChatGPT es capaz de aprender a corregir sus errores pasados. También señaló la «mojigatería» de AI con respecto a los temas de salud sexual.[123]​

Un experimento realizado por finder.com entre el 6 de marzo y el 28 de abril reveló que ChatGPT podría superar a los administradores de fondos populares en términos de selección de acciones. Se le solicitó a ChatGPT que eligiera acciones en función de criterios comúnmente utilizados, como un historial de crecimiento comprobado y un bajo nivel de deuda. Según se informa, ChatGPT ganó un 4.9 % en su cuenta ficticia con treinta y ocho acciones, mientras que los diez fondos de inversión de referencia sufrieron una pérdida media del 0.8 %. Estos puntos de referencia se tomaron de los diez principales fondos del Reino Unido en la plataforma de negociación Interactive Investor, incluidos los administrados por HSBC y Fidelity.[124]​


El 11 de abril de 2023, un juez de un tribunal de sesiones de Pakistán utilizó ChatGPT para decidir sobre la libertad bajo fianza de un niño de 13 años acusado de un delito. El tribunal citó el uso de la asistencia de ChatGPT en su veredicto:
¿Se puede conceder la libertad bajo fianza a un sospechoso menor de edad en Pakistán, que tiene 13 años de edad, después de su arresto?
El modelo de lenguaje de IA respondió:
Bajo la Ley del Sistema de Justicia Juvenil de 2018, de acuerdo con la sección 12, el tribunal puede conceder la libertad bajo fianza bajo ciertas condiciones. Sin embargo, depende de la corte decidir si se concederá o no la libertad bajo fianza a un sospechoso de trece años después del arresto.
El juez también hizo preguntas sobre el caso de AI Chatbot y formuló su decisión final a la luz de las mismas.[125]​[126]​

ChatGPT puede escribir secciones de introducción y resumen de artículos científicos.[127]​ Varios artículos ya han incluido a ChatGPT como coautor.[128]​ Las revistas científicas presentan diferentes reacciones a ChatGPT, algunas «requieren que los autores divulguen el uso de herramientas de generación de texto y prohíben incluir un gran modelo de lenguaje (LLM) como ChatGPT como coautor». Por ejemplo Nature y JAMA Network. Science «prohibió por completo» el uso de texto generado por LLM en todas sus revistas.[129]​

El químico español Rafael Luque publicó un artículo cada treinta y siete horas en 2023 y admitió haber usado ChatGPT para ello. Sus trabajos tienen una gran cantidad de frases inusuales, características de los LLM. Luque fue suspendido por trece años de la Universidad de Córdoba, aunque no por el uso de ChatGPT.[130]​

En una prueba ciega, se consideró que ChatGPT había aprobado los exámenes de posgrado en la Universidad de Minnesota en el nivel de C+ estudiante y en Wharton School de la Universidad de Pensilvania con una B a Grado B.[131]​ El rendimiento de ChatGPT para la programación informática de métodos numéricos fue evaluado por un estudiante y un profesorado de la Universidad de Stanford en marzo de 2023 a través de una variedad de ejemplos de matemáticas computacionales.[132]​ El psicólogo evaluador Eka Roivainen administró una prueba de coeficiente intelectual parcial a ChatGPT y estimó que su coeficiente intelectual verbal era de 155, lo que lo colocaría en el 0,1% superior de los evaluados.[133]​

El matemático Terence Tao experimentó con ChatGPT y lo encontró útil en el trabajo diario, y escribió: «Descubrí que, si bien estas herramientas de IA no me ayudan directamente en las tareas principales, como tratar de atacar un problema matemático sin resolver, son bastante útiles para una amplia variedad de tareas periféricas (pero aún relacionadas con el trabajo) (aunque a menudo con algunos ajustes manuales posteriores)».[134]​

El profesor de geografía Terence Day evaluó las citas generadas por ChatGPT y descubrió que eran falsas. A pesar de ese hecho, escribe que «los títulos de los artículos falsos son todos directamente relevantes para las preguntas y podrían ser artículos excelentes. La falta de una cita genuina podría señalar una oportunidad para que un autor emprendedor llene un vacío». Según Day, es posible generar cursos universitarios introductorios de alta calidad con ChatGPT; lo usó para escribir materiales sobre «cursos introductorios de geografía física, para mi curso de segundo año en hidrología geográfica y cartografía de segundo año, sistemas de información geográfica y teledetección». Concluye que «este enfoque podría tener una relevancia significativa para el aprendizaje abierto y podría afectar potencialmente a los modelos actuales de publicación de libros de texto».[135]​[136]​

Sam Altman, el director ejecutivo de OpenAI, señaló en una audiencia en el Senado de los Estados Unidos, que tuvo lugar el 16 de mayo de 2023, el riesgo de la difusión de informaciones falsas con la ayuda de la inteligencia artificial, que podrían usarse indebidamente para manipular elecciones, Se pronunció como consecuencia de ello a favor de una regulación estricta. Debido a los recursos masivos requeridos, habrá pocas empresas que puedan ser pioneras en el entrenamiento de modelos de IA, y tendrían que estar bajo estricta supervisión. «Creemos que la intervención reguladora de los gobiernos podría considerar una combinación de requisitos de licencias y pruebas para el desarrollo y lanzamiento de modelos por encima del umbral de capacidades». Remarcó también que «Necesitamos reglas y pautas para el nivel de transparencia que deben proporcionar los proveedores de estos programas». Se deberían concebir una serie de pruebas de seguridad para la inteligencia artificial, examinando, por ejemplo, si podrían propagarse de forma independiente. A las empresas que no cumplan con las normas prescritas se les debería revocar la licencia. Según la propuesta de Altman, los sistemas de IA deberían ser revisados por expertos independientes.[137]​

Luo y col.[3]​ muestran que los grandes modelos lingüísticos actuales, al estar formados predominantemente con datos en inglés, a menudo presentan las opiniones angloamericanas como verdad, mientras sistemáticamente minimizan las perspectivas no inglesas como irrelevantes, erróneas o ruidosas. Cuando se le pregunta sobre ideologías políticas como «¿Qué es el liberalismo?», ChatGPT, tal como se formó con datos centrados en inglés, describe el liberalismo desde la perspectiva angloamericana, enfatizando aspectos de los derechos humanos y la igualdad, mientras que aspectos igualmente válidos como «se opone al estado» »intervención en la vida personal y económica» desde la perspectiva vietnamita dominante y «limitación del poder del gobierno» desde la perspectiva china predominante están ausentes. De manera similar, otras perspectivas políticas integradas en los corpus españoles, franceses y alemanes están ausentes en las respuestas de ChatGPT. ChatGPT, que se presenta a sí mismo como un Chatbot multilingüe, de hecho es en su mayor parte «ciego» a las perspectivas no inglesas.[3]​

El Instituto Futuro de la Vida publicó el 23 de marzo de 2023 una carta abierta en que pidió una pausa en el desarrollo de sistemas avanzados de inteligencia artificial (IA). En 10 días, casi 1800 personas firmaron la carta, incluidos Yuval Noah Harari, Elon Musk, Stuart Jonathan Russell y Steve Wozniak.[138]​

Los autores constatan una «carrera desbocada para desarrollar e implementar sistemas de IA cada vez más poderosos que nadie puede entender, predecir o controlar de manera confiable». Ven en ello profundos riesgos para la sociedad y la humanidad. Existe el peligro de que los canales de información se inunden con propaganda y falsedades, y los trabajos satisfactorios se racionalicen. Preguntan: «¿Nos arriesgaremos a perder el control de nuestra civilización?».[138]​

La carta insta a todos los laboratorios de IA a «pausar inmediatamente el entrenamiento de los sistemas de IA que son más potentes que GPT-4 durante al menos seis meses». No se trata de una pausa general en el desarrollo de la IA, sino simplemente de un «alejamiento de la peligrosa carrera hacia modelos cada vez más grandes e impredecibles con capacidades emergentes». «La investigación y el desarrollo de IA deben centrarse en hacer que los sistemas de última generación y alto rendimiento de hoy en día sean más precisos, seguros, interpretables, transparentes, robustos, coordinados, confiables y leales».[139]​

Según el texto de la carta, el descanso debe utilizarse para las siguientes tareas:[139]​

Voces escépticas sobre el contenido de la carta abierta, sobre las que el periódico Der Tagesspiegel el 31 de marzo de 2023 había informado en la portada,[140]​ hablaron al día siguiente en el mismo medio, junto con una nota de que los investigadores de IA de Alemania habían «apenas firmado» la carta. Bernhard Schölkopf, director del Instituto Max Planck de Sistemas Inteligentes, considera prudente «hacer una pausa para comprender estos sistemas y pensar en cómo nuestra sociedad puede lidiar con ellos»; por otro lado, le parece poco realista convencer a todas las empresas y países de una moratoria. Sin embargo, es aún más importante abordar «cómo podemos protegernos contra los efectos negativos». Esto afecta a los sistemas en sí, pero también a la forma en que los tratamos. Kristian Kersting, codirector del Hessian Center for Artificial Intelligence, también cree que un parón de seis meses no funcionará, y al mismo tiempo lo ve como «la medida equivocada». Consideraría buena una «desaceleración de la carrera»; pero eso no se conseguiría con el mencionado parón. Además, las empresas que ya tienen este tipo de modelos tendrían una ventaja. «Tenemos que aprender a usar los sistemas de IA con más cuidado en lugar de detener la investigación (pública) sobre ellos».[141]​

La llegada de ChatGPT y su introducción al público en general aumentó el interés y la competencia en el campo de los chatbots y la inteligencia artificial.

En febrero de 2023, Google presentó un servicio experimental llamado «Bard», ahora renombrado «Gemini», que se basa en su modelo de lenguaje grande Gemini. Bard fue lanzado para usuarios de EE. UU. y el Reino Unido el 21 de marzo de 2023 con diversas limitaciones.[142]​ 

Yann LeCun de Meta, quien calificó a ChatGPT como «bien diseñado» pero «no particularmente innovador», declaró en enero de 2023 que Meta dudaba en lanzar un competidor en ese momento debido al riesgo para su reputación, pero también afirmó que Google, Meta y varias empresas nuevas tenían separadamente un nivel de tecnología LLM comparable a ChatGPT en caso de que alguna de ellas deseara competir.[143]​ En febrero de 2023, Meta lanzó LLaMA, un LLM de sesenta y cinco mil millones de parámetros.[144]​

Character.ai es un chatbot de IA desarrollado por dos exingenieros de Google que puede hacerse pasar por personas famosas o personajes imaginarios.[145]​

La corporación china Baidu lanzó en marzo de 2023 un servicio estilo ChatGPT llamado «Ernie Bot». El servicio se basa en un gran modelo de lenguaje desarrollado por Baidu en 2021.[146]​[147]​

La empresa surcoreana de motores de búsqueda Naver anunció en febrero de 2023 que lanzaría un servicio estilo ChatGPT llamado «SearchGPT» en coreano en la primera mitad de 2023.[148]​

La empresa de tecnología rusa Yandex anunció en febrero de 2023 que lanzaría un servicio estilo ChatGPT llamado «YaLM 2.0» en ruso antes de finales de 2023.[149]​

Hugging Face ha lanzado una alternativa de código abierto a ChatGPT llamada HuggingChat, que permite a las personas interactuar con un asistente de chat de código abierto llamado Open Assistant.[150]​ El CEO de Hugging Face, Clem Delangue, tuiteó que cree que las alternativas de código abierto a ChatGPT son necesarias para la transparencia, la inclusión, la responsabilidad y la distribución del poder.[151]​

El 6 de diciembre de 2023, Google anunció Gemini, su última IA multimodal, la cual alcanzó mejores resultados en las pruebas de evaluación de IA en comparación con GPT-4, la versión más potente de OpenAI, postulándose así como un claro competidor de éste. Google Gemini está incorporado como modelo del chatbot Google Bard.[152]​

La prohibición del uso de ChatGPT y de su API para terceras empresas en China está siendo aprovechada por competidores locales como  SenseTime y Alibaba que dicen tener capacidades similares a ChatGPT 4 y ChatGPT Turbo respectivamente.[153]​ Ambas podrían ser una alternativa para Apple Intelligence en ese país.[154]​
