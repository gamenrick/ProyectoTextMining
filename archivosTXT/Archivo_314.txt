El impacto de la inteligencia artificial generativa en educación superior: una mirada desde la ética y la integridad académica
Cinta Gallent-Torres
redalyc.org

Monográfico
El impacto de la inteligencia artificial generativa en educación superior: una mirada desde la ética y la integridad académica
The impact of Generative Artificial Intelligence in higher education: a focus on ethics and academic integrity
O impacto da inteligência artificial generativa no ensino superior: uma perspectiva ética e de  integridade académica
生成式人工智能对高等教育的影响：从道德及学术诚信角度进行分析
تأثير الذكاء الاصطناعي التوليدي في التعليم العالي: وجهة نظر من الأخلاق والنزاهة الأكاديمية
El impacto de la inteligencia artificial generativa en educación superior: una mirada desde la ética y la integridad académica

RELIEVE. Revista Electrónica de Investigación y Evaluación Educativa, vol.  29, núm.  2, 2023

Universidad de Granada

Recepción:  03 Octubre  2023

Aprobación:  27 Noviembre  2023

Publicación:  07 Diciembre  2023

DOI: https://doi.org/10.30827/relieve.v29i2.29134

Financiamiento 

Fuente: MCIN/ AEI/10.13039/501100011033/ y “FEDER Una manera de hacer Europa”. También forma parte de las acciones de la Red Iberoamericana de Investigación en Integridad Académica (Red-IAI).


Nº de contrato: Proyecto de I+D+i con número de referencia PID2022-141031NB-I0


Resumen:
							                           La Inteligencia Artificial Generativa (IAG) ha revolucionado el ámbito de la educación superior, y ha abierto el debate en torno al potencial de herramientas como ChatGPT, Humata.ai o Sudowrite en los procesos de enseñanza, aprendizaje y evaluación. Si bien su integración en este contexto presenta numerosas oportunidades (i.e., retroalimentación instantánea, generación de recursos y materiales docentes, aprendizaje adaptativo, interactividad, etc.), también plantea importantes desafíos que ponen en entredicho la ética y la integridad académica como la fiabilidad de la información, la transparencia respecto a las fuentes utilizadas o la privacidad y seguridad de los datos. El objetivo de este artículo es examinar, desde una triple perspectiva (alumnado, profesorado y centro), las implicaciones éticas de su uso en educación superior. Se busca también analizar su impacto en aspectos vinculados con la seguridad, accesibilidad, sostenibilidad e, incluso, nuevas formas de plagio y fraude académico que suplanten la autoría. A partir de la revisión bibliográfica realizada, y según lo que plantean algunos autores, se explorarán posibilidades de integración de la IAG en las aulas universitarias, mediante prácticas pedagógicas que orienten al alumnado en su correcta utilización, y permitan al profesorado buscar nuevos enfoques educativos. Este proceso de transformación exigirá el establecimiento de unas directrices claras que se ajusten a los códigos éticos y las políticas de integridad de las instituciones de educación superior. En definitiva, la reflexión sobre cómo aunar educación, innovación e integridad académica brindará a la comunidad universitaria una nueva oportunidad para impulsar mejoras en la enseñanza universitaria.


Palabras clave: ética, integridad académica, Inteligencia Artificial Generativa (IAG), Educación Superior.
		                         

Abstract:
						                           Generative Artificial Intelligence (GAI) has revolutionized the field of higher education, and sparked debates on the potential of tools such as ChatGPT, Humata.ai or Sudowrite in teaching, learning and assessment processes. While their integration in this context offers numerous opportunities (e.g., instant feedback, generation of resources and teaching materials, adaptive learning, interactivity, etc.), it also poses significant challenges that raise ethical and academic integrity concerns, such as the reliability of information, transparency regarding the sources used, or data privacy and security. The aim of this article is to examine the ethical implications of GAI in higher education from a three-fold perspective (students, faculty, and institutions). Additionally, it aims to analyze its impact on aspects related to security, accessibility, sustainability and even new forms of plagiarism and academic fraud that involve impersonation of authorship. Based on the literature review conducted, and in accordance with the ideas proposed by some authors, possibilities for integrating GAI into university classrooms will be explored. This will be achieved through pedagogical practices that guide students in the proper use of GAI and enable faculty to seek new educational approaches. This transformation process will require the establishment of clear guidelines that align with ethical codes and integrity policies of higher education institutions. Ultimately, the reflection on how to combine education, innovation, and academic integrity will provide these three groups with a new opportunity to drive improvements in university education.


Keywords: ethics, academic integrity, Generative Artificial Intelligence (GAI), higher education.
                                

Resumo:
						                           A Inteligência Artificial Generativa (IAG) revolucionou o domínio do ensino superior e abriu o debate sobre o potencial de ferramentas como o ChatGPT, Humata.ai ou Sudowrite nos processos de ensino, aprendizagem e avaliação. Embora a sua integração neste contexto apresente inúmeras oportunidades (ou seja, feedback instantâneo, geração de recursos e material didático, aprendizagem adaptativa, interatividade, etc.), coloca também desafios importantes que põem em causa a ética e a integridade académica, como a fiabilidade da informação, a transparência em relação às fontes utilizadas ou à privacidade e segurança dos dados. O objetivo deste artigo é analisar as implicações éticas da sua utilização no ensino superior, numa tripla perspetiva (estudantes, professores e instituição). Pretende-se também analisar o seu impacto em aspetos ligados à segurança, acessibilidade, sustentabilidade e inclusive a novas formas de plágio e fraude académica que imitem ou roubem a identidade da autoria. Com base na revisão bibliográfica realizada, explorar-se-á a forma de integrar a IAG nas salas de aula universitárias, de forma controlada e respeitadora, através de práticas pedagógicas que orientem os estudantes na sua utilização correta e permitam aos professores lançar as bases de novos modelos educativos. Este processo de transformação exigirá o estabelecimento de diretrizes claras, em conformidade com os códigos éticos e as políticas de integridade das instituições de ensino superior. Em última análise, a reflexão sobre a forma de conjugar educação, inovação e integridade académica proporcionará a estes três coletivos uma nova oportunidade de promover melhorias no ensino universitário.


Palavras-chave: ética, integridade académica, Inteligência Artificial Generativa (IAG), Ensino Superior.
                                

摘要:
						                           生成式人工智能的出现给高等教育带来了革命化的影响，也开启了关于ChatGPT、Humata.ai、Sudowrite等工具在教育、学习及评估过程中应用潜力的讨论。如果说这些工具在该领域的使用确实带来了更多的机会（如实时反馈、教学材料及资源生成、自适应学习、互动等等），但与此同时，也对道德和学术诚信提出了挑战和质疑，如信息的可靠性、信息来源的透明度、数据的隐私和安全性。因此该研究主要从三个角度（学生、教师、机构）出发，对生成式人工智能的使用在高等教育中的道德影响进行查验。同时也对它在安全性、无障碍性、可持续性、甚至是模仿剽窃作者的作弊欺诈新形式等方面的影响进行分析。通过对已有文献的查验和参考，试图探寻将生成式人工智能融入大学课堂的方式，在可控且互相尊重的情况下，通过教学实践指导学生正确地使用人工智能，同时也为教师的教学新模式奠定基础。这一转变过程需要建立一系列清晰的符合道德标准和高等教育机构学术诚信要求的准则。总而言之，关于如何将教育、创新及学术诚信相融合的思考，为三个群体提供了推动大学教育改善的新机遇。


關鍵詞: 道德, 学术诚信, 生成式人工智能, 高等教育.
                                

ملخص:
						                           أحدث الذكاء التوليدي الاصطناعي (GAI) ثورة في مجال التعليم العالي, وفتح النقاش حول إمكانات أدوات مثل ChatGPT أو Humata.ai أو Sudowrite في عمليات التدريس والتعلم والتقييم. وعلى الرغم من أن تكاملها في هذا السياق يوفر العديد من الفرص( أي التغذية الراجعة الفورية, وتوليد الموارد والمواد التعليمية, والتعلم التكيفي, والتفاعل, وما إلى ذلك)فإنه يطرح أيضًا تحديات مهمة تدعو إلى التشكيك في الأخلاقيات والنزاهة الأكاديميةمثل موثوقية المعلومات أو الشفافية فيما يتعلق بالمصادر المستخدمة أو خصوصية البيانات وأمنها. هدف هذا المقال هو دراسة الانعكاسات الأخلاقية لاستخدامه في التعليم العالي من منظور ثلاثي( الطلاب والمعلمين والمركز). كما يسعى أيضًا إلى تحليل تأثيره على الجوانب المتعلقة بالأمن وإمكانية الوصول والاستدامة وحتى الأشكال الجديدة من الانتحال والاحتيال الأكاديمي التي تقلد التأليف أو تحل محله. واستنادًا إلى المراجعة الببليوغرافية التي تم إجراؤها، سنستكشف كيفية دمج IAG في الفصول الدراسية بالجامعة, بطريقة خاضعة للرقابة ومحترمة, من خلال الممارسات التربوية التي توجه الطلاب في الاستخدام الصحيح, وتسمح للمعلمين بوضع الأسس لنماذج جديدةالتعليمية. وستتطلب عملية التحول هذه وضع مبادئ توجيهية واضحة تتوافق مع القواعد الأخلاقية وسياسات النزاهة لمؤسسات التعليم العالي. باختصار, إن التفكير في كيفية الجمع بين التعليم والابتكار والنزاهة الأكاديمية من شأنه أن يوفر لهذه المجموعات الثلاث فرصة جديدة لتعزيز التحسينات في التدريس الجامعي


الكلمات المفتاحية: الأخلاق, النزاهة الأكاديمية, الذكاء الاصطناعي التوليدي, التعليم العالي.
                                

Introducción

A finales del año 2022, el mundo se encontraba viviendo en una era de postpandemia ocasionada por la crisis sanitaria de la COVID-19; un periodo en el que la sociedad se enfrentaba a desafíos sin precedentes en ámbitos que transcendían la salud pública, y el educativo no fue una excepción. Justo en el momento en el que las instituciones de educación superior se encontraban en plena recuperación de las actividades académicas presenciales, emergía una innovación tecnológica que marcaría un antes y un después en este contexto: la Inteligencia Artificial Generativa (IAG). Herramientas como ChatGPT (Generative Pre-trained Transformer), Google Bard (en español, bardo o poeta lírico), Humata.ai o Sudowrite fueron consideradas rápidamente un referente de este avance tecnológico y utilizadas de forma masiva por un gran número de usuarios. Ahora bien, no son las únicas; cada semana aparecen nuevas aplicaciones de este tipo, en su mayoría gratuitas, que ofrecen funcionalidades más avanzadas en sus versiones de pago, lo que permite obtener respuestas más precisas y coherentes, un mayor límite de tokens, navegación por Internet, posibilidad de procesar textos e imágenes, cargar documentos e incluso interactuar con el chatbot en tiempo real gracias a su sistema de voz. A estas características, se añade su amplia disponibilidad a través del ecosistema móvil, lo que facilita un acceso rápido y cómodo desde cualquier lugar.
A pesar de que las principales compañías tecnológicas (Alphabet, Amazon, Meta, OpenAI, entre otras) han estado trabajando en el desarrollo de modelos de procesamiento de lenguaje natural, esta irrupción tecnológica ha tomado al mundo entero por sorpresa, generando opiniones divergentes; muchos temen que transforme algunos sectores clave de la sociedad como el de la industria, los servicios financieros o la educación, y que reemplace algunos puestos de trabajo (Baskara & Mukarto, 2023; Javaid et al., 2023; Oppenlaender et al., 2023). De ahí que se opongan a su uso argumentando que estas herramientas disruptivas suponen una amenaza para el progreso. Otros consideran su llegada una revolución tecnológica sin precedentes, ya que brinda la oportunidad de impulsar la innovación, aumentar la productividad y mejorar la calidad de vida (Dogru et al., 2023; Vidal et al., 2024). Sin embargo, hoy en día, la posición predominante frente a esta tecnología combina el entusiasmo y la aprensión en relación con su impacto, evitando caer así en los extremos de los tecnófilos que la defienden sin evaluar sus riesgos y de los tecnófobos que la rechazan sin contemplar sus beneficios (Flores-Vivar & García-Peñalvo, 2023).
En cuanto a la definición del término, cabe señalar que la inteligencia artificial (IA), en general, se define como la capacidad de las máquinas de imitar la inteligencia humana (Turing, 1950). De acuerdo con Russel y Norvig (1995, citado en Escobar, 2021), “al crearse máquinas que se alimentan de información, de algoritmos con los cuales se desarrollan procesos, se dicen que aprenden (reciben información), razonan (aplican las reglas de uso) y se autocorrigen (mejoran los procesos para los cuales fueron originalmente diseñados)” (p. 31); en realidad, son sistemas que, al entrenarse con grandes cantidades de datos, son capaces de entender, argumentar, resolver problemas y tomar decisiones. En este sentido, señalaba Minsky (1990) hace unas décadas que, aun cuando todavía no se conocía cómo el cerebro realizaba sus habilidades mentales, ya se trabajaba para que las máquinas hicieran lo mismo. Hoy en día, este hecho es una realidad.
Dentro del campo de la IA, la IAG destaca como un área de especial interés. Se trata de un modelo de lenguaje avanzado (Large Language Models, LLM, por sus siglas en inglés), capaz de generar texto, imagen, voz, códigos, música, etc., en respuesta a las solicitudes de los usuarios expresadas en lenguaje natural. Es importante reseñar esta característica porque los contenidos generados por este sistema pueden llegar a confundirse con los de un experto humano. Por otra parte, el modelo opera en base a probabilidades, lo que significa que evalúa la probabilidad (idoneidad) de las palabras o frases en un contexto determinado. Sus respuestas pueden contener errores, por lo que se requiere que el usuario verifique la información. A pesar de ello, esta tecnología simula superar las capacidades humanas y seguirá evolucionando con el fin de alcanzar niveles aún más altos de perfección en su funcionamiento.
Estos sistemas inteligentes son clasificados por algunos autores en cuatro categorías: a) sistemas que piensan como humanos; b) sistemas que actúan como humanos; c) aquellos que piensan racionalmente y d) los que actúan racionalmente (Russell & Norving, 1996). Otros expertos los dividen en dos categorías: la IA débil y la IA fuerte. La primera, también conocida como la IA estrecha, se refiere a sistemas diseñados para realizar una tarea específica o resolver un problema concreto, mientras que la segunda se refiere a sistemas capaces de realizar cualquier tarea cognitiva que un ser humano pueda ejecutar (Soto, 2023). En otras palabras, la primera no se basa en el razonamiento, sino en el procesamiento de una acción; y la segunda imitaría el comportamiento humano. Muchos de estos sistemas se basan en el Aprendizaje Automático o Aprendizaje de las Máquinas (Machine Learning), una rama de la IA que se dedica al estudio de los programas que aprenden o evolucionan basados en su experiencia con el objetivo de realizar una tarea determinada cada vez mejor (Bordignon et al., 2023). Otros sistemas se basan en el Aprendizaje Profundo (Deep Learning), una rama del Aprendizaje Automático que emplea numerosas arquitecturas de redes neuronales con el fin de abordar diversos desafíos en campos como el procesamiento del lenguaje natural, la bioinformática, etc. (Osorio, 2023).
En lo que respecta a la parte legislativa, la regulación de la IA se ha acelerado en los últimos años. Un ejemplo de ello es lo que ocurre en la Unión Europea. Su parlamento aprobó dos resoluciones en el mes de octubre de 2020. Una de ellas se enfocaba en el marco de los aspectos técnicos de la IA, la robótica y las tecnologías conexas. La otra, se orientaba a recomendaciones destinadas a la Comisión Europea sobre un régimen de responsabilidad civil en materia de IA (Tapia, 2020). En el año 2021, se establecieron unas normas armonizadas en materia de inteligencia artificial (Ebers, 2023). Un año después se establecieron las directrices éticas sobre el uso de la IA y datos en la enseñanza y aprendizaje para educadores (Nguyen et al., 2023), y recientemente se ha presentado el proyecto de ley sobre inteligencia artificial (EU IA Act) con el objetivo de establecer un marco normativo y legal común en la Unión Europea que tenga efecto y validez legal antes de 2026.
Otros organismos internacionales se han sumado a la iniciativa de regular el uso de la IA en la educación superior. Por ejemplo, en 2019, la Organización para la Cooperación y el Desarrollo Económicos (OCDE, 2022) establece un conjunto de directrices de políticas intergubernamentales sobre IA que, sin ser jurídicamente vinculantes, se consideran influyentes en el establecimiento de normas internacionales futuras. Ese mismo año, la Organización de las Naciones Unidas para la Educación, la Ciencia y la Cultura (UNESCO) redactó el Consenso de Beijing sobre la Inteligencia artificial, un documento mediante el cual, a través de 44 recomendaciones, pretendía dar respuesta a las oportunidades y desafíos que presenta la IA en educación: desde la planificación de la IA en las políticas educativas, la gestión de la educación, el desarrollo de competencias, la equidad de género e inclusividad, la transparencia, ética e integridad académica, etc.; aspectos que se trataron con mayor detalle en la publicación Inteligencia artificial y educación. Guía para las personas a cargo de formular políticas (UNESCO, 2021). El 23 de noviembre de 2021, se aprobó la Recomendación sobre ética de la inteligencia artificial (UNESCO, 2022), la primera norma mundial sobre la ética de la IA adoptada por los 193 Estados miembros. A través de ella, se examinaron las implicaciones éticas de su uso desde distintos ámbitos de actuación (política de datos, cooperación internacional, medioambiente y ecosistemas, cultura, comunicación e información, etc.). Concretamente en el ámbito 8, dedicado a la educación e investigación, se incentiva a los Estados miembros a colaborar en una formación global en materia de IA a fin de “empoderar a la población y reducir las brechas digitales y las desigualdades en el acceso a la tecnología digital resultantes de la adopción a gran escala de [estos] sistemas” (p. 34). También se apuesta por la promoción de las “competencias previas” (alfabetización informacional básica, competencias digitales y de codificación, pensamiento crítico, etc.) como acciones clave para el desarrollo y el apoyo a la comunidad científica en “la contribución a las políticas y en la concienciación respecto de los puntos fuertes y débiles de las tecnologías de la IA” (p. 36). En 2023, la UNESCO publica una guía de inicio rápido sobre ChatGPT e inteligencia artificial en educación superior, la cual plantea algunos de los principales retos e implicaciones éticas de la IA en entornos educativos y ofrece medidas prácticas que las universidades pueden adoptar (Sabzalieva & Valentini, 2023). Todas estas directrices se elaboran para hacer frente a los desafíos éticos y legales que plantea el uso de esta tecnología en educación superior, minimizando así sus posibles riesgos.
En base a lo anterior, este trabajo se centra en examinar, desde una triple perspectiva (alumnado, profesorado y centro), las implicaciones éticas del uso de la IAG en educación superior; y en analizar cómo esta tecnología puede desafiar la integridad académica en los procesos de enseñanza-aprendizaje. Asimismo, considera su impacto en términos de seguridad, accesibilidad, privacidad y transparencia, entre otras cuestiones; e incide en la importancia de fomentar un compromiso ético por parte de la comunidad universitaria para preservar los valores fundamentales de la educación superior (honestidad, responsabilidad, respeto, etc.) y prevenir el desarrollo de nuevas formas de plagio y fraude académico que busquen imitar o suplantar la autoría.
A partir de la revisión bibliográfica realizada, se explorará cómo integrar la IAG en las aulas universitarias, de forma controlada y respetuosa, mediante prácticas pedagógicas que orienten al alumnado en su correcta utilización, y permitan al profesorado sentar las bases de nuevos modelos educativos.

Estudios previos sobre IAG y sus implicaciones en relación con la integridad académica

Durante la revisión de la literatura, se consultaron bases de datos de acceso abierto y cerrado (Scielo, Redalyc, Web of Science, Scopus, EBSCO y JSTOR) y se priorizaron artículos de investigación publicados en el último año que se aproximaban a la IAG desde perspectivas distintas: algunas de ellas centradas en su potencial transformador (Sun et al., 2023), en las implicaciones de su uso para la práctica docente e investigadora (Farrokhnia et al., 2023), en los posibles riesgos que comprometen la ética e integridad académica (Sullivan et al., 2023), o en la relación que se establece entre el ser humano y la biosfera (Terrones, 2022), atendiendo al concepto de sostenibilidad. Es evidente que esta temática ha generado un notable interés científico (a la par que mediático), y ha acelerado el avance del conocimiento en este ámbito.
Sin embargo, el desarrollo exponencial de la IAG en este último año ha provocado que muchas universidades no hayan tomado todavía una posición clara con respecto a esta nueva tecnología, y estén adoptado estrategias distintas para encarar los retos que plantea en educación superior: desde prohibir cualquier forma de IA en la universidad, explorar cómo el alumnado y el profesorado aprovechan su potencial para mejorar el proceso de enseñanza-aprendizaje (Lievens, 2023), hasta incluir una mención expresa sobre su uso en las guías docentes o establecer directrices y pautas de comportamiento en esta materia. No hay que olvidar que, por su pronta irrupción en este contexto, existen una serie de desafíos éticos y logísticos que enfrentan a centros y educadores al intentar incorporar esta tecnología en las estructuras curriculares existentes (Healy, 2023).
De acuerdo con Sullivan et al. (2023), se reconoce que el uso de herramientas de IAG en las evaluaciones universitarias genera cierta preocupación en lo que respecta a la integridad académica. Se mencionan casos en los que se ha detectado un alto porcentaje de estudiantes que han utilizado ChatGPT en tareas de evaluación, lo que ha llevado a algunas universidades a prohibir su uso. Esto plantea interrogantes sobre cómo garantizar la equidad y la autenticidad en las evaluaciones, y cómo evitar que el fraude académico comprometa el sistema educativo. Ahora bien, existe una limitación adicional: la velocidad con la que surgen las actualizaciones y el tiempo de respuesta y reacción ante ellas; es decir, mientras las distintas partes implicadas en el proceso educativo debaten sobre su uso, el alumnado y el profesorado ya han empezado a utilizar la IAG en su quehacer académico sin disponer de un marco regulatorio institucional.
En este sentido, la propuesta de Chan (2023) resulta de interés por establecer un marco de política educativa de IAG sostenible que permita atender las múltiples implicaciones de su uso en la enseñanza universitaria. Su modelo se organiza en tres dimensiones:
- Pedagógica: enfocada a utilizar la IAG de manera ética y responsable para mejorar los resultados de enseñanza y aprendizaje;
-  De gobernanza: centrada en cuestiones relacionadas con la privacidad, la seguridad y la responsabilidad, lo que implica definir políticas, pautas y regulaciones claras para el uso de la IAG, y exige promover conciencia y responsabilidad por parte de los agentes involucrados; y
-  Operativa: orientada a abordar los aspectos relacionados con la infraestructura y la formación; y a proporcionar los recursos y la capacitación necesaria para que el profesorado, alumnado y personal técnico comprendan y utilicen adecuadamente la IAG.
Estas tres dimensiones exigen revisar los modelos educativos y planes de estudio con el fin de mejorar el aprendizaje y adaptarlo a las necesidades formativas actuales.
Por otra parte, existen diversas preocupaciones relacionadas con el uso de la IAG y la integridad académica, entre las que destacan: i) el plagio y la generación de contenidos no originales (Ellis & Slade, 2023); ii) el uso de herramientas que detecten textos generados por IAG (GPT Zero, AI Text Classifier, Originality AI o Crossplag) (Weber-Wulff et al., 2023); iii) la implementación de planes de evaluación alternativos; iv) la dependencia a estos sistemas (lo que conllevaría un debilitamiento de la capacidad de pensamiento crítico en algunos usuarios y la dificultad de detectar información falsa o incorrecta en las respuestas); y v) la posibilidad de propagar sesgos en los resultados generados (Wach et al., 2023).
Ante estas limitaciones, las cuales irán mutando en el tiempo conforme se generalice su uso, es fundamental tomar medidas a favor de una IAG ética, responsable y confiable. Por tanto, frente a la tentación de resistirse al cambio o de prohibir su utilización, debería apostarse por una integración efectiva en el proceso de aprendizaje. Para ello, algunos autores proponen una serie de medidas que, desde una perspectiva ética, impactarán positivamente en la relación que se establece entre el ser humano y la inteligencia artificial (Fui-Hoon et al., 2023).
En primer lugar, se requiere la existencia de un marco regulatorio que aborde cuestiones como la privacidad de los datos, la seguridad, la transparencia algorítmica y la responsabilidad en la toma de decisiones automatizada (Kasneci et al., 2023). Asimismo, se exige considerar, desde que se comienza a diseñar un sistema de IAG, los posibles desafíos éticos que podrían verse afectados por el uso de dicha herramienta, en términos de equidad, discriminación, transparencia, sesgos, etc., y evaluar con anterioridad qué consecuencias podrían derivarse de su implementación. Dicha evaluación ayudaría a identificar y mitigar potenciales problemas éticos y a fomentar una mayor responsabilidad frente a su uso. También implicaría comprender cómo funciona un modelo de IAG para conocer las razones que existen detrás de sus decisiones automatizadas (Sullivan et al., 2023).
Sin duda, todas estas medidas no serían posibles si no se fomentara la colaboración multidisciplinar entre expertos en el ámbito de la tecnología, el derecho, la sociología, la educación, y otras disciplinas relevantes. Analizar los desafíos éticos desde diferentes perspectivas garantizará un enfoque integral en la toma de decisiones sobre el futuro de la IAG. Acompañar esta reflexión de estrategias de sensibilización y concienciación, programas de alfabetización y políticas o normativas, exigirá realizar cambios sustanciales en la manera de aprender, enseñar y actuar en la sociedad. Considerando que este campo de estudio es novedoso en educación superior, y que actualmente se encuentra en constante transformación, las ideas aquí presentadas seguirán evolucionando y merecerán ser actualizadas a medida que surjan nuevos desafíos éticos –todavía inimaginables– en los próximos meses.

La IAG, un desafío a la integridad académica

Si bien la tecnología generativa existe desde antes del lanzamiento de ChatGPT en noviembre de 2022 (Sullivan et al., 2023), su nivel de sofisticación y calidad de los resultados plantea importantes dilemas éticos en cuanto a la fiabilidad de la información, la transparencia de las fuentes utilizadas, la privacidad de los datos, y la autoría. También respecto a la seguridad, inclusión, diversidad o bienestar físico y mental de los usuarios, aspectos en los que hace hincapié la UNESCO en su documento sobre Ética de la Inteligencia Artificial (2021), el primer marco normativo en esta materia a nivel global.
Estas cuestiones preocupan porque realizar un uso inadecuado de esta tecnología disruptiva en enseñanza superior puede fomentar desigualdad, exclusión, discriminación e, incluso, brechas digitales entre los miembros de la comunidad académica. En otras palabras, estas herramientas pueden acrecentar las desigualdades en el acceso a la tecnología, perpetuar prejuicios y estereotipos, y excluir a aquellos usuarios menos hábiles en un entorno digital, lo cual es precisamente lo que debería evitarse. Para ello, es necesario analizar los riesgos y desafíos a los que se enfrenta la educación superior en el corto y medio plazo, atendiendo a la coyuntura tecnológica actual. Entre los riesgos destacan: los sesgos inherentes en los datos utilizados para entrenar la IAG, los contenidos incompletos o falsos que podrían confundir a investigadores, docentes y alumnado en el desarrollo de sus tareas académicas, la aparición de nuevas formas de plagio y fraude académico (Cotton et al., 2023), la suplantación de la autoría, la veracidad de la información, la falta de transparencia, etc. En cuanto a los desafíos, esta revolución tecnológica exigirá la necesidad de implementar acciones formativas, informativas y de sensibilización por y para la comunidad académica con el fin de integrar la IAG, de forma natural y efectiva, en los procesos de enseñanza-aprendizaje; asimismo, requerirá el establecimiento de unas directrices claras que se ajusten a los códigos éticos y las políticas de integridad de las instituciones de educación superior.
Conocer cómo la IAG puede desafiar la integridad académica en estos niveles educativos es sumamente importante. En primer lugar, porque dicho conocimiento se convierte en una necesidad a la hora de diseñar una hoja de ruta que garantice el cumplimiento de los estándares éticos y la calidad de la enseñanza universitaria. En segundo lugar, porque cualquier innovación tecnológica merece ser investigada y no despreciada, evitada o prohibida (Flores-Vivar y García-Peñalvo, 2023). Y, en tercer lugar, porque indagar sobre cómo esta tecnología puede atentar contra los valores básicos de la educación superior permitirá evaluar, de manera más efectiva, el impacto que aquellos comportamientos indebidos puedan tener en el proceso de enseñanza-aprendizaje.
A continuación, se evaluará dicho impacto desde los distintos colectivos implicados (alumnado, profesorado y centro), quienes promoverán la integración de esta tecnología en las instituciones, y adoptarán las medidas necesarias para asegurar su uso responsable y honesto.

Impacto de la IAG desde una triple perspectiva

La IAG ha transformado la manera de entender y abordar la enseñanza universitaria. Su integración en este ámbito ha traído enormes beneficios como la personalización del aprendizaje, la tutoría inteligente, la generación de contenidos educativos, la retroalimentación inmediata o la evaluación del rendimiento académico. Sin embargo, explorar cómo esta tecnología disruptiva puede limitar el desarrollo de ciertas competencias en el alumnado, entorpecer la labor investigadora del docente o desafiar las políticas internas del centro, insta a que sus actores adopten una posición crítica al respecto y busquen un equilibrio entre innovación, creación, ética e integridad académica.

Impacto en el alumnado

Desde la perspectiva de la educación centrada en el alumnado, numerosos son los debates en torno a la posibilidad de que estas herramientas favorezcan o no el desarrollo de comportamientos deshonestos por su parte. Si bien el número de estudios empíricos que analizan el uso fraudulento de la IAG entre el alumnado es todavía limitado (Sullivan et al., 2023; Waltzer et al., 2023), el interés por abordar esta problemática va en aumento. Prueba de ello son las investigaciones que se aproximan a ella desde aristas distintas, de las que la ética y la integridad académica también forman parte de la discusión. Por ejemplo, Sullivan et al. (2023) examinan el potencial de ChatGPT para el aprendizaje y apoyo al alumnado, en lugar de considerarlo un riesgo para su formación. Sin embargo, en base a la revisión sistemática que realizan, los autores identifican 88 artículos que abordan el uso indebido de estas herramientas, el fraude estudiantil, la subcontratación de ensayos a chatbots, el aumento de conductas plagiarias en trabajos académicos o las trampas en los exámenes de ingreso a la universidad. Ahora bien, señalan que si el alumnado recibe un mayor input de noticias que posicionan a la IAG como una herramienta que facilita el engaño o la trampa, este podría verse tentado a incurrir en comportamientos ilícitos, interpretando estas actitudes como una práctica generalizada (Cotton et al., 2023).
Otros estudios como el de Waltzer et al. (2023) comparan la escritura humana con la generada por la IAG, fomentando el debate sobre si los textos producidos por dicha tecnología pueden considerarse auténticos o no, dado que la semejanza entre ellos los hace indistinguibles. Esta circunstancia implica ahondar en el concepto de autenticidad, originalidad, autoría y apropiación indebida, teniendo en cuenta que la línea que separa lo genuinamente humano de lo creado por una máquina se vuelve cada vez más difusa. Como señala Lancaster (2023), el alumnado se enfrenta a un desafío importante en este nuevo escenario educativo: el de ser capaz de generar textos originales haciendo uso de la IAG. Si dicho esfuerzo no se produce, y se limita a copiar el contenido generado automáticamente, entraría en una dinámica de dependencia en lugar de fomentar su crecimiento intelectual. Este comportamiento podría asemejarse al de aquel que paga a otra persona por redactar un trabajo que debería haber realizado él. Ciertamente el texto aparentaría ser auténtico, pero no lo sería, ya que no habría sido creado por el estudiante (Lancaster, 2023).
Por otra parte, a la facilidad de acceso a dicha tecnología se suma un aliciente adicional que podría fomentar el uso indebido de la IAG entre el alumnado: su bajo (o nulo) coste. Si bien algunos estudios identifican este aspecto como un elemento democratizador (es decir, un mayor número de personas podrían acceder a estas herramientas sin necesidad de incurrir en costes elevados) (Kasneci et al., 2023), otros lo consideran una tentación que podría llevarles incluso a comercializar los resultados obtenidos entre sus compañeros (Qadir, 2023). De hecho, la versatilidad de estas herramientas es tal que podrían ofrecer respuestas distintas para todo un grupo-clase (Lancaster, 2023). Esto desviaría la atención de los más avispados que, en lugar de concentrarse en resolver problemas o utilizar el pensamiento crítico en sus áreas de estudio, se dedicarían a crear las mejores preguntas o prompts para alcanzar sus objetivos en el menor tiempo posible. Por tanto, no se produciría aprendizaje, sino competición; no se desarrollarían las habilidades básicas de expresión, comprensión y análisis, sino que el alumnado adoptaría un rol pasivo, convirtiéndose en un mero consumidor de respuestas prefabricadas. Esta actitud influiría en su autoconcepto como estudiante, en la satisfacción por realizar un trabajo propio, en el sentido del esfuerzo, y en su capacidad para actuar en autonomía. Solo aquellos alumnos que utilicen la IAG de forma crítica y responsable aprenderán a manejar unas herramientas que formarán parte de su ámbito profesional. Por el contrario, aquellos que las empleen para obtener mejores calificaciones sin merecerlo trasladarán sus inseguridades y malas prácticas al plano laboral (Guerrero-Dib et al., 2023).
Conviene subrayar, pues, que el uso de la IAG no exime a los estudiantes de sus responsabilidades académicas y del respeto a las normas y valores de la institución. De ahí que, si un docente prohíbe expresamente su uso en una actividad o prueba evaluable, y el alumnado desobedece a dicha indicación, su conducta represente una violación a la integridad académica y, por tanto, sería penalizable. La IAG tampoco les exime de ser críticos con la información que consumen, sino todo lo contrario; contrastar la autenticidad de los datos debería ser una prioridad (al igual que una competencia a desarrollar) en estos niveles educativos. Como ya se sabe, la IAG genera respuestas coherentes, pero inexactas; proporciona enlaces rotos o referencias a fuentes que, en ocasiones, no existen, e incluso contribuye a la propagación de noticias falsas, lo que complica la verificación de la información. Esta idea está, además, conectada con el concepto de transparencia (Gallent, 2024). Entender cómo estas herramientas operan y se entrenan, qué datos utilizan o cómo se actualizan es fundamental para confiar en esta tecnología y contribuir a su avance. También les ayudará a reflexionar y comprender los límites entre el uso legítimo de la IAG (como herramienta de aprendizaje) y cualquier uso abusivo y deshonesto de esta tecnología.

Impacto en el profesorado

Si bien la IAG tiene el potencial de transformar la enseñanza y facilitar los procesos educativos al crear experiencias de aprendizaje personalizadas, reducir el tiempo de preparación de materiales, y asistir al profesorado en las tareas de investigación, también plantea desafíos éticos y pedagógicos para este colectivo. En primer lugar, esta tecnología podría aumentar la brecha digital entre los docentes (UNESCO, 2022), dependiendo de su nivel de acceso, conocimiento y competencia en el uso de la IAG. Es cierto que no todos se encuentran en la misma etapa profesional, han recibido la misma formación o muestran el mismo interés por esta tecnología. Incluso la necesidad de incorporarla a su docencia es distinta. No obstante, a todos les corresponde cuestionarla, adaptarla, y utilizarla en beneficio propio y del alumnado, aportándole un valor añadido a su aprendizaje.
Algunos docentes temen que la IAG pueda reemplazarles o alterar su rol como facilitadores del aprendizaje, lo que podría resultar en una pérdida de autonomía, creatividad e interacción con el alumnado (Ayoola et al., 2023). Este cambio les podría llevar a actuar como meros supervisores o a ejecutar las instrucciones de la IAG sin pensar más allá. También afectaría a su motivación, implicación y compromiso por la profesión.
Al igual que el alumnado, aunque con motivaciones distintas, la IAG también podría incitarles a incurrir en conductas plagiarias debido a la presión que sienten por publicar u obtener financiación. Así pues, podrían verse tentados a apropiarse de las ideas de terceros, alterar el trabajo de los demás sin el debido crédito o utilizar información falsa o errónea no contrastada; también podrían recurrir intencionalmente a la fabricación de datos, la autoría indebida, el autoplagio, la manipulación de resultados e incluso a la violación de la privacidad y anonimato de posibles conversaciones registradas a través de la IAG –de acuerdo con Ausín (2021), “los individuos pueden volverse identificables a partir de datos que, en primera instancia, son anónimos” (p. 7). El profesorado que utiliza esta tecnología e incurre en conductas ilícitas en su docencia o investigación puede ver afectada su reputación; perder su credibilidad ante el alumnado, sus compañeros y la comunidad académica; limitar su desarrollo profesional y dejar de contribuir al avance del conocimiento con investigaciones originales.
En lugar de llevar a cabo estas acciones que socavan el valor de la ética y la integridad académica, sus aportaciones científicas deberían cumplir con el principio de transparencia y reproducibilidad. Habrían de describir minuciosamente la metodología empleada, cómo han alcanzado sus resultados y los procedimientos seguidos en su investigación. Es importante que mencionen explícitamente si han utilizado sistemas de IAG, permitiendo así que los futuros lectores tengan conocimiento de ello y puedan replicar su estudio. Esta idea lleva a autores como Dergaa et al. (2023) a plantear la cuestión sobre si cabe incluir a la IAG como un autor más en la lista de referencias de trabajos académicos y publicaciones científicas.
A menudo, se tiende a culpar al alumnado por utilizar la IAG para copiar. Sin embargo, ¿quién supervisa el plagio en los contenidos de aprendizaje? Se pide al estudiantado que no utilice la IAG para engañar a los docentes, pero ¿quién controla lo que los docentes ofrecen a sus alumnos? Sin duda, podría llegarse a la ridícula situación de que todo el esfuerzo de “aprendizaje” esté siendo realizado por una máquina, es decir, el profesor obtiene de una IAG una propuesta de contenidos o tareas mediante la cual comprobar que el alumnado ha asimilado el conocimiento, mientras que los alumnos utilizan la misma IAG u otra para obtener las respuestas correctas. Todo un absurdo si el interés se centra en evaluar el resultado final en lugar del proceso, lo que plantea el debate sobre la corresponsabilidad ética del profesorado.
Los docentes deben asumir un compromiso ético consigo mismos y con su profesión; un compromiso que se manifieste en sus actitudes y comportamientos, dado que desempeñan un papel crucial en la formación de futuras generaciones. Deben crear conciencia sobre las limitaciones de estos modelos de lenguaje para que sean utilizados como herramientas de apoyo, y no de reemplazo a otras fuentes de autoridad (Pavlik, 2023); e incidir en la verificación y el cuestionamiento del contenido generado, ya que, en ocasiones, podría estar protegido por derechos de autor. Para ello, efectivamente requerirán formación, y es ahí donde entra en juego la institución.

Impacto en la institución

Las instituciones de educación superior deberían aprovechar el potencial de la IAG para mejorar la eficiencia de sus procesos administrativos, tomar decisiones estratégicas y ofrecer experiencias de aprendizaje personalizadas. Estas herramientas pueden ser de utilidad también para predecir y mejorar la retención del alumnado, identificar posibles riesgos de abandono, analizar datos sobre su rendimiento académico y optimizar la gestión de los recursos disponibles (humanos y materiales) (Sullivan et al., 2023). Sin embargo, implementar la IAG en las instituciones universitarias conlleva una serie de desafíos éticos relacionados con la seguridad, la privacidad de los datos, la capacidad de interacción con estos modelos o la formación; siendo este último un aspecto esencial en esta revolución tecnológica.
Capacitar a la comunidad universitaria (desde el alumnado hasta el personal académico y administrativo) para que integre la IAG en su práctica académica y profesional es importante por dos razones: en primer lugar, porque utilizar un sistema con “imperfecciones” genera, a priori, cierto temor, y limita la predisposición a usarlo. Por lo tanto, si no se usa, no se conoce y no se integra en la práctica diaria, lo que impide adquirir algunas competencias específicas como la capacidad de adaptación a las tecnologías emergentes, o la habilidad de contrastar la información que se consume, entre otras. En segundo lugar, porque utilizar estas herramientas ayuda a tomar conciencia de que no deberían reemplazar el pensamiento crítico, el análisis ni la reflexión personal (Kasneci, 2023). Por tanto, se debe encontrar un equilibrio entre el aporte de la tecnología al quehacer académico-científico, y el desarrollo de habilidades que garanticen el éxito del proceso de enseñanza-aprendizaje. Dicha formación deberá ir orientada a satisfacer las demandas del profesorado, alumnado y personal administrativo para que, sin prejuicios ni miedos, conozcan los usos de estos modelos de lenguaje y puedan integrarlos en su día a día.
En esta línea, algunos autores señalan que las universidades han optado por modificar sus cursos y planes de estudio para hacerlos menos vulnerables a la IAG (Ausín, 2021); y que los docentes vuelven a las pruebas escritas supervisadas (Littleton & Fox, 2023), a pesar de reconocer que no son la mejor solución de aprendizaje. Sería interesante centrarse en diseñar tareas que permitan ejercitar el pensamiento crítico o la creatividad (i.e., debates, problemas complejos, casos prácticos, simulaciones, podcasts, comparación de textos, etc.) y explorar el trabajo colaborativo a través de proyectos de investigación que combinen tecnología y razonamiento, entorno digital y físico. Estas formaciones permitirán la retroalimentación constante sobre el uso de estos sistemas, y promoverán la creación de comunidades de aprendizaje que compartan sus prácticas y perspectivas (una iniciativa que podría incluso incentivarse económicamente).
Volviendo a los desafíos éticos que esta tecnología plantea, las universidades se enfrentan a importantes decisiones en cuanto a su uso y desarrollo. Por ejemplo, deberán pensar en cómo garantizar la privacidad de los datos del alumnado o el profesorado, a través de plataformas digitales que faciliten el acceso, la gestión y la verificación de información. Cualquier acceso no autorizado podría tener graves consecuencias tanto legales como éticas, por lo que el desarrollo de políticas de protección y ciberseguridad se hace imperativo. A dichas políticas deberían sumarse también los códigos y protocolos de integridad académica que definen las pautas éticas, las conductas esperadas y las sanciones aplicables por mala praxis en el uso de la IAG.
Por último, otro desafío ético al que debe hacer frente la institución son los sesgos y la discriminación en la toma de decisiones automatizada (Flores-Vivar & García-Peñalvo, 2023). Por ejemplo, cuando se delega a estas herramientas la tarea de seleccionar candidatos para programas académicos o de evaluar el rendimiento del alumnado en una asignatura, existe el riesgo de que dicha información se vea influenciada por prejuicios inherentes en los datos de entrenamiento. Sería necesario implementar medidas de revisión de algoritmos para identificar y corregir dichos sesgos y garantizar la equidad y la igualdad de oportunidades para todos.
Analizar estas cuestiones desde una triple perspectiva (alumnado, profesorado y centro), colocando en el centro de la reflexión la ética y la integridad académica, debería ser una prioridad en las agendas institucionales, máxime cuando la educación se encuentra inmersa en un proceso de transformación tecnológica de tal envergadura.

Algunas propuestas para integrar la IAG en los entornos de educación superior

De acuerdo con Sullivan et al. (2023), son muchas las publicaciones que señalan el gran potencial de la IAG en el ámbito educativo, pero expresan únicamente algunas ideas generales sobre su integración; solo unas pocas ofrecen propuestas concretas y específicas sobre su uso. Por señalar algunas, los autores identificaron las siguientes: crear tareas académicas personalizadas, utilizar una inteligencia artificial para editar o crear informes de evaluación de las tareas realizadas por los estudiantes, obtener explicaciones sencillas de conceptos complejos, ofrecer una “lluvia de ideas”, corregir código de diferentes lenguajes informáticos, producir borradores iniciales, generar contenidos para trabajar el pensamiento crítico en clase, crear rúbricas de evaluación, superar el bloqueo del escritor y generar citas, entre otras.
De acuerdo con lo descrito en las secciones anteriores, y atendiendo a uno de los objetivos generales del trabajo, a continuación, se plantean algunas propuestas para integrar la IAG en los entornos de educación superior.
Por ejemplo, el uso de chatbots o asistentes virtuales que puedan auxiliar a estudiantes y profesores en tiempo real (García-Brustenga et al., 2018); estos sistemas son capaces de responder a cuestionamientos, resolver problemas de cualquier área de conocimiento, ofrecer orientación académica e, incluso, detectar estados emocionales. Su implementación representa un reto para los centros universitarios, ya que deberán establecer reglas claras para su utilización.
Una iniciativa dirigida al profesorado universitario sería la implementación de herramientas que permitan automatizar la generación de ejercicios y evaluaciones. Esto facilitará la creación de pruebas más variadas y con distintos niveles de dificultad, así como una retroalimentación instantánea al alumnado (Vidal et al., 2024).
En cuanto a la aplicación del metaverso en los entornos universitarios, se propone el desarrollo de simulaciones y entornos virtuales de aprendizaje para crear escenarios realistas y de difícil acceso en la vida real. Esto puede ser especialmente útil para diversas disciplinas como las del área de la salud o las ingenierías (Aydin, 2023; Gutiérrez-Cirlos et al., 2023). En este sentido, la IAG ofrece una gran variedad de herramientas para la creación de contenido multimedia educativo como vídeos, infografías y animaciones; una acción que podría impactar de forma positiva en la creación de contenido cada vez más atractivo y accesible, lo que redundaría en la motivación del alumnado.
Otra propuesta interesante con un alto impacto en este ámbito es la traducción de contenido educativo a diferentes idiomas. Esto significa que se podrá tener acceso a transcripciones de forma automática y a subtítulos en tiempo real (Baskara & Mukarto, 2023), lo que ayudaría a estudiantes con discapacidades auditivas, favoreciendo así la inclusividad y la igualdad de oportunidades (Porto-Castro, 2022).
Otra sugerencia está relacionada con las actividades de investigación y análisis de datos (Cárdenas, 2023). A través de estas herramientas se pueden analizar grandes conjuntos de datos y generar información útil para mejorar la toma de decisiones institucionales. También, puede facilitar la colaboración en proyectos de investigación, ayudando a profesores y a estudiantes a generar ideas y contenido de manera conjunta.
Autores como Sun y Hoelscher (2023) contribuyen al avance de este campo mediante una serie de recomendaciones para los docentes con el fin de reflexionar sobre la efectiva integración de la IAG en las aulas. A partir de su propuesta, la cual es considerablemente más amplia que la que se presenta a continuación, se destacan las siguientes:
- Consensuar y definir lo que se entiende por “un uso adecuado” de la IAG en las tareas académicas;
- Crear exámenes que sean difíciles de resolver con la asistencia de una IAG, como proponer el análisis de imágenes, gráficos, fragmentos de vídeos o cualquier contenido que no pueda ser interpretado automáticamente -esta medida tiene un corto recorrido, dado que la IAG será capaz de interpretar ese tipo de contenido en breve.
- Diseñar propuestas de evaluación que promuevan la expresión verbal en entornos sincrónicos, como discusiones y debates en tiempo real.
- Diseñar tareas académicas que no puedan ser resueltas fácilmente por una IA; tareas que impliquen pensamiento complejo en situaciones o contextos muy específicos. En opinión de los autores, proponer la misma tarea para toda la clase puede persuadir al alumno de utilizar las respuestas de la IAG, haciéndolas pasar por ideas propias, ya que serán muy similares a las de otros compañeros que utilicen la misma IAG y el docente podrá reconocer con facilidad que el alumno no está presentado un trabajo original. Gracias a la capacidad humana para aprender y reconocer patrones, un docente experimentado puede llegar a sospechar que el texto que está leyendo ha sido creado por una IAG, teniendo la sensación de tener un cierto “sabor a…”.
Para evitar cualquier sorpresa desagradable, OpenAI (2023) recomienda lo siguiente:
- Compartir las conversaciones generadas con la IAG (la aplicación guarda la conversación y ofrece la posibilidad de compartirla mediante un enlace). De esta forma los docentes podrán analizar y valorar la interacción que se ha producido entre el alumnado y la IAG. Los alumnos podrán compartir entre ellos sus conversaciones para aprender en grupo. Al contar con un registro de sus conversaciones, los alumnos pueden observar el proceso de su progreso y los docentes realizar una evaluación personalizada a partir de dichos registros individuales.
- Evaluar las distintas competencias que el alumnado desarrolla en su interacción con la IAG: la pertinencia de las preguntas realizadas, la relevancia de la información obtenida, y la capacidad para valorarla de forma crítica, detectando, posibles sesgos y errores en las respuestas.
Todas estas medidas contribuirán a que la IAG sea percibida como una herramienta de aprendizaje, en lugar de un simple robot que genera trabajos.

Discusión

El año 2023 podría considerarse el Big Bang de la IAG, debido al crecimiento exponencial experimentado por estas herramientas (Chance, 2022; Faraboschi et al., 2023); un crecimiento que no parece que vaya a ralentizarse a corto plazo. Empresas referentes como OpenAI, Alphabet, Meta y Amazon anuncian cada día nuevas funcionalidades en estos sistemas, lo que les convierte en modelos de lenguaje potentes y altamente sofisticados. Las actualizaciones más recientes apuntan a que la IAG será multimodal, es decir, que será capaz de escuchar, observar e interactuar con los usuarios (Du et al., 2023; Lv, 2023) y accederá en tiempo real a información actualizada de Internet. Por tanto, no estará limitada a datos anteriores a septiembre de 2021 como ocurre hasta el momento, lo que supone un salto de gigante en la evolución de esta tecnología.
En cuanto a la interpretación de los hallazgos encontrados en la literatura, numerosos son los debates abiertos sobre el impacto de la IAG en los procesos de enseñanza y aprendizaje en educación superior. Por una parte, estas herramientas tienen el potencial de automatizar tareas relacionadas con la docencia y la investigación. Por otra parte, contemplan ciertas limitaciones en cuanto a la generación de contenidos (por su calidad cuestionable y poco fiable), el respeto por la propiedad intelectual o los derechos de autor. Son modelos que imitan el discurso humano al ser capaces de pensar y conversar como tal; algunos autores comparan la IAG con un “loro estocástico” (Bender et al., 2023), aludiendo a que estos modelos de lenguaje repiten palabras o ejecutan acciones sin una comprensión profunda de su significado. Sin embargo, y dada la rapidez a la que evolucionan y el nivel de razonamiento que alcanzan, posiblemente este calificativo no pueda aplicarse por mucho tiempo (Arkoudas, 2023).
Desde la perspectiva del alumnado universitario, se destaca que en la mayoría de las fuentes consultadas se encontró que han estado utilizando estas herramientas de forma experimental, sin una guía clara por parte del profesorado y con la ausencia de una normativa oficial por parte de las autoridades educativas que regule su uso responsable y ético (Cotton et al., 2023; Lancaster, 2023). El lado más obscuro de la IAG se muestra a través del plagio académico que cometen los estudiantes al tomar textos en los que no se reconoce la autoría intelectual; además, cuando se solicita a la herramienta que informe de las fuentes en las que se basó para generar el contenido, esta provee enlaces rotos y referencias ficticias (Wach et al., 2023). Esta circunstancia exige que los usuarios cuenten con unas competencias que les permitan evaluar la calidad de los resultados. Por eso, Stojanov (2023) recomienda que la IAG no sea utilizada por alumnos con conocimientos básicos sobre una temática, pues no serían capaces de detectar los sesgos o las ideas erróneas que obtengan en sus respuestas. De ahí la importancia de la supervisión o el acompañamiento.
En cuanto al profesorado, varios artículos consultados se centran en describir cómo pueden potenciar la práctica docente y las actividades relacionadas con la investigación gracias a estas herramientas. Entre ellas destacan: automatizar tareas, resumir contenidos, obtener imágenes de libre distribución, transformar texto en audio y viceversa, lo que significa generar nuevos contenidos de una forma extraordinariamente rápida (Baidoo-Anu & Ansah, 2023; Ahmad et al., 2023). Sin embargo, necesitan sentirse respaldados por sus instituciones y comprender claramente las expectativas asociadas a estas herramientas en todo el proceso de enseñanza-aprendizaje, con especial atención a las prácticas de evaluación (Cooper, 2023). También están expuestos a caer en situaciones de plagio académico y enfrentar dilemas éticos (Zhu & Yang, 2023).
Por último, y respecto a las instituciones educativas, se señala que la mayoría de ellas no cuentan aún con una normativa que regule su uso (Lievens, 2023). En consecuencia, algunas universidades han optado por prohibir ChatGPT (u otras herramientas similares) para la elaboración de las tareas académicas, lo cual afectará negativamente en la formación integral del alumnado. La falta de adopción de la IA en la academia puede también afectar la reputación de las universidades (Cárdenas, 2023). Se puede determinar que los retos que los centros enfrentan son múltiples: promover un uso responsable de la IAG, prevenir la vulneración de la integridad académica, e informar y concienciar acerca de las implicaciones éticas y los derechos humanos asociados al uso de estas herramientas (Gutiérrez, 2023).
Ciertamente el futuro de la educación superior se vislumbra con incertidumbre debido a que la IAG no ha hecho más que despegar; sin embargo, sus efectos empiezan a visualizarse tanto en los entornos presenciales como virtuales de aprendizaje. Por tanto, la colaboración y comunicación entre los distintos actores será crucial para encarar con éxito los nuevos desafíos, y llevar a cabo los ajustes necesarios para fortalecer el sistema educativo en lugar de debilitarlo.

Conclusiones, limitaciones y prospectiva

La sociedad está inmersa en un proceso de transformación digital que afecta a todos los ámbitos y disciplinas, y al que algunos expertos han denominado la «cuarta revolución industrial» (Escobar, 2021); una era que se recordará por la irrupción de sistemas «inteligentes» (robots conversacionales, agentes virtuales, etc.) capaces de imitar, de manera racional, el comportamiento humano, y emular su capacidad de pensamiento lógico, toma de decisiones y resolución de problemas. Dicho proceso tiene un impacto en educación superior que merece explorarse desde dos perspectivas: (i) desde el estudio de las propias herramientas de IAG (describiendo sus usos y funcionalidades, analizando su aplicación y las competencias necesarias para obtener mejores resultados); y (ii) desde la reflexión sobre las consecuencias y limitaciones éticas que se derivan tanto en el proceso de enseñanza-aprendizaje, como en los procesos administrativos y de servicios o en la investigación.
Se busca, además, analizar dicho impacto desde una triple perspectiva (alumnado, profesorado y centro), y con la mirada puesta en la ética y la integridad académica. A partir de la revisión de la literatura se concluye que el alumnado debe ser capaz de generar textos originales aun haciendo uso de la IAG, y sin incurrir en conductas deshonestas que comprometan sus principios y su formación. El profesorado, por su parte, debe asumir un compromiso ético consigo mismo y con su profesión, haciendo uso de la IAG como herramienta de apoyo y no de reemplazo a su labor docente e investigadora. Así, las instituciones deben también aprovechar su potencial para mejorar la eficiencia de sus procesos administrativos y educativos, encarando retos éticos relacionados con la seguridad, la privacidad, la transparencia y la equidad. También deben regular el uso de estos sistemas a través de políticas y normativas claras que eviten cualquier vulneración de los valores básicos de la educación superior.
Hoy en día existe un sentimiento generalizado de transformación y cambio que implica cierta sensación de pérdida; como si dejáramos algo por el camino, como si ahora el alumnado fuera a ser menos competente porque dejara de aprender algo. Sin embargo, esta sensación ya la hemos vivido en el pasado, ya que, debido a la automatización de las tareas, hemos dejado atrás una ingente cantidad de conocimientos prácticos que han sido desplazados por la tecnología: desde transformar un pedazo de obsidiana en una herramienta de corte, confeccionar cuerdas a partir de juncos o pelo animal, o construir utensilios para cultivar la tierra. Podríamos adoptar una actitud derrotista o de resistencia al cambio (lo cual de nada serviría), o abrazar las oportunidades que esta tecnología nos brinda en el entorno educativo. En cualquier caso, lo primero sería reconocer que la evolución es inherente al progreso y que beneficia al individuo, pero no le exime de evaluar de manera crítica sus posibles implicaciones y consecuencias.
Entre las limitaciones de este trabajo, hay una muy significativa. El campo de la IAG es novedoso y sumamente dinámico, por lo que las ideas compartidas pueden quedar obsoletas en poco tiempo, debido a la aparición de nuevas herramientas y funcionalidades. No obstante, este estudio se centra en una circunstancia presente, y proporciona una base sólida para comprender los riesgos éticos a los que enfrenta la educación superior un año después de la llegada de esta tecnología. Se reconoce también que la revisión bibliográfica realizada no ha sido sistemática, sino que se ha basado en una selección de fuentes relevantes y recientes, lo que podría haber dejado fuera algunas aportaciones igualmente interesantes.
Como futuras líneas de investigación se sugiere realizar estudios cuantitativos y cualitativos que involucren a distintos agentes educativos y recojan sus percepciones y experiencias con respecto al uso de la IAG; estudios que exploren las mejores prácticas educativas y analicen cómo minimizar los riesgos anteriormente comentados. También podrían analizarse las diferencias y similitudes entre los distintos colectivos, contextos, disciplinas, niveles o modalidades de enseñanza; propuestas que aportarían evidencias empíricas para mejorar: (i) la toma de decisiones estratégicas sobre el uso de la IAG en educación superior; (ii) el diseño de estrategias pedagógicas que favorezcan conductas éticas y responsables en un entorno digital; y (iii) el establecimiento de políticas institucionales que integren la IAG en los procesos de enseñanza-aprendizaje, contribuyendo así a superar la actual terra ignota en este campo.
Agradecimientos
Esta publicación forma parte del proyecto de I+D+i con número de referencia PID2022-141031NB-I00, financiado/a por MCIN/ AEI/10.13039/501100011033/ y “FEDER Una manera de hacer Europa”. También forma parte de las acciones de la Red Iberoamericana de Investigación en Integridad Académica (Red-IAI).

Referencias

Ahmad, N., Murugesan, S., & Kshetri, N. (2023). Generative Artificial Intelligence and the Education Sector. Computer, 56(6), 72-76. https://doi.org/10.1109/MC.2023.3263576

Arkoudas, K. (2023). ChatGPT is no Stochastic Parrot. But it also Claims that 1 is Greater than 1. Philos. Technol. 36(54). https://doi.org/10.1007/s13347-023-00619-6

Ausín, T. (2021). ¿Por qué la ética para la Inteligencia Artificial? Lo viejo, lo nuevo y lo espurio. Sociología y Tecnociencia, 11, extra 2, 1-16. https://tinyurl.com/49h2huhn

Aydin, Ö. (2023). Google Bard generated literature review: metaverse. Journal of AI, 7(1), 1-14. https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4454615

Ayoola, O. O., Alenoghena, R., & Adeniji, S. (2023). ChatGPT impacts on access-efficiency, employment, education and ethics: The socio-economics of an AI language model. BizEcons Quarterly, 16, 1-17.
Baidoo-Anu, D., & Ansah, L. O. (2023). Education in the era of generative artificial intelligence (AI): Understanding the potential benefits of ChatGPT in promoting teaching and learning. Journal of AI, 7(1), 52-62. https://doi.org/10.2139/ssrn.4337484

Baskara, F. R., & Mukarto, F. X. (2023). Exploring the Implications of ChatGPT for Language Learning in Higher Education. IJELTAL. Indonesian Journal of English Language Teaching and Applied Linguistics, 7(2), 343-358. https://ijeltal.org/index.php/ijeltal/article/view/1387/pdf

Bender, E. M., Gebru, T., McMillan-Major, A., & Shmitchell, S. (2021). On the dangers of stochastic parrots: Can language models be too big? En Proceedings of the 2021 ACM conference on fairness, accountability, and transparency (pp. 610-623). https://doi.org/10.1145/3442188.3445922

Bordignon, F., Dughera, L., & Tolosa, G. (2023). IAG y el momento de las máquinas imperfectas. Revista Hipertextos, 11(19), e069.https://doi.org/10.24215/23143924e069

Cárdenas, J. (2023). Inteligencia artificial, investigación y revisión por pares: escenarios futuros y estrategias de acción. RES. Revista Española de Sociología, 32(4), 199. https://doi.org/10.22325/fes/res.2023.184

Chan, C. K. Y. (2023). A comprehensive AI policy education framework for university teaching and learning. International Journal of Educational Technology in Higher Education, 20(1), 1-25. https://doi.org/10.1186/s41239-023-00408-3

Chance, C. (2022). Has there been a second AI big Bang? Forbes. https://www.forbes.com/sites/calumchace/2022/10/18/has-there-been-a-second-ai-big-bang/
Cooper, G. (2023). Examining Science Education in ChatGPT: An Exploratory Study of Generative Artificial Intelligence. Journal of Science Education and Technology, 32, 444-452. https://doi.org/10.1007/s10956-023-10039-y

Cotton, D. R. E, Cotton, P. A. et Reuben Shipway, J. (2023). Chatting and cheating: Ensuring academic integrity in the era of ChaGPT. Innovations in Education and Teaching International. Routledge. Taylor & Francis Group, pp. 1-12. https://doi.org/10.1080/14703297.2023.2190148

Dergaa, I., Chamari, K., Zmijewski, P., & Ben Saad, H. (2023). From human writing to artificial intelligence generated text: examining the prospects and potential threats of ChatGPT in academic writing. Biology of sport, 40(2), 615-622. https://doi.org/10.5114/biolsport.2023.125623

Dogru, T., Line, N., Mody, M., Hanks, L., Abbott, J. A., Acikgoz, F., ... & Zhang, T. (2023). Generative artificial intelligence in the hospitality and tourism industry: Developing a framework for future research. Journal of Hospitality & Tourism Research, 10963480231188663. https://doi.org/10.1177/10963480231188663

Du, H., Liu, G., Niyato, D., Zhang, J., Kang, J., Xiong, Z., ... & Kim, D. I. (2023). Generative AI-aided Joint Training-free Secure Semantic Communications via Multi-modal Prompts. arXiv preprint arXiv:2309.02616.
Ebers, M. (2023). El futuro marco jurídico europeo de la inteligencia artificial. Revista general de legislación y jurisprudencia, (2), 249-280. https://dialnet.unirioja.es/servlet/articulo?codigo=8927540

Ellis, A. R., & Slade, E. (2023). A New Era of Learning: Considerations for ChatGPT as a Tool to Enhance Statistics and Data Science Education. Journal of Statistics and Data Science Education, 31(2), 1-10. https://doi.org/10.1080/26939169.2023.2223609

Escobar Hernández, J.C. (2021). La Inteligencia Artificial y la enseñanza de lenguas: una aproximación al tema. Decires. Revista del Centro de Enseñanza para Extranjeros, 25(21), 29-44. https://doi.org/10.22201/cepe.14059134e.2021.21.25.3

European Commission, Directorate-General for Education, Youth, Sport, and Culture (2022). Ethical guidelines on the use of artificial intelligence (AI) and data in teaching and learning for educators. Publications Office of the European Union.  https://data.europa.eu/doi/10.2766/153756

Faraboschi, P., Frachtenberg, E., Laplante, P., Milojicic, D., & Saracco, R. (2023). Artificial General Intelligence: Humanity’s Downturn or Unlimited Prosperity. Computer, 56(10), 93-101. https://doi.org/10.1109/MC.2023.3297739

Farrokhnia, M., Banihashem, S. K., Noroozi, O., & Wals, A. (2023). A SWOT analysis of ChatGPT: Implications for educational practice and research. Innovations in Education and Teaching International, 1-15. https://doi.org/10.1080/14703297.2023.2195846

Flores-Vivar, J. M., & García-Peñalvo, F. J. (2023). Reflexiones sobre la ética, potencialidades y retos de la Inteligencia Artificial en el marco de la Educación de Calidad (ODS4). Comunicar, 31(74), 37-47. https://doi.org/10.3916/C74-2023-03

Fui-Hoon Nah, F., Zheng, R., Cai, J., Siau, K., & Chen, L. (2023). Generative AI and ChatGPT: Applications, challenges, and AI-human collaboration. Journal of Information Technology Case and Application Research, 25(3), 277-304. https://doi.org/10.1080/15228053.2023.2233814

Gallent Torres, C. (2024). L’utilisation de l’IA Générative dans le cadre de l’enseignement du FLE : aspects pratiques et considérations éthiques. Inteligencia Artificial, ¿amiga o enemiga? Colección Ciencias Sociales en abierto. Peter Lang (en proceso de publicación).
García-Brustenga, G., Fuertes-Alpiste, M., & Molas-Castells, N. (2018). Briefing paper: los chatbots en educación. eLearn Center. Universitat Oberta de Catalunya. https://doi.org/10.7238/elc.chatbots.2018

Guerrero-Dib, J. G., Portales, L., & Gallego, D. (2023). Academic Integrity as a Way to Promote Workplace Ethical Behaviour. In Academic Integrity in the Social Sciences: Perspectives on Pedagogy and Practice (pp. 165-183). Springer International Publishing. https://doi.org/10.1007/978-3-031-43292-7_11

Gutiérrez, J. D. (2023). Lineamientos para el uso de inteligencia artificial en contextos universitarios. GIGAPP Estudios Working Papers, 10(267-272), 416-434.
Gutiérrez-Cirlos, C., Bermúdez-González, J. L., Carrillo-Pérez, D. L., Hidrogo-Montemayor, I., Martínez-González, A., Carrillo-Esper, R., & Sánchez-Mendiola, M. (2023). La medicina y el metaverso: aplicaciones actuales y futuro. Gaceta Médica, 159, 286-292. https://doi.org/10.24875/GMM.23000166

Healy, M. (2023). Using Curriculum Theory to Inform Approaches to Generative AI in Schools. SSRN 4564372. http://dx.doi.org/10.2139/ssrn.4564372

Javaid, M., Haleem, A., & Singh, R. P. (2023). A study on ChatGPT for Industry 4.0: Background, Potentials, Challenges, and Eventualities. Journal of Economy and Technology. https://doi.org/10.1016/j.ject.2023.08.001

Kasneci, E., Seßler, K., Küchemann, S., Bannert, M., Dementieva, D., Fischer, F., Gasser, U., Groh, G., Günnemann, S., Hüllermeier, E., Krusche, S., Kutyniok, G., Michaeli, T., Nerdel, C., Pfeffer, J., Poquet, O., Sailer, M., Schmidt, A., Seidel, T., Stadler, M., Weller, J. Kuhn, J., & Kasneci, G. (2023). ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education. Learning and Individual Differences, 103, 102274. https://doi.org/10.1016/j.lindif.2023.102274

Lancaster, T. (2023). Artificial intelligence, text Generation tools and ChatGPT - does digital watermarking offer a solution? International Journal for Educational Integrity, 19(10), 2-14. https://doi.org/10.1007/s40979-023-00131-6

Lievens, J. (2023). Artificial Intelligence (AI) in higher education: tool or trickery? Education and New Developments, 2, 645-647. International Conference on Education and New Developments, Lisboa (Portugal), 24-26 de junio de 2023. ISBN: 978-989-35106-4-3.
Littleton, E., & Fox, H. (22 de enero de 2023). Artificial intelligence presents new challenge to the university. Daily Missisippian.https://thedmonline.com/artificial-intelligence-presents-new-challenge-to-the-university/
Lv, Z. (2023). Generative Artificial Intelligence in the Metaverse Era. Cognitive Robotics, 3, 208-217. https://doi.org/10.1016/j.cogr.2023.06.001

Minsky, M. (1990). The Age of Intelligent Machines: Thoughts About Artificial Intelligence. KurzweilAI.net. http://www.kurzweilai.net/articles/art010 0.html
Nguyen, A., Ngo, H. N., Hong, Y., Dang, B., & Nguyen, B. P. T. (2023). Ethical principles for artificial intelligence in education. Education and Information Technologies, 28(4), 4221-4241. https://doi.org/10.1007/s10639-022-11316-w

OECD (2022). Recommendation of the Council on Artificial Intelligence. OECD/LEGAL/0449.
OpenAI (2023). GPT-4 Technical Report. ArXiv, abs/2303.08774. https://cdn.openai.com/papers/gpt-4.pdf

Oppenlaender, J., Visuri, A., Paananen, V., Linder, R., & Silvennoinen, J. (2023). Text-to-Image Generation: Perceptions and Realities. arXiv preprint arXiv:2303.13530. https://doi.org/10.48550/arXiv.2303.13530

Osorio, J. (2023). Revisión sistémica de la relación jurídica en entornos digitales. Ektenos, 1(2), 23-34.
Pavlik, J.V. (2023). Collaborating with ChatGPT: Considering the implications of generative artificial intelligence for journalism and media education. Journalism & Mass Communication Educator, 78(1), article 10776958221149577  https://doi.org/10.1177/1077695822114957

Porto-Castro, A. M. (2022). Percepción del alumnado y profesorado universitario sobre la accesibilidad y la inclusión. RELIEVE, Revista Electrónica de Investigación y Evaluación Educativa, 28(1), art. 7. http://doi.org/10.30827/relieve.v28i1.23673

Qadir, J. (2023). Engineering education in the era of ChatGPT: Promise and pitfalls of generative AI for education. 2023 IEEE Global Engineering Education Conference (EDUCON) (pp. 1-9). IEEE. https://doi.org/10.36227/techrxiv.21789434

Russell, S. & Norving, P. (1996). Inteligencia Artificial: Un enfoque moderno. Primera edición en español. Prentice Hall Hispanoamericana. México.
Sabzalieva, E., & Valentini, A. (2023). ChatGPT e inteligencia artificial en la educación superior: Guía de inicio rápido. UNESCO. ED/HE/IESALC/IP/2023/12. https://unesdoc.unesco.org/ark:/48223/pf0000385146_spa

Soto, J. Á. (2023). La «velocidad de escape» de la IA y el futuro del trabajo. Nuevas Tendencias, (110), 37-39. https://revistas.unav.edu/index.php/nuevas-tendencias/article/view/45027

Stojanov, A. (2023). Learning with ChatGPT 3.5 as a more knowledgeable other: an autoethnographic study. International Journal of Educational Technology in Higher Education, 20(35), 1-17. https://doi.org/10.1186/s41239-023-00404-7

Sullivan, M., Kelly, A., & McLaughlan, P. (2023). ChatGPT in higher education: Considerations for academic integrity and student learning. Journal of Applied Learning & Teaching, 6(1), 31-40. https://doi.org/10.37074/jalt.2023.6.1.17

Sun, G.H., & Hoelscher, S. (2023). The ChatGPT Storm and What Faculty Can Do. Nurse Educ, 48(3), 119-124. Epub. https://doi.org/10.1097/NNE.0000000000001390

Sun, W., Yan, L., Ma, X., Ren, P., Yin, D., & Ren, Z. (2023). Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agent. arXiv preprint arXiv:2304.09542. https://doi.org/10.48550/arXiv.2304.09542

Tapia, A. J. (2020). Decálogo de la inteligencia artificial ética y responsable en la Unión Europea. Diario La Ley, 9749, sección Tribuna.http://www.aidaargentina.com/wp-content/uploads/Dec%C3%A1logo_de_la_inteligen...-1.pdf

Terrones, A. L. (2022). Ética para la inteligencia artificial sostenible. Arbor, 198(806), a683. https://doi.org/10.3989/arbor.2022.806013

Turing, A. M. (1950). Computing Machinery and Intelligence. Mind, LIX, 236, 433-460. https://doi.org/10.1093/mind/LIX.236.433

UNESCO (2021). Recomendación sobre la Ética de la Inteligencia Artificial. https://unesdoc.unesco.org/ark:/48223/pf0000380455_spa

European Parlament (2023). EU Artificial Intelligence Act. https://tinyurl.com/3kv85wn9

UNESCO (2019). Consenso de Beijing sobre la Inteligencia artificial.International Conference on Artificial Intelligence and Education. Planning Education in the AI Era: Lead the Leap. Beijing. https://unesdoc.unesco.org/ark:/48223/pf0000368303

UNESCO (2021). Inteligencia artificial y educación. Guía para las personas a cargo de formular políticas. https://unesdoc.unesco.org/ark:/48223/pf0000379376

UNESCO (2021). Ética de la Inteligencia Artificial. https://www.unesco.org/es/artificial-intelligence/recommendation-ethics

Vidal, J., Llorens-Largo, F., & García-Peñalvo, F. J. (2024). The new reality of education in the face of advances in generative artificial intelligence. RIED-Revista Iberoamericana de Educación a Distancia, 27(1). https://doi.org/10.5944/ried.27.1.37716

Wach, K., Duong, C. D., Ejdys, J., Kazlauskaitė, R., Korzynski, P., Mazurek, G., ... & Ziemba, E. (2023). The dark side of generative artificial intelligence: A critical analysis of controversies and risks of ChatGPT. Entrepreneurial Business and Economics Review, 11(2), 7-24. https://doi.org/10.15678/EBER.2023.110201

Waltzer, T., Cox, R. L., & Heyman, G. D. (2023). Testing the ability of teachers and students to differentiate between essays generated by ChatGPT and High School Students. Human Behaviour and Emerging Technologies, ID artículo 1923981, 1-9.   https://doi.org/10.1155/2023/1923981

Weber-Wulff, D., Anohina-Naumeca, A., Bjelobaba, S., Foltýnek, T., Guerrero-Dib, J., Popoola, O., ... & Waddington, L. (2023). Testing of detection tools for AI-generated text. arXiv preprint arXiv:2306.15666. https://arxiv.org/ftp/arxiv/papers/2306/2306.15666.pdf

Zhu, Y., & Yang, F. (2023). ChatGPT/AIGC and Educational Innovation: Opportunities, Challenges, and the Future. Journal of East China Normal University (Educational Sciences), 41(7). 1.
Notas de autor 
cinta.gallent@uv.es
Enlace alternativo 
https://revistaseug.ugr.es/index.php/RELIEVE/article/view/29134	(html)
            


https://revistaseug.ugr.es/index.php/RELIEVE/article/view/29134	(html)
            