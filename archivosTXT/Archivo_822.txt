Cómo la IA está transformando la forma de hacer ciencia, según un ex CEO de Google - Infobae
Autor desconocido
infobae.com

1 Dic, 2024
La inteligencia artificial (IA) está a punto de convertir a la ciencia en algo “mucho más emocionante y, en cierto modo, irreconocible. Las repercusiones de este cambio se sentirán fuera del laboratorio y nos afectarán a todos”. Así resumió cómo está viendo este cambio de época, Eric Schmidt, quien fuera CEO de Google desde 2001 a 2011.
Como ejemplo de cómo está cambiando el mundo científico y tecnológico, el empresario e informático contó que Nvidia, está creando un gemelo digital de la Tierra, llamado Earth-2 que usará un modelo de IA llamado FourCastNet para predecir el clima extremo con mayor rapidez y precisión que los métodos actuales. FourCastNet puede simular miles de escenarios posibles, lo que permite anticipar y prevenir desastres naturales. Este avance en el modelado climático es parte de una revolución científica impulsada por la IA, que tendrá un gran impacto en la sociedad y el medio ambiente.
El exCEO de Google —cofundador de Schmidt Futures, una iniciativa filantrópica que apuesta por personas excepcionales que mejoran el mundo, aplican la ciencia y la tecnología y unen a las personas en todos los campos— dijo en un artículo en MIT Technology Review que, “si jugamos bien nuestras cartas con una regulación sensata y el apoyo adecuado para los usos innovadores de la IA para abordar los problemas más apremiantes de la ciencia, la IA puede reescribir el proceso científico. Podemos construir un futuro en el que las herramientas impulsadas por IA nos salven del trabajo sin sentido y que consume mucho tiempo y también propongan invenciones y descubrimientos creativos, fomentando avances que de otro modo tomarían décadas”.
El experto recordó que la IA ya ha impulsado grandes avances en la ciencia, tanto con modelos pequeños y específicos como con modelos grandes y generales o LLM. Estos modelos han ayudado, por ejemplo, a los científicos de McMaster y el MIT a encontrar nuevos antibióticos para combatir una de las bacterias consideradas resistentes a los medicamentos, según la Organización Mundial de la Salud. También han permitido a través de un modelo de Google DeepMind controlar el plasma en la fusión nuclear lo que podría llevar a una revolución de energía limpia. Dentro de la atención médica, la FDA ya aprobó 523 dispositivos que usan IA, el 75% para uso en radiología.
La IA puede cambiar la forma de hacer ciencia, desde la revisión de literatura hasta la formulación de hipótesis. Los científicos pueden usar herramientas basadas en estos sistemas para obtener resúmenes y citas de artículos existentes. Los modelos de lenguaje grandes pueden predecir el siguiente paso lógico en una secuencia científica, sugiriendo posibles descubrimientos.
“En esencia, el proceso científico que todos aprendimos en la escuela primaria seguirá siendo el mismo: realizar una investigación de antecedentes, identificar una hipótesis, probarla a través de la experimentación, analizar los datos recopilados y llegar a una conclusión. Pero la IA tiene el potencial de revolucionar la apariencia de cada uno de estos componentes en el futuro”, dijo Schmidt.
Lejos de las predicciones alarmantes que están formulando muchas personas, incluso de ámbitos científicos, el experto informático consideró que “esta técnica hace que los LLM sean especialmente adecuados para problemas escalados intrínsecos a la estructura jerárquica de la ciencia y puede permitir que dichos modelos predigan el próximo gran descubrimiento en física o biología”. La IA puede mejorar la generación y evaluación de hipótesis científicas, lo que facilita el descubrimiento de nuevos medicamentos y el diseño de experimentos más eficientes, destacó.
Otro ejemplo que está dando impulso a la ciencia de la salud es el realizado por expertos de CalTech, dijo Schmidt, que utilizaron un modelo de simulación de fluidos de IA para diseñar automáticamente un mejor catéter que evita que las bacterias naden río arriba y causen infecciones. De esta forma, dijo, la IA puede acelerar el progreso científico al permitir a los investigadores encontrar la mejor solución posible para un problema desde el principio, en lugar de tener que probar muchas soluciones parciales o subóptimas hasta llegar a la mejor, como ocurrió en el pasado con el desarrollo de las bombillas de electricidad.
“Pasando al paso de la experimentación, la IA podrá realizar experimentos más rápido, más barato y a mayor escala. Por ejemplo, podemos construir máquinas impulsadas por IA con cientos de micropipetas funcionando día y noche para crear muestras a una velocidad que ningún ser humano podría igualar. En lugar de limitarse a solo seis experimentos, los científicos pueden usar herramientas de inteligencia artificial para ejecutar mil”, agregó.
Según dijo, la IA puede liberar a los científicos de las limitaciones y sesgos que afectan su trabajo, permitiéndoles explorar hipótesis más innovadoras y arriesgadas. Además, la IA puede automatizar y optimizar el diseño, la ejecución y el análisis de los experimentos, utilizando plataformas robóticas que funcionan como laboratorios autónomos. Se trata de “plataformas robóticas automatizadas combinadas con inteligencia artificial. Aquí, podemos llevar la destreza de la IA del ámbito digital al mundo físico. Estos laboratorios autónomos ya están surgiendo en empresas como Emerald Cloud Lab y Artificial e incluso en el Laboratorio Nacional de Argonne”, expresó. Estos laboratorios autónomos pueden actuar como socios de investigación para los científicos, interpretando los resultados, sugiriendo los próximos pasos y reponiendo los materiales necesarios. Así, la IA puede acelerar el ciclo de descubrimiento científico y mejorar la calidad y eficiencia de la investigación.
Schmidt cree también que la IA dará chances de sumarse a nuevos científicos en una suerte de democratización de las áreas del conocimientos que hasta ahora no se ha visto. La IA puede transformar el trabajo de la ciencia, haciéndolo más creativo, inclusivo y eficiente. Los LLM pueden facilitar la codificación, la escritura y la revisión de los proyectos de investigación, ampliando el alcance y la calidad de la ciencia.
“Las herramientas de IA pueden reducir la barrera de entrada para nuevos científicos y abrir oportunidades para aquellos tradicionalmente excluidos del campo. Con los LLM capaces de ayudar en la creación de código, los estudiantes de STEM ya no tendrán que dominar lenguajes de codificación oscuros, abriendo las puertas de la torre de marfil a nuevos talentos no tradicionales y facilitando que los científicos se comprometan con campos más allá de los suyos”, explicó.
El especialista consideró que “las herramientas de IA tienen un potencial increíble, pero debemos reconocer dónde el toque humano sigue siendo importante y evitar correr antes de poder caminar. Por ejemplo, fusionar con éxito la IA y la robótica a través de laboratorios autónomos no será fácil. Hay mucho conocimiento tácito que los científicos aprenden en los laboratorios que es difícil de transferir a la robótica impulsada por IA. Del mismo modo, debemos ser conscientes de las limitaciones, e incluso las alucinaciones, de los LLM actuales antes de descargarles gran parte de nuestro papeleo, investigación y análisis”.
Schmidt cree que empresas como OpenAI y DeepMind siguen liderando el camino en nuevos avances, modelos y trabajos de investigación, pero el dominio actual de la industria no durará para siempre. DeepMind se ha destacado por centrarse en problemas bien definidos con objetivos y métricas claros. La forma de las proteínas es un enigma que la ciencia llevaba años intentando descifrar. Fue esta última compañía la que ha encontrado la solución con su modelo AlphaFold2, que dejó atrás a sus rivales humanos en una prueba mundial. Este logro muestra el potencial de la IA para impulsar el progreso científico.
La inteligencia artificial de código abierto permite que los investigadores académicos aprovechen los avances de la industria y los mejoren. Un ejemplo es RoseTTAFold, un modelo desarrollado por científicos de la Universidad de Washington que se basa en el trabajo de DeepMind para predecir cómo se unen las proteínas entre sí, algo que el modelo original no podía hacer. Además, los académicos tienen más libertad para explorar problemas científicos más complejos y desafiantes que los que interesan a la industria.
El informático recordó que, según un trabajo publicado en Nature en 2016, cerca del 70% de los científicos dijeron que no habían podido reproducir el experimento de otro científico, “pero a medida que la IA reduzca el costo y el esfuerzo de realizar experimentos, en algunos casos será más fácil replicar (o no replicar) los resultados, lo que contribuirá a una mayor confianza en la ciencia”, opinó. “La clave para la replicabilidad y la confianza es la transparencia”.
Según la visión de Schmidt, la ciencia se beneficiaría de que todos sus recursos fueran de acceso abierto, desde las publicaciones hasta los datos, los códigos y los modelos de inteligencia artificial. Sin embargo, algunos modelos de IA pueden ser peligrosos si caen en manos equivocadas, por lo que no siempre es posible compartirlos libremente. En estos casos, hay que sopesar los riesgos y los beneficios de la transparencia. Pero cuando se trata de modelos de IA más simples y específicos, deberíamos optar por el acceso abierto. “Lamentablemente, con los peligros que estos modelos pueden desencadenar, no siempre es realista hacer que todos los modelos sean de código abierto”, subrayó, pero “en la medida en que podamos ser transparentes con los modelos, especialmente los modelos clásicos de IA con usos más limitados, deberíamos serlo”, agregó.
La inteligencia artificial puede ser una herramienta muy útil para la ciencia, pero también puede ser muy peligrosa si se usa con fines maliciosos. Un ejemplo de esto lo dio el profesor Andrew White, de la Universidad de Rochester, que participó en un proyecto de OpenAI para evaluar los riesgos de GPT-4, un modelo de lenguaje muy avanzado. White logró usar el modelo para diseñar y pedir sustancias químicas nocivas, lo que demostró la necesidad de mejorar la seguridad de GPT-4 antes de hacerlo público. OpenAI afirma que tomó en cuenta los hallazgos de White para modificar el modelo.
“Incluso los humanos con buenas intenciones pueden provocar que las IA produzcan malos resultados. Deberíamos preocuparnos menos por crear Terminator y, como dijo el  científico informático Stuart Russell, más por convertirnos en el rey Midas, que deseaba que todo lo que tocaba se convirtiera en oro y, por lo tanto, mató accidentalmente a su hija con un abrazo”, subrayó.
El especialista recordó que la inteligencia artificial puede ser muy obstinada cuando se trata de cumplir su objetivo, aunque ese objetivo sea algo tan simple como hacer clips. Un ejemplo extremo que se suele dar es el de una IA que se vuelve loca y destruye el mundo para hacer más y más clips, sin importarle las consecuencias. Nadie puede detenerla porque solo le importa su objetivo. Este escenario imaginario es una advertencia de lo que podría pasar si no controlamos bien la IA. Según Schmidt, OpenAI ha hecho un buen trabajo para proteger su modelo de lenguaje GPT-4, pero hay que evitar que otros lo roben y lo usen sin seguridad.
Para abordar los malos usos de la IA, tanto intencionales como no intencionales, destacó, necesitamos una regulación inteligente y bien informada, tanto en los gigantes tecnológicos como en los modelos de código abierto, que no impida usar la IA de formas que puedan ser beneficiosas para la ciencia. Si bien las empresas de tecnología han avanzado en la seguridad de la IA, los reguladores gubernamentales actualmente están lamentablemente mal preparados para promulgar leyes adecuadas y deberían tomar medidas más importantes para informarse sobre los últimos desarrollos, dijo.
Más allá de la regulación, los gobiernos, junto con la filantropía, pueden apoyar proyectos científicos con un alto retorno social pero poco retorno financiero o incentivo académico. Hay varias áreas con un tiempo de solución especialmente urgente, incluido el cambio climático, la bioseguridad y la preparación para una pandemia. Es en estas áreas donde necesitamos con mayor urgencia la velocidad y la escala que ofrecen las simulaciones de IA y los laboratorios de conducción autónoma, explicó.
El exCEO de Google remarcó que los conjuntos de datos abiertos son esenciales para aprovechar el poder de la IA en la ciencia, pero requieren el apoyo de los gobiernos y la filantropía. Algunos campos científicos, como la química, tienen datos dispersos que necesitan ser unificados. Otros, como la biología, tienen datos incompletos o desconocidos que necesitan ser descubiertos y registrados.
Como conclusión el experto consideró que aún resta un largo camino para que la IA sea adoptada en forma generalizada en la ciencia y deben hacerse avances sin fallas en varios aspectos, “desde construir las bases de datos correctas hasta implementar las regulaciones correctas, mitigar los sesgos en los algoritmos de IA para garantizar un acceso equitativo a través de las fronteras a recursos como cómputo y GPU”.
Pero como resumen de su posición respecto del uso de la IA en la ciencia dijo que vivimos un “momento profundamente optimista”. La ciencia ha evolucionado a lo largo de la historia, adoptando métodos y herramientas que la hacen más rigurosa y exacta. Pero la inteligencia artificial ofrece algo diferente: la posibilidad de conectar y combinar información de formas nuevas y creativas, que pueden impulsar el avance científico a niveles nunca vistos.
Seguir leyendo