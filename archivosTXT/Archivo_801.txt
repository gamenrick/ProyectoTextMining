Kalyanaramam (AWS): “Invertimos en inteligencia artificial generativa porque su promesa es inmensa”
Autor desconocido
elespanol.com



                                                            Prasad Kalyanaraman, vicepresidente global de infraestructuras de AWS.
                                                

Ser el máximo responsable de infraestructuras en el mayor hiperescalar mundial de la nube, es decir, Amazon Web Services (AWS), supone tener en la cabeza algo así como un mapamundi cruzado por cables, salpicado de ‘regiones de datos’ y punteado por datacenters. Bueno, pues ese es el caso de Prasad Kalyanaramam, vicepresidente global de infraestructuras del gigante cloud.
DISRUPTORES - EL ESPAÑOL conversó con él por videoconferencia sobre el momento, podría decirse que entre enfebrecido y enloquecido, que se vive en su ámbito de responsabilidad tras la arrebatadora aparición de la IA generativa.
“La infraestructura tecnológica es extremadamente importante hoy y también lo es para la economía: Sí. Lo es. En España, tenemos planes para invertir unos 15.700 millones de euros en los próximos años. Amazon es el mayor empleador privado del sector, con unos 25.000 puestos. Así que es de importancia crítica no sólo para el negocio de AWS, sino para todos los países y sus PIB”, subraya Kalyanaramam.
“Por otro lado, nuestra organización ha estado siempre muy enfocada a los clientes. Ellos nos dicen exactamente lo que quieren. Si rebobinamos, años atrás, cuando empezamos, nuestra primera guía era localizar los puntos de dolor con los que tropezaban nuestros clientes. Y en la gran mayoría de las industrias, ya fuera el sector público, ecommerce, atención médica, entretenimiento, finanzas… lo primero que nos decían es que no querían lidiar con la infraestructura sino enfocarse en su negocio”.
“Partimos con ímpetu para decir que no debería ser complicado para los clientes disponer de la tecnología y obtener sus servicios”, prosigue Kalyanaramam. “Tuvimos la suerte de ser el primer gran proveedor de la nube y logramos el liderazgo mucho antes de que otros se fijaran. Jamás consideramos que los competidores no debieran entrar en esta área. Necesitamos que haya mucha competencia. Pero fuimos afortunados escuchando a nuestros clientes, y seguimos haciéndolo. Si mira nuestra lista de más de 200 servicios, cada uno de ellos está basado en lo que nuestros clientes nos han dicho que necesitaban para innovar”.
Lo cierto es que AWS crece a doble dígito (un 19% de aumento de ventas en el tercer trimestre del año), pero también los gastos. Y se disparan las inversiones del sector con la locura de la IA los últimos tres años. ¿No teme que se pueda estar creando una gran burbuja?
“La promesa de la IA generativa es inmensa y estamos superemocionados con ella. Si nos fijamos sólo en los casos de uso, y estamos muy al principio del viaje, las posibilidades de esta tecnología, desde desarrollo de software hasta atención al cliente y atención médica, es enorme la promesa de mejorar la vida de nuestros clientes y mejorar su eficiencia. No podemos caracterizarlo plenamente como una burbuja”, responde.
“Yo diría que hay una afluencia de capital absolutamente significativa. Eso ocurre cuando una tecnología es muy prometedora. Podemos verlo en otras, como las criptomonedas. Pero no creo que esta sea similar a otras burbujas que ha habido. Si se fija en algunos de nuestros servicios como Bedrock y SageMaker [desarrollos destinados a servicios IA en la nube AWS], ya hay unos 100.000 clientes en la plataforma, prácticamente de todas las industrias. Es una demanda real que está ahí y tenemos ya un negocio de varios miles de millones de dólares con la IA generativa. ¿Es proporcional la inversión al crecimiento…?”, se cuestiona.
“Es una etapa muy temprana. Invertimos en cada una de las capas”, prosigue. “Invertimos en la capa de infraestructura, en la que algunas de las compañías más avanzadas en IA, como Anthropic y Mistral, pueden construir sus modelos fundacionales. En el lado de ML, con SageMaker y Bedrock, los clientes pueden también usar la infraestructura subyacente para construir sus modelos Y en la tercera parte, la capa de aplicaciones, tenemos funciones como el reconocimiento y todas las cosas que hacemos con Amazon Connect… Que son aplicaciones con soluciones llave en mano listas para usar por los clientes”.
“creo que estamos haciendo las inversiones correctas”, concluye su alegato. “Es absolutamente cierto que la IA generativa está creciendo a un ritmo feroz y requiere una cantidad de capital bastante importante. Y por eso estamos siendo cuidadosos. Estamos escuchando a nuestros clientes y eso, que nos ha funcionado durante un largo período de tiempo, continuará ayudándonos”.
Lo que se advierte, le decimos, es que con la IA generativa todo va a muy alta velocidad. En los inicios de la nube hicieron falta unos cuantos años para que los usuarios empezasen a entender lo que tenían entre manos.
“Es un planteamiento realmente válido. Nosotros estamos haciendo inversiones muy significativas en IA generativa, tanto en términos de capital como en la cantidad de capacidades que estamos construyendo. Lo que puedo decir es que es mucho más prometedor de lo que podría insinuarse y ya estamos viendo una demanda real. Estamos muy al principio y esa es la parte que tal vez mucha gente no reconoce. Cuando se invirtió en cloud computing, muchos podían hablar de una burbuja, pero ahora tenemos un negocio de 100.000 millones de dólares. Y parte de eso se debe a escuchar a los clientes, nuestra ejecución y nuestro enfoque en la seguridad y funcionalidades”, remacha.
Antes de que hubiera mucho que escuchar sobre la IA, recordamos, AWS fue una de las primeras en desarrollar procesadores propios específicos para trabajar con la inteligencia artificial. Pero parece que Nvidia les ha adelantado en la carrera…
“En nuestra estrategia, siempre queremos construir cada una de las capas, porque no consideramos que una sola talla que valga para todos sea buena solución. Por eso hablo de las tres capas de nuestra IA generativa y nuestro machine learning. Hace muchos años empezamos a invertir en [el procesador] Graviton. Había proveedores como Intel y AMD. Y creímos que podríamos fabricar un chip más eficiente energéticamente.  Era algo que nuestros clientes demandaban. Por eso invertimos. Es un 60% más eficiente que otros procesadores iguales. Y en precio/rendimiento es significativamente mejor, comparado con otras plataformas”.
“Hoy en día tenemos tres tipos separados de instancias”, detalla el vicepresidente de AWS. “Una basada en Intel, otra basada en AMD y la otra, basada en Graviton. Los clientes tienen distintos casos de uso y nosotros seguimos invirtiendo en todas ellas. Y, por cierto, como esas cargas de trabajo no son de talla única, tenemos demanda de las tres plataformas”.
“Con la IA generativa habrá también casos de entrenamiento e inferencia que correrán en plataformas basadas en Nvidia”, admite. “Somos la vanguardia de la tecnología. Lanzamos hace más de un año nuestras instancias P5 y nos estamos preparando para trabajar con Nvidia en la plataforma Grace Hopper. Y luego también en premium. Si bien es cierto que algunos proveedores comenzaron a construir GPU antes que nosotros, hemos estado invirtiendo en nuestra tecnología de chips y diseños de hardware durante mucho tiempo”.
Hay que añadir que, además del chip Graviton, para ejecutar tareas de IA, AWS también ha desarrollado otro específico, el Trainum, para, como su nombre sugiere, entrenar modelos.
“Los clientes siempre quieren opciones”, precisa. “Ninguno quiere que le digan ‘esto es lo único que puedes hacer’. Si fueras a una tienda de comestibles y te dijeran que sólo puedes comer un tipo de pan…”.
Otra cuestión que afecta de lleno a su tarea es la proliferación de centros de datos, que cada vez necesitan más energía y más agua para refrigerarse.
“Es un tema importante, que cualquier hiperescalar sea muy responsable en la forma en que utiliza la capacidad de la infraestructura, ya sea energía o red, sea cual sea el caso. Estamos en este negocio para asegurándonos de que estamos construyendo un mundo mejor para las futuras generaciones. Suelo decir que ‘el mejor paquete de electrones son los electrones que no necesitas’. Lo que quiero decir es que tienes que ser realmente eficiente en el uso de la energía. Es un recurso bastante importante y limitado en todo momento”.
“Hace muchos años nos pusimos el objetivo de usar el 100% de energía renovable para 2030 y ahora estamos muy orgullosos de haber alcanzado ese objetivo siete años antes. En cuanto a la eficiencia energética, es la razón por la que estamos invirtiendo en cosas como el Gravitón y los diseños de nuestros centros de datos. Nuestras inversiones van desde la capa de chips, de hardware y refrigeración, hasta el diseño de centros de datos y redes. Ha sido un esfuerzo sumamente útil para nosotros”, asegura Kalyanaramam.
“Hemos estado invirtiendo en energía renovable y también en energía libre de carbono. Nuestro compromiso climático es que quisiéramos ser cero emisiones netas de carbono en 2040. Estamos en camino de lograrlo. Cuando se piensa en centros de datos para la IA generativa, hay que tener en cuenta si estás siendo eficiente con el uso de los recursos. Y creemos que lo somos. Tenemos nuestro propio equipo de diseño e ingeniería del centro de datos y lo hemos estado haciendo durante mucho tiempo, con algunos objetivos muy audaces sobre energía libre de carbono, así como energía renovable y carbono neto cero. La combinación de eso nos hace altamente responsables”.
“Le daré un dato más”, incide. “Recientemente, un estudio de Accenture sobre la ejecución en AWS frente a la ejecución ‘on prem’ [en instalación propia de cada compañía].  En AWS es 4,1 veces más eficiente energéticamente. Por lo tanto, si un cliente que trabaja ‘on prem’ traslada esa carga a AWS, vería su huella de carbono reducida en un 99%. Ese es un cambio significativo”.
Pues, según datos que facilita la propia AWS, en la actualidad el 85% de las compañías siguen trabajándose sus datos en casa…
“Correcto. Por eso, cuando pregunta por una burbuja en la IA generativa… nadie diría que la computación en la nube es hoy una burbuja y, sin embargo, sólo el 10% o el 15% de las cargas de trabajo se han migrado a la nube”.
Otra cuestión del momento son los orígenes de la energía. La exigencia máxima de los nuevos centros de datos está haciendo que las hiperescalares inviertan también en energía nuclear para asegurarse sus suministros.
“La realidad es que tampoco en esto va a haber una sola talla para todos. Nosotros seguiremos invirtiendo en energía solar y en energía eólica. Contamos con más de 500 proyectos solares y eólicos en todo el mundo. Y vamos a seguir invirtiendo en energía nuclear también, porque creemos que lo que se puede conseguir depende de la ubicación, en cada lugar del mundo. No se puede meter con calzador una solución particular en un lugar específico sin pensar en las implicaciones en el área. Siempre mantenemos nuestras opciones abiertas, con una cosa muy clara: queremos llegar a cero emisiones netas de carbono, y vamos a seguir invirtiendo en energía libre de carbono, de una manera muy responsable”.
En los centros de datos instalados en Aragón, donde se ubica la ‘región española’, AWS puede presumir de utilizar electricidad proveniente de fuentes 100% renovables desde el primer día. Y en cuanto a ‘regiones’ Prasad Kalyanaramam tiene también bajo su responsabilidad cuestiones de futuro, como el desarrollo de otras seis nuevas ‘regiones de datos’, incluyendo la que denomina ‘nube soberana europea’.
“La nube soberana europea es una iniciativa en la que trabajamos con muchos países europeos. Los clientes en Europa quieren tener un entorno de computación en la nube con reglas estrictas de soberanía y eso comienza desde cada capa de la pila. Piense en nuestras inversiones en Nitro, que es una capa de seguridad. Y esta es otra innovación en nuestro diseño de hardware y nuestro diseño de chips, donde nos aseguramos de que los datos de los clientes estén altamente seguros e incluso los operadores de AWS no tengan acceso a ellos”, explica.
“Por eso queremos dar ese tipo de garantías a los clientes en cada capa de la pila. Comienza en la capa Nitro [aislamiento y seguridad para instancias EC2] y pasa a la capa de red entre nuestros centros de datos. Encriptamos todos los datos de la red cuando salen de nuestro control físico. Además, tenemos un montón de requisitos de seguridad física. No es sencillo entrar en un centro de datos nuestro. De hecho, no puedo hacerlo yo mismo, aunque dirijo toda la infraestructura global. Y con razón, porque nuestros clientes quieren la seguridad de los datos. La nube soberana europea es una gran inversión y nos estamos preparando para lanzarla. Ya tenemos muchos clientes en Europa que están muy interesados en operar en la nube soberana europea”.
Pues, hablando de seguridad y de Europa, se acaba de saber que algunos cables submarinos en el Báltico han resultado dañados, probablemente por un sabotaje.
“Si pregunta a alguien en AWS ¿cuál es tu trabajo número uno?, la respuesta constante será ‘seguridad y protección’ [security and safety]”, replica Kalyanaramam. “Operamos centros de datos con grandes cantidades de energía y voltaje y la seguridad de nuestros empleados y la comunidad es muy importante. Si no tienes una nube segura y una infraestructura segura, el resto de las capacidades no importa del todo, ¿verdad? La confianza de los clientes se erosiona muy rápidamente”.
Esa seguridad, como trabajo número uno se refiere también a la propia infraestructura: “Le dedicamos una enorme cantidad de tiempo a la seguridad de esa capa, incluidas las redes. Conectamos nuestras regiones con múltiples redundancias y rutas. Algunas rutas de red pueden cortarse durante un período de tiempo, pero siempre tenemos muchas otras que las rodean. Y todas son físicamente redundantes. La segunda parte es, como dije, que todo nuestro tráfico de red está completamente encriptado. Por lo tanto, cualquier tipo de ataque cibernético que ocurra en la red, en la práctica obtiene datos cifrados, lo cual es inútil”.
Queda otra opción, la comunicación a través del espacio, para lo que ya creó AWS una división espacial hace años. “Para la comunicación satelital, tenemos el servicio Ground Station, un programa espacial bastante bien establecido que permite a agencias gubernamentales y agencias estrictamente reguladas trabajar con nosotros. Hemos invertido en esto, como invertimos en otras muchas áreas, algunas de ellas especulativas y otras basadas en lo que nos dicen los clientes”.
Pues hace unos días, el ex gobernador del Banco Central Europeo y ex primer ministro italiano Mario Draghi dijo en la Conferencia WOBI, en Madrid, que Europa ha perdido ya la carrera de la IA generativa y debería centrarse en la computación cuántica. Otro área nueva…
“Yo No diría que Europa ha perdido realmente la IA generativa, si nos fijamos en [la francesa] Mistral y en Clarity AI, una empresa española que está con nosotros, les hemos ayudado y han estado construyendo su propio modelo fundacional… Estamos muy temprano en este viaje, es demasiado pronto y hay muchas buenas empresas emergentes y buena innovación que en realidad ya está sucediendo en Europa. Algunas de sus empresas, como Iberdrola, es cliente nuestro desde hace mucho tiempo. De hecho, también nos ayudan con energías renovables y han planeado más de 100 aplicaciones de IA generativa para sus propios clientes”, dice Kalyanaramam.
“También hay muchas oportunidades en la computación cuántica. He visto algunos de nuestros trabajos sobre computación cuántica. La computación en la nube aún se encuentra en la fase inicial de investigación y creo que será un lugar para la computación cuántica. En el futuro, valdrá la pena. Cualquier líder bueno y responsable siempre debe centrarse en algunas de estas tecnologías emergentes e invertir con responsabilidad. No debe ser una carrera loca e invertir de repente mucho esfuerzo. Pero tampoco no invertir. Tampoco es buena idea”, concluye.
Antonio Neri, presidente de HPE: "La IA requiere gestionar datos que están distribuidos en entornos híbridos"
Todos contra VMware: tras un 2024 de planificación, el próximo año podría ser el de la migración masiva
Constantino Fernández Pico (Altia): “La tecnología  es una prioridad para las empresas, incluso en contextos difíciles"
Hiperconvergencia, IA y sostenibilidad, la fórmula de Nutanix para ahorrar a las empresas un 30% de energía
Operar con instrumentos financieros o criptomonedas conlleva altos riesgos, incluyendo la pérdida de parte o la totalidad de la inversión, y puede ser una actividad no recomendada para todos los inversores. Los precios de las criptomonedas son extremadamente volátiles y pueden verse afectadas por factores externos como el financiero, el legal o el político. Operar con apalancamiento aumenta significativamente los riesgos de la inversión. Antes de realizar cualquier inversión en instrumentos financieros o criptomonedas debes estar informado de los riesgos asociados de operar en los mercados financieros, considerando tus objetivos de inversión, nivel de experiencia, riesgo y solicitar asesoramiento profesional en el caso de necesitarlo. 

Recuerda que los datos publicados en Invertia no son necesariamente precisos ni emitidos en tiempo real. Los datos y precios contenidos en Invertia no se proveen necesariamente por ningún mercado o bolsa de valores, y pueden diferir del precio real de los mercados, por lo que no son apropiados para tomar decisión de inversión basados en ellos. Invertia no se responsabilizará en ningún caso de las pérdidas o daños provocadas por la actividad inversora que relices basándote en datos de este portal. Queda prohibido usar, guardar, reproducir, mostrar, modificar, transmitir o distribuir los datos mostrados en Invertia sin permiso explícito por parte de Invertia o del proveedor de datos. Todos los derechos de propiedad intelectual están reservados a los proveedores de datos contenidos en Invertia.
© 2024 El León de El Español Publicaciones S.A.