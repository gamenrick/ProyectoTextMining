IA generativa e ingeniería de ‘software’: destinadas a entenderse | Computerworld.es
Autor desconocido
computerworld.es


Desde que hace menos de dos años se popularizase, la inteligencia artificial generativa se ha puesto en boca de todo el mundo; especialmente, del mundo empresarial. Aunque las cifras bailan, los estudios sugieren que su adopción está siendo intensa: la consultora McKinsey, en su última encuesta sobre IA, habla de un 65% de compañías participantes que lo han adoptado, casi el doble que en la anterior edición, de apenas diez meses antes. Un informe reciente del Instituto de Investigación Capgemini apunta a un aumento de la inversión en esta tecnología: el 80% de organizaciones participantes han incrementado la financiación en este ámbito y el 20% restante lo ha mantenido.  
El impacto de la IA en entornos laborales está siendo notable, especialmente en aquellos asociados al área de TIC. Se prevé que un 92% de estos trabajos vivirá una transformación moderada o alta por los avances en herramientas inteligentes. Una de las áreas que resultará de especial importancia será la de la arquitectura de modelos de lenguajes grandes (LLM), la base de la IA generativa. Si ya la inteligencia artificial (sin apellido) tiene influencia en cómo se desempeñan los empleos TIC hoy en día, con una tecnología como la GenIA, que permite la producción de contenidos dándole a un click, es esperable que esto se incremente.  
Un ejemplo claro está en la ingeniería de software. Capgemini cifra en un 85% el personal de este área que adoptará la herramienta en los próximos dos años. El 80% cree, además, que esto les permitirá focalizarse en actividades de mayor valor añadido. “Ya que hablamos de IA, que mejor que los números para entender su impacto”, explica María Borbonés García, Client Engineering Manager and Solutions Architect de IBM España, Portugal, Grecia e Israel, sobre el impacto de la GenIA en programación. “Solo en 2023, ha aumentado en un 59,3% el número de proyectos en GitHub de inteligencia artificial; pero, además, el número de estrellas en GitHub para proyectos de IA ha crecido de 4 millones en 2022 a 12 millones en 2023”. Para Borbonés, se puede hablar de un cambio en el paradigma del desarrollo de software “principalmente en tres tareas: generación de código, explicación-documentación del código y arregla-mantener código”. En el momento actual se está viviendo, indica, “una transformación que permite acelerar el día a día de la comunidad de desarrolladores y, que por tanto, permite reducir tiempos y entregar valor mucho más rápido”.  
Desde Microsoft identifican como clave esa velocidad en el trabajo de la programación, que “ayuda a las organizaciones a liberar más tiempo para la innovación”, y ponen como ejemplo la herramienta de GitHub Copilot: investigaciones de la plataforma estiman que el personal de desarrollo que la emplea es un 55% más rápido. “Además, el uso de la IA permite mejorar las habilidades de los desarrolladores y reducir las brechas de conocimiento al facilitar que los desarrolladores codifiquen en lenguajes con los que están menos familiarizados”, afirma un portavoz de la compañía. Otros informes, como los de la consultora PwC, hablan de un aumento de productividad y velocidad de entre un 20% y un 50%.  
“Esperamos que tenga un impacto masivo y total, la pregunta es el cuándo va a llegar”, valora Gabriel Enríquez, vicepresidente y responsable del área de Ingeniería de Software de Capgemini España, sobre el papel que la GenIA tendrá en programación. Distingue entre dos tipos de aplicaciones: aquellas compañías que emplean la tecnología como un asistente de codificación extra para programar y las que, como su propia firma, consideran que el impacto debe ser mayor. “La parte de codificación, dentro de un proyecto de software, no deja de ser el 30-40% aproximadamente del tiempo total que dedicamos a un proyecto. Por tanto, estamos dejándonos fuera más del 60-70%, de las opciones que tenemos de acelerarlo”. Desde Capgemini se aboga por “una aplicación más holística”, en la que se emplee “para conversar y para generar esa interacción con todos los ámbitos de un proyecto”.  
Esa visión holística que propone Capgemini no está exenta de retos. “La inteligencia artificial generativa permite soluciones creativas increíbles, pero debe implementarse de manera responsable para minimizar el riesgo de generar contenido perjudicial”, afirman desde Microsoft. Esa aplicación adecuada es también uno de los potenciales problemas, si no el principal, que identifican en Capgemini: cualquier persona que la integre debe tener el nivel de conocimiento necesario. Esto puede llegar a suponer un peligro si, por ejemplo, una persona lo emplease a nivel particular y no esponsorizado ni tutorizado. “Al final muchos de los riesgos que tenemos no es tanto que la compañía a nivel corporativo tome una mala decisión”, explica Enríquez, “pero sí que personas individuales puedan por desconocimiento cometer un error”.  
Otro de los retos con los que se enfrentan las personas de desarrollo de software al integrar GenIA: las ya archiconocidas alucinaciones. Esto puede suponer “una pérdida de tiempo y dinero, o lo que es más peligroso, que el resultado que obtenga sea equivocado”, aunque en opinión de Enríquez, se están reduciendo a buen ritmo. “Cada vez que sale un nuevo sistema de inteligencia artificial la evolución con el anterior es abismal, y gran parte de esa diferencia que tienen está enfocada en reducir las alucinaciones”. Enríquez pone el foco en otro elemento con el que se encuentran frecuentemente entre su clientela: “los procesos de inteligencia artificial no son deterministas, es decir, no devuelven siempre la misma respuesta”. Frecuentemente se encuentra con clientes que le comentan cómo la respuesta que les devuelven modelos de este tipo puede cambiar de un día a otro. “Sí, como cualquier desarrollador software al que le pidas que haga un código el martes, y el jueves siguiente te da un código distinto. La gente no programa siempre igual”, contesta: lo importante es centrarse en que el resultado sea válido y correcto.  
En un aspecto más técnico, Borbonés añade otros factores. “Las fuentes de código usadas suponen uno de los principales retos de estos modelos, ya que pueden suponer problemas de calidad, propiedad intelectual o contener información sensible”. Para esto, desde IBM se apuesta por la libertad del uso de los modelos, la transparencia de los procesos de entrenamiento y de los datos utilizados para asegurar la calidad y la transparencia. “Otro de los grandes retos es añadir capacidades e información a estos grandes modelos”. Lo ejemplifica con un caso propio: enseñarles Cobol a sus modelos para que fueran expertos en este lenguaje de programación. Para esto emplearon una herramienta propia creada en colaboración con RedHat, InstructLab, que permite coger un modelo base y alinearlo con nueva información o capacidades para que sea capaz de realizar las tareas. En el proceso se empleó material variado: ocho libros de cobol, un manual de programación de mainframe y un libro de programación en Java, entre otros, mediante los que se generaron automáticamente miles de ejemplos para luego usar los más adecuados. “Con esta metodología, en tan sólo una semana fuimos capaces de mejorar la capacidad de generación de código a un nivel espectacular, algo que no habríamos sido capaces de conseguir durante meses utilizando técnicas de fine tuning”. 
En su experiencia desde Capgemini, Enríquez constata que “nos está costando que los equipos dejen de programar para que se centren en la conversación”. “Estamos viendo un reto de adopción diciendo a la gente: no programes, conversa, y solamente programa al final, cuando ya lo tenemos todo claro y ya nos ha devuelto la inteligencia artificial el código fuente”. Esto lleva, para Enríquez, a que a la hora de crear una aplicación de cero, lo primero es asegurarse de que la IA ha entendido lo que hay que hacer, favorecer una documentación detallada con la que trabaje; un poco en la línea del trabajo en IBM con InstructLab. “La inteligencia artificial no está resultando ser un perfil desarrollador senior, sino que está siendo para nosotros una especie de sabio loco”, completa Enríquez, “que sabe muchísimo, pero que o eres capaz de preguntarle las cosas adecuadamente o te contesta u otra cosa distinta o lo que le da la gana”. El sabio loco que es la IA generativa puede ser un aliado potente, pero más vale aprender a dialogar con él para poder desarrollar todo su potencial.  
La periodista María Ramos Domínguez colabora con las publicaciones COMPUTERWORLD, CSO y CIO en España.