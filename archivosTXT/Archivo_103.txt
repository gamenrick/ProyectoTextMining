Los gigantes de la IA asesoran a nuestros gobiernos, pero son juez y parte | Ideas | EL PAÍS
Eric Sadin
elpais.com

Estamos en una época en la que la inteligencia artificial es omnipresente. No se habla de otra cosa y no hay un día en el que no se haga algún anuncio espectacular. En los últimos 10 años, estas tecnologías cada vez más sofisticadas han sacudido muchos ámbitos de nuestra vida y todo indica que lo harán todavía más en el futuro. Y la sociedad empieza a protestar por tanta perturbación.
De manera que, en un periodo ya de por sí muy turbulento, y como ocurre con muchos asuntos delicados, los gobiernos quieren dar la impresión de que controlan la situación y no están desbordados por los acontecimientos. En este sentido, en la mayoría de las democracias liberales existe un reflejo institucional: en cuanto se manifiesta algún foco de efervescencia, se crea un comité ad hoc.
Con el prerrequisito sistemático —especialmente en relación con la IA— de que los principales criterios de evaluación son los factores económicos y la religión del crecimiento. Además, los políticos están convencidos de que los que están en el corazón de la máquina —empezando por los empresarios y los ingenieros— son los que mejor conocen las conclusiones de todos estos avances.
Sin embargo, ese es un grave error, porque esas personas transmiten una visión determinada del mundo —basada en la hipótesis de que los seres humanos son imperfectos desde el principio y unos sistemas cada vez más omniscientes van a “mejorarlos”— al tiempo que defienden intereses privados.
Eso es lo que hacen en Francia los miembros de la comisión sobre IA que presentó hace unos meses su informe al presidente, Emmanuel Macron; entre ellos estaban Yann LeCun, científico jefe de IA en Meta; Joëlle Barral, directora científica de Google, y Arthur Mensch, fundador de Mistral AI.
Es extraordinario que, a la hora de orientar las políticas nacionales y las inversiones públicas en estos ámbitos, dejemos que unas personas que son a la vez juez y parte no solo nos iluminen, sino que además nos hagan recomendaciones. Esta es una confusión de categorías que, en una República, y desde el punto de vista jurídico, es sencillamente un conflicto de intereses.
La verdad es que cometemos una y otra vez los mismos errores. Es como si no tuviéramos memoria. Porque esas prácticas, en vigor desde los años ochenta, son las que han desembocado en una especialización cada vez mayor de la sociedad, que ve a supuestos sabios —muchas veces procedentes de gabinetes de consultoría— dictar el rumbo de los asuntos públicos desde la cima de sus hipotéticos conocimientos. Y que, por ejemplo, han promovido el uso indiscriminado de pesticidas, la implantación de unos métodos de gestión despiadados y el retroceso de los servicios públicos.
Hoy ni siquiera se pone en duda la legitimidad de esas costumbres. Un ejemplo es la presidenta de la Comisión Europea, Ursula von der Leyen, que quiere crear un “panel mundial de expertos” que saldrán en su mayoría, es de presumir, del mundo de la tecnología, dada la fascinación que despiertan los diseñadores de la IA, a los que se considera los oráculos de nuestro tiempo, a quienes vamos a pedir consejo y sobre los que no cabe la menor duda de que están trabajando por un nuevo mundo feliz.
Por el contrario, lo que habría que hacer con estos temas tan importantes —y con otros decisivos— es dar la vuelta a esos argumentos. Deberíamos trabajar, lejos de la retórica de las “promesas” con las que nos machacan sin descanso, para establecer un peritaje de comprobación: garantizar que quienes se mueven en entornos transformados por la integración de sistemas de inteligencia artificial puedan explicar qué efectos han percibido en las oficinas, la logística, la administración, la escuela, los hospitales, el sistema judicial y así sucesivamente.
De esa forma obtendríamos una interpretación completamente diferente de los fenómenos, basada en la experiencia y las realidades concretas, no en opiniones emitidas desde dentro de una burbuja y ligadas a determinados intereses. Digamos que sería una saludable política del testimonio.
Eso es lo que nos ha faltado, ahora que estamos adquiriendo conciencia de muchos extravíos pasados que han alimentado el resentimiento y la amargura por no tener voz ni voto en el rumbo de nuestro destino. De esta manera inculcaríamos una vitalidad democrática elemental, similar a lo que John Dewey (1859-1952), en El público y sus problemas (1927), llamaba “experimentos sociales”, que consiste en proponernos involucrar a la mayor cantidad de gente posible en una acción común.
Estamos en una época de fundamentalismo de la inteligencia artificial, en el sentido de que se considera una verdad manifiesta que la IA encarna el curso inevitable de la historia, proporciona beneficios sin fin y contribuirá a mejorar todos los aspectos de nuestra vida. Aunque, por supuesto, se entiende que habrá muchas turbulencias en el camino hacia un mundo que pronto estará libre del más mínimo defecto.
Si nos fijamos bien, la constante renovación tecnológica interfiere con el ejercicio de la lucidez en el presente, por lo que, en general, tardamos en comprender los fenómenos. Tal como sucedió con el dogma de la digitalización de la enseñanza pública, que, a principios de la década de 2010, se convirtió en una prioridad absoluta.
Es revelador que esta política, promovida en su momento por los mismos comités y poderosos grupos de presión, esté hoy en tela de juicio en Suecia. Ha llegado el momento de volver a la escritura a mano y la lectura atenta de libros, que ahora están volviendo a considerarse indispensables para el desarrollo de nuestra inteligencia y la formación de mentes libres y críticas.
La realidad es que vivimos un momento de enorme gravedad. A la dimensión cognitiva y organizativa de la IA, que funciona desde hace 15 años y a la que se ha asignado la tarea de orientar y supervisar nuestras acciones con diversos propósitos, ahora, desde que se instaló la versión pública de ChatGPT en noviembre de 2022, se ha añadido un poder intelectual y creativo. Un modelo que tiene tres consecuencias fundamentales.
En primer lugar, la renuncia anunciada a las facultades que nos hacen ser lo que somos, empezando por la de crear lenguaje. En segundo lugar, un régimen de representación en el que ya no seremos capaces de distinguir ni el origen ni la naturaleza de una imagen, lo que desembocará en una indistinción generalizada y muy peligrosa. Por último, un huracán en el sector terciario, que representa más de dos tercios del empleo en los países del Norte, y muchas de cuyas tareas ya pueden asumirlas unos sistemas generativos que operan con muchísima más rapidez y costes mucho menores que un ser humano.
Todos esos cambios sociales, culturales y de civilización son demasiado decisivos para que nos pongamos en manos de pitonisos que tienen una única opinión.
A los Estados solo les preocupa garantizar su “soberanía digital” —concebida en un único sentido económico y geopolítico— y entrar, en cuerpo y alma y de cabeza, en la carrera de la IA. Una especie de argumento acrítico que no conduce más que a una automatización cada vez mayor de los asuntos humanos y asfixia la implantación de cualquier modo de vida basado en unos principios completamente diferentes.
Ha llegado el momento de acabar con esta concepción piramidal y anticuada del saber y construir una sociedad que se mire en el espejo, que sea capaz de hacer públicos los datos que merecen serlo dentro de nuestro cuerpo político común. Es decir, unas condiciones que nos den los medios para contradecir las representaciones dominantes, para hacer valer nuestros derechos fundamentales y nuestras legítimas diferencias, mediante el ejercicio, con hechos, de nuestra propia soberanía.
Éric Sadin es filósofo y especialista en el mundo digital. Acaba de publicar La vida espectral, Pensar la era del metaverso y las inteligencias artificiales generativas (Caja Negra Editora).
Este artículo se publicó originalmente en Le Figaro.
Traducción de María Luisa Rodríguez Tapia.
Apúntate aquí a la newsletter semanal de Ideas.
¿Quieres añadir otro usuario a tu suscripción?
Si continúas leyendo en este dispositivo, no se podrá leer en el otro.
¿Por qué estás viendo esto?
Si quieres compartir tu cuenta, cambia tu suscripción a la modalidad Premium, así podrás añadir otro usuario. Cada uno accederá con su propia cuenta de email, lo que os permitirá personalizar vuestra experiencia en EL PAÍS.
En el caso de no saber quién está usando tu cuenta, te recomendamos cambiar tu contraseña aquí.
Si decides continuar compartiendo tu cuenta, este mensaje se mostrará en tu dispositivo y en el de la otra persona que está usando tu cuenta de forma indefinida, afectando a tu experiencia de lectura. Puedes consultar aquí los términos y condiciones de la suscripción digital.
O suscríbete para leer sin límites
Suscríbete y lee sin límites