¿Qué es el entrenamiento distribuido? - Azure Machine Learning | Microsoft Learn
sdgilley
microsoft.com

Este explorador ya no se admite.
Actualice a Microsoft Edge para aprovechar las características y actualizaciones de seguridad más recientes, y disponer de soporte técnico.
En este artículo, obtendrá información sobre el entrenamiento distribuido y sobre cómo lo admite Azure Machine Learning para los modelos de aprendizaje profundo.
En el entrenamiento distribuido, la carga de trabajo para entrenar un modelo se divide y se comparte entre varios procesadores pequeños, denominados "nodos de trabajo". Estos nodos de trabajo trabajan en paralelo para acelerar el entrenamiento del modelo. El entrenamiento distribuido se puede usar para modelos tradicionales de Machine Learning, pero es más adecuado para tareas de proceso y que requieren mucho tiempo, como el aprendizaje profundo para entrenar redes neuronales profundas.
Hay dos tipos principales de entrenamiento distribuido: el paralelismo de datos y el paralelismo de modelos. En el caso del entrenamiento distribuido en modelos de aprendizaje profundo, el SDK de Azure Machine Learning en Python admite integraciones con PyTorch y TensorFlow. Ambos son marcos populares que emplean paralelismo de datos para el entrenamiento distribuido y pueden usar Horovod para optimizar las velocidades de proceso.
Entrenamiento distribuido con PyTorch
Entrenamiento distribuido con TensorFlow
Para los modelos de Machine Learning que no requieren entrenamiento distribuido, consulte el artículo Entrenamiento de modelos con Azure Machine Learning para conocer las distintas formas de entrenar modelos mediante el SDK de Python.
De entre los dos enfoques de entrenamiento distribuido, el paralelismo de datos es el más sencillo de implementar y es suficiente para la mayoría de los casos de uso.
En este enfoque, los datos se dividen en particiones, donde el número de particiones es igual al número total de nodos disponibles en el clúster de proceso o el proceso sin servidor. El modelo se copia en cada uno de estos nodos de trabajo y cada nodo opera en su propio subconjunto de los datos. Tenga en cuenta que cada nodo debe tener la capacidad de admitir el modelo que se está entrenando; es decir, todo el modelo debe ajustarse a cada nodo.
En el siguiente diagrama se ilustra este enfoque.


Cada uno de los nodos calcula de forma independiente los errores entre sus predicciones en sus ejemplos de entrenamiento y las salidas etiquetadas. A su vez, cada nodo actualiza su modelo en función de los errores encontrados y debe comunicar todos sus cambios al resto de nodos para que actualicen sus modelos correspondientes. Los nodos de trabajo deben sincronizar los parámetros del modelo, o gradientes, al final del cálculo por lotes para asegurarse de que están entrenando un modelo coherente.
En el paralelismo de modelos, también conocido como paralelismo de redes, el modelo se segmenta en diferentes partes que se pueden ejecutar simultáneamente en nodos diferentes, y cada una de ellas se ejecuta con los mismos datos. La escalabilidad de este método depende del grado de paralelización de tareas del algoritmo y es más complejo de implementar que el paralelismo de datos.
En el paralelismo de modelos, los nodos de trabajo solo tienen que sincronizar los parámetros compartidos (normalmente una vez por cada paso de propagación hacia delante o hacia atrás). Además, los modelos más grandes no son un problema, ya que cada nodo trabaja en una subsección del modelo en los mismos datos de entrenamiento.
¿Le ha resultado útil esta página?