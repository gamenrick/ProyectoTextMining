ChatGPT entre los útiles escolares en este regreso a clases | WIRED
Pia Ceres
wired.com

El año pasado, la presentación del alarmantemente sofisticado chatbot de OpenAI hizo que los educadores entraran en una crisis (sí, además de las que los alumnos generan). Surgió entonces el temor a que la IA generativa permitiera el plagio y el engaño desenfrenados, e incluso que dejara obsoletas las materias de lenguaje. Las universidades debatieron la actualización de las políticas sobre plagio. Algunos distritos escolares prohibieron directamente ChatGPT en sus redes. Ahora, otro curso escolar más presenta nuevos retos y, para algunos, nuevas oportunidades.
Después de casi un año con el boom la IA generativa, la alarma inicial entre los educadores ha dado paso al pragmatismo. Muchos estudiantes se han dado cuenta de la tendencia de la tecnología a fabricar información. David Banks, rector de las escuelas públicas de Nueva York, escribió que el distrito estaba ahora "decidido a adoptar" la IA generativa, a pesar de haberla prohibido en las redes escolares el año pasado. Muchos profesores se centran ahora en tareas que requieren pensamiento crítico, utilizan la IA para suscitar nuevas conversaciones en el aula y desconfían de las herramientas que prometen ser capaces de detectar a los tramposos de la IA.
Instituciones y educadores también se encuentran ahora en la incómoda situación de tener que lidiar, no solo con una tecnología que no pidieron, sino también con algo que podría remodelar radicalmente su trabajo y el mundo en el que crecerán sus alumnos.
Lisa Parry, directora de una escuela K-12 y profesora de Lengua y Composición Inglesa en la zona rural de Arlington, en Dakota del Sur, EE UU, dice que este año escolar está "adoptando con cautela" la IA generativa. Le sigue preocupando que ChatGPT, que no está bloqueado en las redes escolares, pueda permitir hacer trampa. Pero también señala que el plagio siempre ha sido una preocupación para los profesores, razón por la cual, cada año, hace que sus alumnos escriban sus primeras tareas en clase para poder hacerse una idea de sus capacidades.
Este año, Parry planea que sus estudiantes de inglés utilicen ChatGPT como "un motor de búsqueda con esteroides" para ayudarles a pensar en temas de ensayo. "ChatGPT tiene un gran poder para hacer el bien, y tiene poder para socavar lo que intentamos hacer aquí académicamente", aclara. "Pero no quiero tirar al bebé con el agua de la bañera", añade.
El pensamiento de Parry está en línea con la idea de que ChatGPT podría hacer por la escritura y la investigación lo que una calculadora hizo por las matemáticas: ayudar a los estudiantes en las partes más tediosas del trabajo y permitirles conseguir más. Pero los educadores también están lidiando con la tecnología antes de que nadie entienda realmente qué trabajos o tareas puede automatizar, o antes de que haya consenso sobre la mejor forma de utilizarla. "Nos enseñan las diferentes tecnologías a medida que van surgiendo", refiere Lalitha Vasudevan, profesora de tecnología y educación en el Teachers College de la Universidad de Columbia. "Pero en realidad no tenemos ni idea de cómo van a funcionar", confiesa.
La carrera por eliminar a quienes hacen trampa, con IA generativa o sin ella, continúa. Turnitin, el popular comprobador de plagios, ha desarrollado una herramienta de detección de IA que señala qué partes de un escrito pueden haber sido generadas por inteligencia artificial. Entre abril y julio, Turnitin revisó más de 65 millones de trabajos y descubrió que el 10.3% de ellos contenía IA en más del 20% de su contenido, y que el 3.3% de los trabajos podían haber sido generados por IA en un 80%. Pero estos sistemas no son infalibles. Turnitin asegura que a la hora de determinar si una frase ha sido escrita por IA, su detector tiene una tasa de falsos positivos del 4% .
Debido a esos falsos positivos, Turnitin también recomienda a los educadores mantener conversaciones con los estudiantes en lugar de suspenderles o acusarles de hacer trampa. "Se supone que es información para que el educador decida qué quiere hacer con ella", aclara Annie Chechitelli, directora de producto de Turnitin. "No es perfecto".
Las limitaciones de la herramienta de Turnitin para detectar trabajos generados por IA se hacen eco de las propias limitaciones de la IA generativa. Al igual que ChatGPT, que se entrenó utilizando contenido extraído de la web, el sistema de Turnitin se entrenó con trabajos enviados por estudiantes y otros escritos por IA. En un intento de minimizar los sesgos, se incluyeron trabajos de estudiantes de inglés y de grupos subrepresentados, como alumnos de universidades históricamente negras. Existe la preocupación de que las herramientas de detección de IA sean más propensas a marcar erróneamente algunos estilos de escritura o vocabularios como generados por IA si se entrenan demasiado en ensayos de estudiantes de un determinado origen, como alumnos blancos, de habla inglesa o con ingresos elevados.
Pero sigue habiendo riesgos de sesgo. Los estudiantes de inglés pueden ser más propensos a ser marcados; un estudio reciente descubrió una tasa de falsos positivos del 61.3% al pasar exámenes del Test of English as a Foreign Language (TOEFL) por siete diferentes detectores de IA. En el estudio no se utilizó el de Turnitin. Los errores pueden deberse en parte a que los estudiantes de inglés y la inteligencia artificial tienen algo en común: ambos utilizan frases menos complejas y un vocabulario menos sofisticado. Los detectores "realmente no funcionan muy bien", señala James Zou, profesor de informática y ciencia de datos biomédicos en la Universidad de Stanford, quien trabajó en la investigación. "Pueden llevar a acusaciones peligrosas contra los estudiantes".
Como resultado, algunas escuelas se están oponiendo a las herramientas que buscan detectar el trabajo generado por inteligencia artificial. El Centro de Enseñanza de la Universidad de Pittsburgh ha declarado recientemente que no respalda ninguna herramienta de detección de IA, debido a su falta de fiabilidad, y ha desactivado la herramienta de detección de IA en Turnitin. La Universidad de Vanderbilt también dijo en agosto que desactivaría el detector de IA.
Incluso OpenAI, creadora de ChatGPT, ha decidido que no puede determinar con eficacia si el texto ha sido escrito por su chatbot o no. En julio, la empresa cerró una herramienta llamada AI Classifier, lanzada apenas unos meses antes, en enero. Alegó un bajo índice de precisión a la hora de determinar el origen del texto. OpenAI anunció entonces que seguía investigando una mejor forma de detectar la IA en el lenguaje. La empresa declinó hacer más comentarios sobre la imprecisión de la herramienta o sobre lo que planea construir a continuación.
Dado que los sistemas de IA no están a la altura, es probable que algunos profesores recurran a otros medios para evitar las trampas. La supervisión en directo, en la que un observador ve a alguien completar un examen o una tarea a través de una cámara web, se hizo muy popular durante la pandemia, y no ha desaparecido; el software de control, que rastrea lo que hacen los estudiantes en sus dispositivos, también sigue utilizándose. Aunque ambos conllevan importantes problemas de privacidad.
La IA generativa asombra por su capacidad para regurgitar internet, pero no es la mejor pensadora crítica. Algunos profesores están diseñando planes de clase específicamente con esto en mente. Los educadores pueden probar a dar sus tareas a un chatbot y ver qué se genera, propone Emily Isaacs, directora ejecutiva de la Oficina para la Excelencia del Profesorado de la Universidad Estatal de Montclair, en Nueva Jersey. Si un chatbot puede generar fácilmente un trabajo decente, podría significar que la tarea necesita un ajuste.
Este juego del gato y el ratón no es nada nuevo. Isaacs opina que el reto que plantea la IA generativa es similar al de copiar de los libros o de internet. La tarea de los educadores, recuerda, es persuadir a los alumnos sobre el hecho de que "aprender vale la pena".
David Joyner, profesor del Instituto de Tecnología de Georgia, anima a sus alumnos a considerar la inteligencia artificial como una herramienta de aprendizaje, no como un sustituto del aprendizaje. En mayo, Joyner, que imparte clases en la Facultad de Informática, añadió una política sobre chatbot de IA a su programa de estudios.
En un hilo en X, la red social antes conocida como Twitter, en el que describe el borrador de su política, compara el uso de un chatbot de IA con el trabajo con un compañero. "Puedes hablar de tus ideas y trabajar con otras personas, tanto dentro como fuera de la clase, así como con asistentes basados en IA", escribió. Pero, al igual que en la interacción con un compañero de clase, el trabajo presentado tiene que ser del propio estudiante. "Los estudiantes van a tener que saber cómo utilizar este tipo de cosas", advierte Joyner. Así que le toca a él establecer tareas que sean "duraderas" contra las trampas asistidas por IA, pero también guiar a sus alumnos para que utilicen la inteligencia artificial de forma eficaz.
Los profesores de secundaria también se sienten obligados a preparar a sus estudiantes para un mundo cada vez más moldeado por la IA. Este año, Theresa Robertson, profesora de STEM en una escuela pública de un suburbio de Kansas City, Missouri, guiará a sus alumnos de sexto año en conversaciones sobre qué es la inteligencia artificial y cómo podría cambiar su forma de trabajar y vivir. "En algún momento, tienes que decidir: ¿Es algo que vamos a esconder debajo de la alfombra o vamos a afrontarlo? ¿Cómo exponemos ahora a los niños a ella y trabajamos el aspecto ético de la misma, y hacemos que realmente la entiendan?", comenta.
Todavía no hay consenso o una "mejor práctica" para enseñar en un mundo post ChatGPT. En Estados Unidos, las orientaciones para los profesores son dispersas. Aunque el Departamento de Educación publicó un informe con recomendaciones sobre la IA en la enseñanza y el aprendizaje, los distritos escolares decidirán en última instancia si los estudiantes pueden acceder a ChatGPT en las aulas este año. Como resultado, los mayores distritos escolares de EE UU están adoptando posturas muy diferentes. El invierno pasado, el Distrito Escolar Unificado de Los Ángeles bloqueó ChatGPT y no ha cambiado su política. Pero en Chicago y Nueva York, las escuelas públicas no bloquean actualmente el acceso al chatbot.
Los profesores también siguen recuperándose del último gran acontecimiento que trastornó la educación: la pandemia de Covid-19. Jeromie Whalen, profesor de comunicación y producción audiovisual en un instituto, estudiante de doctorado en la Universidad de Massachusetts Amherst, y quien estudia las experiencias de los profesores de primaria y secundaria con la tecnología, sostiene que muchos educadores desconfían de ChatGPT: "Todavía nos estamos recuperando del aprendizaje a distancia de emergencia. Todavía estamos abordando esas lagunas de aprendizaje", recuerda Whalen. Para los profesores agotados, incorporar ChatGPT a la planificación de las clases no es tanto una oportunidad emocionante como una tarea más en una interminable lista de tareas pendientes.
Aun así, existe el peligro de prohibir rotundamente ChatGPT. Noemi Waight, profesora asociada de enseñanza de las ciencias en la Universidad de Buffalo, estudia cómo utilizan la tecnología los profesores de ciencias de primaria y secundaria. Señala que, aunque la herramienta supone una responsabilidad adicional para los profesores, prohibir ChatGPT en las escuelas públicas niega a los estudiantes la oportunidad de aprender de la tecnología. Los estudiantes menos favorecidos económicamente y los de color, que dependen desproporcionadamente más de los dispositivos escolares y del acceso a internet, serían los más perjudicados, profundizando la brecha digital: "Tendremos que estar muy atentos al aspecto equitativo y orientado a la justicia de la inteligencia artificial", alerta.
Para otros profesores, la IA generativa está abriendo nuevos debates. Bill Selak, director de tecnología de la Hillbrook School de Los Gatos, California, empezó a utilizar ChatGPT para construir indicaciones para Midjourney, un generador de imágenes de IA, tras el tiroteo masivo en la Covenant School de Nashville en marzo de 2023. Selak destaca que no es un ilustrador nato y que buscaba una forma de procesar su dolor por el tiroteo en la escuela. Midjourney le proporcionó una imagen que le ayudó a canalizarlo, y decidió llevar la idea a dos clases de quinto año del colegio donde trabaja.
Cada clase eligió un tema importante: el racismo en Estados Unidos y el cambio climático. Selak cuenta que trabajó con cada clase para generar una pregunta con ChatGPT sobre los temas, y luego los introdujo en Midjourney. Después refinó los resultados. Midjourney dio a los alumnos tres caras de distintos colores para el tema del racismo, y otra que mostraba tres escenas exteriores diferentes con casas y chimeneas, conectadas por una carretera. Los alumnos debatieron sobre el simbolismo de cada imagen.
Según Selak, la IA generativa permitió a los estudiantes procesar y debatir estas ideas tan importantes y emotivas de una forma que no habrían podido hacerlo con una redacción. "Les dio la oportunidad de participar de una forma que no es habitual en estas grandes conversaciones", apunta Selak, "y me dio la sensación de que amplificaba la creatividad humana de una forma que no esperaba".
Artículo originalmente publicado en WIRED. Adaptado por Mauricio Serfatty Godoy.
Algunos estudios e informes que se mencionan en este artículo:
WIRED EN ESPAÑOL
Otros Sitios de Condé Nast
© 2024 Condé Nast México S.A de C.V. Todos los derechos reservados. Convenio del usuario Aviso de Privacidad Términos y condiciones