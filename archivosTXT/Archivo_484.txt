El inmenso poder y los peligros del código generado por IA | WIRED
Will Knight
wired.com

En junio de 2021, GitHub anunció Copilot, una especie de autocompletado para código informático, impulsado por la tecnología de generación de texto de OpenAI. Fue una primera ojeada al potencial impresionante de la inteligencia artificial generativa para automatizar un trabajo. Dos años después, Copilot es uno de los ejemplos más maduros de cómo la tecnología puede asumir tareas que antes tenían que hacerse a mano.
Esta semana, Github publicó un informe, con base en los datos de casi un millón de programadores que pagan por utilizar Copilot. Muestra hasta qué punto se ha transformado la programación con IA generativa. En promedio, aceptaron las propuestas del asistente de IA en un 30% de las ocasiones, lo que sugiere que el sistema es notablemente bueno a la hora de predecir código útil.
A medida que los programadores se familiarizan con el asistente Copilot de GitHub, aceptan más sugerencias.
El sorprendente gráfico anterior muestra cómo los usuarios tienden a aceptar más sugerencias de Copilot a medida que pasan más meses utilizando la herramienta. El informe también concluye que los programadores ayudados por la IA ven aumentar su productividad con el tiempo, con base en el hecho de que un estudio anterior sobre Copilot informó acerca de una relación entre el número de sugerencias aceptadas y la productividad de un programador. El nuevo informe de GitHub señala que los mayores aumentos de productividad se observaron entre los profesionales con menos experiencia.
A primera vista, es una imagen impresionante de una tecnología novedosa que rápidamente demuestra su valor. Cualquier tecnología que aumente la productividad y potencie las capacidades de los trabajadores menos calificados puede ser una bendición, tanto para las personas como para la economía en general. GitHub hace algunas conjeturas y estima que para 2030, la programación con IA podría aumentar el PIB mundial en 1.5 billones de dólares.
Pero el gráfico de GitHub que muestra a los programadores vinculándose con Copilot me recordó otro estudio del que oí hablar recientemente, mientras conversaba con Talia Ringer, una profesora de la Universidad de Illinois en Urbana-Champaign, en Estados Unidos, sobre la relación de los programadores con herramientas como Copilot.
A finales del año pasado, un equipo de la Universidad de Stanford publicó un trabajo de investigación en el que se analizaba cómo afectaba a la calidad del código la utilización de un asistente de IA que ellos mismos habían creado. Los investigadores descubrieron que los programadores que recibían sugerencias de la IA tendían a incluir más errores en su código final, mientras que los que tenían acceso a la herramienta además creían que su código era más seguro. "Probablemente, codificar junto con la IA conlleva tanto beneficios como riesgos", opina Ringer. "Más código no es mejor código".
Si tenemos en cuenta la naturaleza de la programación, este hallazgo no es sorprendente. Como escribió Clive Thompson en un reportaje de WIRED de 2022, Copilot puede parecer milagroso, pero sus sugerencias tienen base en patrones del trabajo de otros programadores, que pueden ser erróneos. Estas suposiciones pueden crear errores endemoniadamente difíciles de detectar, sobre todo cuando uno está ‘hechizado’ por lo buena que suele ser la herramienta.
En otros campos de la ingeniería sabemos que los humanos pueden caer en el exceso de confianza en la automatización. La Autoridad Federal de Aviación de Estados Unidos ha advertido en repetidas ocasiones que algunos capitanes se están volviendo tan dependientes del piloto automático, que sus habilidades de vuelo se están atrofiando. Un fenómeno similar se observa en los vehículos autónomos, que requieren una vigilancia extraordinaria para evitar fallos, poco frecuentes, pero potencialmente mortales.
Esta paradoja puede ser fundamental para el desarrollo de la IA generativa y para saber adónde nos llevará. La tecnología ya parece estar provocando una espiral descendente en la calidad de los contenidos web, a medida que los sitios reputados se ven inundados de basura generada por la IA, proliferan las páginas web de spam, y los chatbots intentan aumentar artificialmente el engagement.
Esto no quiere decir que la IA generativa sea un fracaso. Cada vez hay más estudios que demuestran que las herramientas de ese tipo pueden aumentar el rendimiento y la felicidad de algunos trabajadores, como los que atienden las llamadas de atención al cliente. Otros estudios tampoco han detectado un aumento de los fallos de seguridad cuando los desarrolladores utilizan un asistente de IA. Por su parte, GitHub está investigando cómo codificar de forma segura con la ayuda de la IA. En febrero anunció una nueva función Copilot que intenta detectar las vulnerabilidades generadas por el modelo subyacente.
Pero los complejos efectos de la generación de código constituyen una advertencia para las empresas que trabajan en el despliegue de algoritmos generativos para otros casos de uso.
Los reguladores y legisladores que muestran más preocupación por la IA también deberían tomar nota. Con tanto entusiasmo por el potencial de la tecnología, y especulaciones descabelladas sobre cómo podría conquistar el mundo, podrían pasarse por alto pruebas más sutiles y sustanciales de cómo están funcionando las implementaciones de IA. Casi todo en nuestro futuro tendrá su base en software y, si no tenemos cuidado, también podría estar plagado de errores generados por la IA.
Artículo originalmente publicado en WIRED. Adaptado por Mauricio Serfatty Godoy.
Algunos estudios mencionados en este artículo:
WIRED EN ESPAÑOL
Otros Sitios de Condé Nast
© 2024 Condé Nast México S.A de C.V. Todos los derechos reservados. Convenio del usuario Aviso de Privacidad Términos y condiciones