La IA, en los dos lados de la ciberseguridad: aliada y amenaza en el mundo digital
BBVA
bbva.com

Cerrar panel
BBVA.com
Pulsar Enter
Búsqueda Predictiva
Cerrar panel
Cerrar panel
Cerrar panel
BBVA.com
EnglishEspañol
Cerrar panel
Innovación
La inteligencia artificial no es buena ni mala por sí misma, sino que, al igual que sucede con cualquier herramienta, todo depende del uso que se haga de ella. De hecho, en el ámbito de la ciberseguridad tiene un doble papel: mientras los equipos de seguridad utilizan sus capacidades para reforzar las defensas, los ciberdelincuentes la emplean para mejorar sus ataques.
Un mensaje que advierte sobre la suspensión temporal de una cuenta bancaria, otro que informa de un paquete no entregado y uno que anuncia la obtención de una tarjeta regalo. Además, incluyen un enlace que solicita al usuario introducir sus datos personales. Sin embargo, ninguno es lo que parece. Todos pueden ser ejemplos de ingeniería social, un conjunto de técnicas de manipulación diseñadas para engañar a las personas y obtener beneficios del engaño. Mecanismos que, con el reciente auge de la inteligencia artificial generativa, han aumentado tanto en número como en complejidad.
Actualidad
El 'Mapa del Emprendimiento 2024', elaborado por South Summit para ofrecer una radiografía del tejido emprendedor español, refleja cómo la madurez del ecosistema sigue en ascenso con la rápida adopción de nuevas tecnologías y la incorporación de la sostenibilidad en la cadena de valor. Sin embargo, persisten algunos desafíos, como ampliar la presencia femenina en un entorno donde las mujeres solo representan el 20%.
Hasta ahora, la realización de un 'phishing', uno de los ataques de ingeniería social más comunes, requería la realización de una investigación exhaustiva de la víctima que se tenía que hacer fundamentalmente de forma manual (lenta y costosa), por lo que estos ataques eran menos frecuentes. Sin embargo, las capacidades de inteligencia artificial generativa permiten automatizar esta búsqueda y realizar ataques dirigidos de forma masiva. De hecho, los ataques de 'phishing' promovidos por IA generativa han incrementado un 60% en todo el mundo entre enero y diciembre de 2023, según un informe de Zscaler, empresa estadounidense de ciberseguridad.
Además, hay otro aspecto clave: la IA generativa facilita la creación inmediata de mensajes redactados de forma que parecen legítimos y que tienen más probabilidades de engañar a las víctimas, ya sea a través de correos, llamadas y SMS que simulan ser entidades legítimas como una red social, un banco o una institución pública.
Internet es un entorno en el que los estafadores no tienen que exponerse físicamente para dar sus golpes, lo cual les proporciona una cómoda sensación de seguridad. Asimismo, existen muchas formas de automatizar tareas, que hace que los delincuentes puedan afectar a cifras astronómicas de posibles víctimas casi sin esfuerzo.
Por este motivo, la ingeniería social a través de Internet no ha dejado de evolucionar junto con la digitalización de las empresas y de las personas. Si bien inicialmente solo se realizaba a través de correos electrónicos (lo que se conoce como 'phishing'), progresivamente se han ido incorporando nuevos canales a los engaños, como los sistemas de mensajería instantánea y redes sociales ('SMSishing'), las memorias USB extraviadas ('baiting'), las llamadas telefónicas ('vishing'), y más recientemente los códigos QR, que están cada vez más presentes tanto en el entorno físico como en el digital ('QRishing').
A lo largo del tiempo los ataques de ingeniería social también se han ido haciendo cada vez más sofisticados. Al inicio, consistían en envíos masivos de mensajes con contenidos muy generales, cada vez se han ido perfeccionando más, dirigiéndose a colectivos específicos y tratando temáticas adaptadas a ese colectivo, de modo que el engaño sea mucho más difícil de identificar.
De esta forma, el 'phishing' se enmascara en un mensaje aparentemente procedente de un contacto real, o simula un mensaje correspondiente a un proceso real de la empresa de la víctima, por ejemplo. Esto es lo que se conoce como 'phishing' dirigido, o comúnmente en su término en inglés 'spear phishing'. Y, aunque los correos electrónicos de 'phishing' dirigido representan solo el 0,1% de todos los emails enviados, estos son responsables del 66% de todas las brechas de seguridad, según un informe de Barracuda, compañía de seguridad estadounidense.
Como consecuencia, los ciberataques recibidos en España han incrementado de manera notable. En 2023 alcanzaron una cifra récord de 107.777 incidentes registrados, lo que supone un aumento del 94% con respecto al 2022, según un informe del Centro Criptológico Nacional (CCN). Por esta razón, la ciberseguridad es el problema que más preocupa al 48% de las empresas españolas, las cuales han incrementado en 4,7 millones de euros su presupuesto destinado a técnicos de la información, según el Informe de Ciberpreparación de la aseguradora Hiscox.
También los objetivos de la ingeniería social han ido evolucionando con el tiempo. Si bien al principio fundamentalmente buscaban información fácilmente convertible en dinero, como contraseñas de los bancos, o directamente engañar a la víctima para que realice un pago al atacante, con la mejora en los sistemas de verificación de la identidad del usuario, como la biometría, cada vez más el objetivo consiste en instalar un 'malware' en el dispositivo de la víctima que permita al atacante obtener el control y acceder desde él a las tareas que considere.
Imagen generada con Midjourney (IA).
Con todos estos avances en materia de ingeniería social, cabe plantearse si ya hemos llegado al máximo de sofisticación o todavía quedan nuevos caminos por explorar. Y en este punto hacen su aparición los grandes descubrimientos que se han producido en inteligencia artificial en los últimos años.
La IA generativa ha facilitado más que nunca la práctica del 'phishing' y otras estafas digitales. Esto ha dado lugar a la aparición de programas como WormGPT, un modelo de lenguaje de inteligencia artificial entrenado con datos fraudulentos diseñado para ayudar a los 'hackers' con sus actividades delictivas.
Así, los timos derivados de la IA generativa son más sofisticados y pueden adoptar diversas formas, según un artículo de MIT Technology Review:
"Cada vez es más difícil creer lo que leemos, vemos y oímos en Internet. Eso es preocupante, tanto porque va a haber personas víctimas de 'deepfakes' como porque habrá gente que alegue falsamente la 'defensa de la IA' para eludir responsabilidades", explicó Hany Farid, profesor de ciencias de la computación en la Universidad de California, en una entrevista.
A pesar de que la inteligencia artificial se utiliza para perfeccionar los ciberataques, también se emplea para lo contrario: aumentar la seguridad del mundo digital. Los sistemas de IA se utilizan desde hace tiempo para la detección de anomalías que puedan indicar la existencia de un ciberataque o de un fraude. Sin embargo, con los nuevos avances, los sistemas de defensa son mucho más precisos a la hora de detectar amenazas cada vez más sofisticadas, permitiendo su prevención y eliminación temprana.
Los sistemas de inteligencia artificial también pueden utilizarse para automatizar tareas de supervisión de la ciberseguridad, de modo que se puedan hacer más rápido y evitando un gran número de errores humanos. Esto tiene varias ventajas para la ciberdefensa, según un artículo de IBM:
Aunque es importante contar con mecanismos de defensa contra ataques fraudulentos, la educación de los usuarios para detectar engaños también es fundamental. Por eso, el Instituto Nacional de Ciberseguridad (INCIBE) ofrece una serie de recomendaciones para identificar este tipo de fraudes:
Por tanto, aunque las distintas técnicas de ingeniería social han evolucionado con el fin de aumentar su rentabilidad para los atacantes, los sistemas de defensa también han mejorado en paralelo para mejorar sus capacidades de defensa.
La inteligencia artificial tiene potencial para cambiar las reglas del juego, tanto desde el punto de vista de los atacantes como de los equipos de ciberseguridad. Vistas las posibilidades que la inteligencia artificial aporta a la ingeniería social, solo la aplicación de técnicas de inteligencia artificial podrá mantenernos a salvo de los nuevos ciberataques.
Teniendo en cuenta todas estas tendencias conviene que usuarios y empresas extremen las precauciones para detectar cualquier tipo de engaño antes de que sea tarde, avisar a los interesados cuando se detecte algún intento de fraude, y buscar ayuda especializada cuando se tengan dudas.
Sigue leyendo sobre

Échale un vistazo
Newsletter
Resultados BBVA
Aprendemos Juntos
Reporte Vulnerabilidades
© Banco Bilbao Vizcaya Argentaria, S.A. 2024