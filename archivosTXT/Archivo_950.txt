Inteligencia artificial: oportunidades y desafíos | Temas | Parlamento Europeo
Autor desconocido
europa.eu

La inteligencia artificial (IA) está cada vez más presente en nuestras vidas. Descubra cuáles son las oportunidades y las amenazas para la seguridad, democracia, negocios y empleos.
El crecimiento y la economía de la UE dependen en gran medida del uso de los datos y de las tecnologías conectadas. La inteligencia artificial ya afecta, de forma positiva o negativa, a la vida diaria de los europeos.
En junio de 2023, el Parlamento Europeo adoptó su posición negociadora sobre la ley de IA, el primer conjunto de normas del mundo que gestiona en profundidad los riesgos de la IA. A continuación se exponen algunas oportunidades y amenazas que serán clave para futuras aplicaciones de la IA. 
Lea más sobre qué es la inteligencia articial y cómo se usa. 
Los países europeos están avanzados en la industria digital y en las aplicaciones entre empresas. Con una infrastructura de gran calidad y un marco regulatorio que proteja la privacidad y la libertad d expresión, la UE podría llegar a ser un líder global en la economía de datos y en sus aplicaciones.

La inteligencia artificial sirve para ayudar a que los ciudadanos mejoren la atención médica, los coches y otros medios de transporte sean más seguros y a que los productos y servicios sean personalizados, más baratos y duraderos. También facilita el acceso a la información, educación y formación, lo que se puso especialmente de manifiesto con la necesidad del aprendizaje a distancia durante la pandemia de Covid-19. Además, la IA puede hacer que los lugares de trabajo sean más seguros, ya que los robots realizarían para las tareas más peligrosas, y crearía más puestos de trabajo a medida que la industria y las empresas se van adaptando a esta tecnología. 

La IA permite el desarrollo de una nueva generación de productos y servicios, incluso en sectores en los que las empresas europeas ya tienen posiciones sólidas: economía verde y circular, maquinaria, agricultura, salud, moda, turismo. La IA se usa para agilizar y optimizar las rutas de venta, mejorar el mantenimiento de las máquinas, aumentar la producción y la calidad, mejorar el servicio al cliente y ahorrar energía.
La IA en los servicios públicos reduciría los costes y ofrecería oportunidades nuevas en el transporte público, educación, energía, gestión de los residuos y mejoraría la sostenibilidad de los productos. En definitiva, podría contribuir a alcanzar los objetivos del Pacto Verde Europeo. 
El escrutino basado en los datos, la prevención de la desinformación y de los ciberataques y el acceso a la información de calidad podrían hacer más fuerte a la democracia. La diversidad y la transparencia también se beneficiarían de la IA, al utilizarse, por ejemplo, datos analíticos en los procesos de contratación y evitar la posibilidad de prejuicios. 
Se prevé que la inteligencia artificial se utilice más en la prevención del delito y en el sistema de justicia penal, ya que los conjuntos de datos masivos podrían procesarse más rápido, los riesgos de fuga de los prisioneros se evaluarían con mayor precisión, el crimen o incluso los ataques terroristas se podrían predecir y prevenir. Las plataformas en línea ya lo utilizan para detectar y reaccionar ante comportamientos en línea ilegales e inapropiados.
En el campo militar, la IA podría usarse para estrategias de defensa y ataque en piratería y phishing o para atacar sistemas clave en la guerra cibernética.
La creciente dependencia de los sistemas de IA plantea riesgos.
La infrautilización de la IA se considera una gran amenaza. No aprovechar las oportunidades que ofrece la IA podría implicar una implementación deficiente de algunos programas europeos, como el Pacto Verde Europeo. También supondría la pérdida de ventaja competitiva frente a otras regiones, el estancamiento económico y menos posibilidades para los ciudadanos. La infrautilización podría deberse a la desconfianza del público y las empresas en la IA, una infraestructura deficiente, la falta de iniciativa, las bajas inversiones o, como que el aprendizaje automático de la IA depende de los datos, a los mercados digitales fragmentados.
El uso excesivo es también problemático. Existe el riesgo de invertir en aplicaciones inútiles o usar la IA en tareas que no la requieren, como en intentar explicar con esta tecnología problemas sociales complejos. 

Determinar quién es el responsable del daño causado por un servicio o aparato que aplicó la IA es un gran desafío. En un accidente en el que esté implicado un coche de conducción autónoma, ¿quién debería cubrir los daños: el propietario, el fabricante del vehículo o el programador?
Si el productor estuviera libre de responsabilidad, podría no haber ningún incentivo para ofrecer un buen producto o servicio, y se dañaría la confianza de los ciudadanos en la tecnología. Sin embargo, unas regulaciones demasiados estrictas impedirían la innovación. 

Los resultados de la IA dependen de su uso y de los datos utilizados. Existe la posibilidad de sesgar, intencional o involuntariamente, tanto el diseño como los datos. Por ejemplo, algunos aspectos importantes de un asunto podrían no estar programados en el algoritmo o, por el contratio, podrían programarse para reflejar y replicar segos estructurales. Además, el uso de números para represetar una realidad social compleja podría hacer que la IA parezca objetiva y precisa cuando no lo es (lo que se conoce como "mathwashing"). 
Otro de los peligros es utilizar la inteligencia artificial tomar decisiones influenciadas por la etnia, el sexo o la edad incluidos en los datos al contratar o despedir, ofrecer préstamos o incluso en procesos penales.
La IA también supone riesgos para la privacidad y la protección de datos al utilizarse, por ejemplo, en equipos de reconocimiento facial o para el seguimiento en línea y la creación de perfiles de personas. Además, permite fusionar información que una persona ha proporcionado con datos nuevos, lo que genera resultados que la persona no esperaría. 
Esta tecnología presenta riesgos para la democracia, al crear, por ejemplo, cámaras de eco por internet basadas en el comportamiento previo de alguien en la red, al mostrar solo un contenido específico. Los sistemas de IA también pueden usarse para crear vídeos, audios o imágenes falsos pero realistas, conocidos como "deepfakes" o "ultrafalsos. Este contenido puede implicar riegos financieros, daños reputacionales y problemas en las tomas decisiones. Todo esto podría conducir a la separación y polarización en la esfera pública y manipular las elecciones.

La libertad de reunión y protesta está también amenazada por la IA, ya que ésta podría rastrear y controlar a las personas vinculadas a ciertas creencias o acciones.

El uso de IA en el empleo eliminaría un gran número de puestos de trabajo, pero crearía otros. La educación y la formación tendrán un papel crucial para prevenir el desempleo a largo plazo y garantizar una mano de obra cualificada. 
La acumulación de información amenaza con la distorsión de la competencia ya que los actores con más información tendrían una ventaja y eliminarían a los competidores.
Las aplicaciones de IA que están en contacto físico con personas o integradas en el cuerpo humano pueden presentar riesgos de seguridad si están mal diseñadas, mal utilizadas o pirateadas.
El uso mal regulado de la IA en las armas podría provocar la pérdida del control humano sobre las armas peligrosas.
Se podrían aprovechar los desequilibrios en el acceso a la información. Por ejemplo, un proveedor en línea puede usar la IA para predecir cuánto está dispuesto a pagar el consumidor al observar su comportamiento en línea o una campaña política podría adaptar su mensaje.

Otro problema de transparencia es que, a veces, las personas desconocen si están interactuando con IA o con una persona.
Descubra cómo los eurodiputados quieren regular la legislación sobre datos para promover la innovación y garantizar la seguridad.